{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STA 863 Final Project - FHMM\n",
    "*Factorial Hidden Markov Models* - Gharamani and Jordan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from numpy import linspace,exp\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns\n",
    "from music_comp import * ## pre-processing and metrics code\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate log likelihood\n",
    "# n is number of observations\n",
    "# W is a M long list of D x K[m] matrices\n",
    "# pi is a M long list of K[m] vectors for the initial distributions\n",
    "# Tmat is a M long list of K[m] x K[m] transition matrices\n",
    "# C is a D x D covariance matrix for the Gaussian observations \n",
    "# mu is a D x n mean matrix\n",
    "def log_like(n, pi, Tmat, mu, C, Y, zstates):\n",
    "    y_prob = np.zeros(n) # emission probabilities\n",
    "    t_prob = 0 # transition matrix probabilities\n",
    "    pi_prob = 0 # initial probability\n",
    "    for i in range(0, M):\n",
    "            pi_prob += np.log(pi[i][zstates[i][0]])\n",
    "    \n",
    "    for t in range(0, n):\n",
    "        y_prob[t] = np.log(multivariate_normal.pdf(Y[:, t], mean = mu[:, t], cov = C))  \n",
    "        \n",
    "        for i in range(0, M):\n",
    "            t_prob += Tmat[i][zstates[i][t-1], zstates[i][t]]\n",
    "    ll = pi_prob + t_prob + np.sum(y_prob)        \n",
    "    return(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Toy Data and Parameters\n",
    "\n",
    "$$P({S_t, Y_t}) = P(S_1)P(Y_1 | S_1)\\prod_{t=2}^T P(S_t | S_{t-1})P(Y_t | S_t)$$\n",
    "\n",
    "- Assume three different chains, each with 5 hidden states each\n",
    "- M = 3, K = (5, 5, 5)\n",
    "- n = 10 observations, D = 3 (dimension of Gaussian)\n",
    "- Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# M = 3 ## Number of independent hidden state chains\n",
    "# K = np.array([5, 5, 5]) ## number of hidden states for each chain\n",
    "# D = 3 ## Dimension of Gaussian\n",
    "# n = 10 ## number of observations\n",
    "\n",
    "\n",
    "# ## Generate distribtions\n",
    "# pi = [] ## initial distribution\n",
    "# Tmat = []  ## transition distribution\n",
    "# W = [] ## contribution to means matrices D x K\n",
    "# for i in range(0, M):\n",
    "#     vals = np.random.rand(K[i])\n",
    "#     pi.append(vals/np.sum(vals))\n",
    "#     vals1 = np.random.rand(K[i], K[i])\n",
    "#     Tmat.append(vals1/np.sum(vals1, axis=1)[:,None])\n",
    "#     W.append(10*np.random.rand(D, K[i]))\n",
    "    \n",
    "# ## Generate state variables\n",
    "# S = []\n",
    "# for i in range(0, M):\n",
    "#     zstates = np.arange(0, K[i], dtype = int)\n",
    "#     z = np.zeros(n, dtype = int)\n",
    "#     zmat = np.zeros((K[i], n), dtype = int)\n",
    "#     z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "#     zmat[z[0], 0] = 1\n",
    "#     for j in range(1, n):\n",
    "#         z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "#         zmat[z[j], j] = 1\n",
    "#     S.append(zmat)\n",
    "# #x = np.random.normal(size=D)\n",
    "# #y = np.random.normal(size=D)\n",
    "# #z = np.vstack((x, y))\n",
    "# #C = np.cov(z.T) ## covariance matrix\n",
    "# C = np.identity(D)\n",
    "# mu = np.zeros((D, n))\n",
    "# Y = np.zeros((D, n))\n",
    "# for t in range(0, n):\n",
    "#     for i in range(0, M):\n",
    "#         mu[:, t] += np.dot(W[i], S[i][:, t])\n",
    "#     Y[:, t] = np.random.multivariate_normal(mu[:, t], C, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#C_new = np.dot((np.array([1, 2, 1] ) - np.array([0, 0.7, 0]))[np.newaxis].transpose(), \n",
    "#               (np.array([1, 2, 1] ) - np.array([0, 0.7, 0]))[np.newaxis])\n",
    "#print(np.all(np.linalg.eigvals(C_new) > 0))\n",
    "#C_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(\"Pi\")\n",
    "# print(np.round(pi, 3))\n",
    "# print(\"Tmat\")\n",
    "# print(np.round(Tmat, 3))\n",
    "# print(\"W\")\n",
    "# print(np.round(W, 3))\n",
    "# print(\"C\")\n",
    "# print(np.round(C, 3))\n",
    "# print(\"Z states\")\n",
    "# print([np.where(S[0][:, t] == 1)[0][0] for t in range(n)])\n",
    "# print([np.where(S[1][:, t] == 1)[0][0] for t in range(n)])\n",
    "# print([np.where(S[2][:, t] == 1)[0][0] for t in range(n)])\n",
    "# print('Log-Likelihood')\n",
    "# zstore = [[np.where(S[0][:, t] == 1)[0][0] for t in range(n)], [np.where(S[1][:, t] == 1)[0][0] for t in range(n)],\n",
    "#          [np.where(S[2][:, t] == 1)[0][0] for t in range(n)]]\n",
    "# log_like(n, pi, Tmat, mu, C, Y, zstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(Y)\n",
    "# plt.title(\"Toy Data Y Values\")\n",
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E - Step\n",
    "\n",
    "## 2. Gibbs Sampling \n",
    "\n",
    "$$S_t^{(m)} \\propto P(S_t^{(m)} | S_{t-1}^{(m)})P(S_{t+1}|S_t^{(m)})P(Y_t | S_t^{(1)}, \\ldots, S_t^{(M)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate transition matrix from a vector\n",
    "# q is a vector from 0 to m different states\n",
    "# return m x m transition matrix b\n",
    "from collections import Counter\n",
    "def trans_mat(q, m):\n",
    "    b = np.zeros((m,m))\n",
    "    for (x,y), c in Counter(zip(q, q[1:])).items():\n",
    "        b[x, y] = c\n",
    "    return(b)\n",
    "\n",
    "\n",
    "# t is the time step to be updated\n",
    "# y is the observed value at that time step\n",
    "# M is the number of hidden Markov chains\n",
    "# K is a vector of number of hidden states for each chain\n",
    "# C is covariance matrix for emission distribution\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable \n",
    "# S is a M long list of current states, each element of list is K[i] x n long (n number of observations)\n",
    "# update is which of M chains to calculate emission probabilities for, for every K[i] possible values\n",
    "# output is a K[update] vector of density of y for each possible value of S[update]\n",
    "def y_density(t, y, M, K, S, C, W, update):\n",
    "    ydense = np.zeros(K[update]) ## output density for each possible value of S[update]\n",
    "    Stemp = S\n",
    "    for i in range(0, K[update]):\n",
    "        mu = 0\n",
    "        Stemp[update][:, t] = 0\n",
    "        Stemp[update][i, t] = 1 # state variable value to calculate probability for\n",
    "        for j in range(0, M):\n",
    "            mu += np.dot(W[j], Stemp[j][:, t])\n",
    "        ydense[i] = multivariate_normal.pdf(y, mean = mu, cov = C)\n",
    "    return(ydense)\n",
    "\n",
    "\n",
    "\n",
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# it is the number of iterations to run for the Gibbs Sampler\n",
    "# output is:\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "def gibbs_sampler(n, M, K, Y, Tmat, W, C, it = 10):\n",
    "    # Randomly initialize state vectors\n",
    "    small = 10E-5\n",
    "    S = []\n",
    "    zstates = []\n",
    "    for i in range(0, M):\n",
    "        s = np.zeros((K[i], n), dtype = int)\n",
    "        ind = np.random.choice(range(0, K[i]), n)\n",
    "        s[ind, range(0, n)] = 1\n",
    "        zz = np.zeros((it, n), dtype = int)\n",
    "        zz[0, :] = ind\n",
    "        zstates.append(zz)\n",
    "        S.append(s)\n",
    "        \n",
    "    for l in range(1, it):\n",
    "        ## update one  chain at a time\n",
    "        for i in range(0, M):\n",
    "            ## step through each time point\n",
    "            for t in range(0, n):\n",
    "                ## select P(S_t | S_t-1)\n",
    "                if t == 0:\n",
    "                    tback = np.ones(K[i])\n",
    "                else:\n",
    "                    prev = zstates[i][l-1, t-1]\n",
    "                    tback = Tmat[i][prev, :]\n",
    "                ## select P(S_t+1 | S_t)\n",
    "                if t == (n-1):\n",
    "                    tfore = np.ones(K[i])\n",
    "                else:\n",
    "                    fore = zstates[i][l-1, t]\n",
    "                    tfore = Tmat[i][fore, :]\n",
    "                ## calculate P(Y_t | S_t^1, S_t^2, ..., S_t^M)\n",
    "                ydense = y_density(t, Y[:, t], M, K, S, C, W, i)\n",
    "                \n",
    "                ## Calculate probability for each state for S_t^i\n",
    "                probvec = np.multiply(np.multiply(tback, tfore) , ydense)\n",
    "                if np.sum(probvec) == 0: # check if all states have 0 probability\n",
    "                    probvec = np.ones(len(probvec)) # reset to equal probs if so\n",
    "                probvec = probvec/sum(probvec)\n",
    "                ## sample state and update vector\n",
    "                zstates[i][l, t] = np.random.choice(range(0, K[i]), 1, p = probvec)\n",
    "                S[i][zstates[i][l, t], t] = 1\n",
    "    \n",
    "    ## Calculate expectations\n",
    "    # <S_t^(m)>\n",
    "    St = []\n",
    "    Smm = []\n",
    "    for i in range(0, M):\n",
    "        uprobs = [np.unique(zstates[i][:, t], return_counts = True)[1]/it for t in range(0,n)] # calculate probs\n",
    "        zmat = np.zeros((K[i], n))\n",
    "        inds = [np.unique(zstates[i][:, t], return_counts = True)[0] for t in range(0,n)]\n",
    "        for t in range(n):\n",
    "            zmat[inds[t], t] += uprobs[t] + small\n",
    "        #zmat = zmat/np.sum(zmat)\n",
    "        St.append(zmat)\n",
    "        # calculate trans mat\n",
    "        Smm.append(np.stack([trans_mat(zstates[i][:, t], K[i])/(it-1) for t in range(0, n)], axis = 2))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # <S_t^(m)S_t^(n)>\n",
    "    Snm = np.zeros((sum(K), sum(K), n))\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0) # indices for Snm matrix\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            for j in range(0, M):\n",
    "                if i == j:\n",
    "                    s1 = np.zeros((K[i], K[i]))\n",
    "                    mm = np.unique(zstates[i][:, t], return_counts = True)\n",
    "                    s1[mm[0], mm[0]] = mm[1]/it\n",
    "                    Snm[ind1[i]:ind2[i], ind1[i]:ind2[i], t] = s1\n",
    "                s2 = np.zeros((K[i], K[j]))\n",
    "                for l in range(0, it):\n",
    "                    s2[zstates[i][l, t], zstates[j][l, t]] += 1\n",
    "                Snm[ind1[i]:ind2[i], ind1[j]:ind2[j], t] = s2/it\n",
    "    \n",
    "    return(St, Smm, Snm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Completely Factorized VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## KL divergence (to monitor convergence of approximation) - equation C.9\n",
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# pi is M long list of initial distributions\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# Return KL divergence\n",
    "def KL_factorized(n, M, K, Y, theta, pi, Tmat, W, C):\n",
    "    term1 = 0\n",
    "    term2 = 0\n",
    "    term3 = 0\n",
    "    term4 = 0\n",
    "    term5 = 0\n",
    "    term6 = 0\n",
    "    term7 = 0\n",
    "    small = 10E-10\n",
    "    for t in range(n):\n",
    "        term2 += np.dot(Y[:, t].transpose() , np.dot(np.linalg.inv(C), Y[:, t]))\n",
    "        for i in range(M):\n",
    "            term1 += np.dot(theta[i][:, t].transpose(), np.log(theta[i][:, t] + small))\n",
    "            term3 += np.dot(np.dot(Y[:, t].transpose(), np.linalg.inv(C)), np.dot(W[i], theta[i][:, t]))\n",
    "            for j in range(M):\n",
    "                if i != j:\n",
    "                    targ1 = np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), W[j])\n",
    "                    targ2 = np.dot(theta[j][:, t], theta[i][:, t].transpose())\n",
    "                    term4 += np.trace(np.dot(targ1, targ2))\n",
    "            \n",
    "            term5 += np.trace(np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), \n",
    "                                     np.dot(W[i], np.diag(theta[i][:, t]))))\n",
    "            if t > 0:\n",
    "                term7 += np.trace(np.outer(theta[i][:, t-1], \n",
    "                                           np.dot(theta[i][:, t].transpose(), np.log(Tmat[i] + small))))\n",
    "                \n",
    "    for i in range(M):\n",
    "        term6 += np.dot(theta[i][:, 0].transpose(), np.log(pi[i] + small))\n",
    "        \n",
    "    # Find normalizing constants\n",
    "    \n",
    "    KL = term1 + 0.5*(term2 - 2*term3 + term4 + term5) + term6 + term7\n",
    "    return(KL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Softmax operator on input vector x\n",
    "def softmax(x):\n",
    "    y = x - np.max(x)\n",
    "    return(np.exp(y)/np.sum(np.exp(y)))\n",
    "\n",
    "\n",
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# theta is a M long list of K[m] x n matrices from completely factorized VI approx\n",
    "# pi is M long list of initial distributions\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# tol is the tolerance for convergence of the KL divergence to stop the iterations\n",
    "# output is:\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "def factorized_VI(n, M, K, Y, pi, Tmat, W, C, tol):\n",
    "    D = Y.shape[0]\n",
    "    thetaOld = []\n",
    "    thetaNew = []\n",
    "    for i in range(M):\n",
    "        vals1 = np.random.rand(K[i], n)\n",
    "        thetaOld.append(vals1/np.sum(vals1, axis=0)[None, :])\n",
    "        thetaNew.append(np.zeros((K[i], n)))\n",
    "\n",
    "    KLOld = 10E10\n",
    "    small = 10E-10\n",
    "    convergence = 0\n",
    "    iterations = 0\n",
    "    criteria = 10E10\n",
    "    maxit = 20 ## max number of iterations\n",
    "    while(convergence == 0):\n",
    "        for i in range(M):\n",
    "            for t in range(n):\n",
    "                ## Calculate Y tilde\n",
    "                s1 = np.zeros((D, 1))\n",
    "                for j in np.delete(np.arange(M), i):\n",
    "                    s1 += np.dot(W[j], thetaOld[j][:, t])[np.newaxis].transpose()\n",
    "                Ytilde = Y[:, t][np.newaxis].transpose() - s1\n",
    "                ## Calculate delta term\n",
    "                delta = np.dot(W[i].transpose(), np.dot(np.linalg.inv(C), W[i])).diagonal()\n",
    "                ## Calculate first term\n",
    "                term1 = np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), Ytilde)\n",
    "                term2 = delta[np.newaxis].transpose()/2\n",
    "                if t > 0:\n",
    "                    term3 = np.dot(np.log(Tmat[i] + small), thetaOld[i][:, t-1])[:, np.newaxis]\n",
    "                else:\n",
    "                    term3 = np.log(pi[i] + small)[np.newaxis].transpose()\n",
    "                if t < n-1:\n",
    "                    term4 = np.dot(np.log(Tmat[i] + small).transpose(), thetaOld[i][:, t+1])[np.newaxis].transpose()\n",
    "                else:\n",
    "                    term4 = np.zeros(K[i])[np.newaxis].transpose()\n",
    "                ## Find sum\n",
    "                sumterm = term1 - term2 + term3 + term4\n",
    "                thetaNew[i][:, t] = softmax(sumterm).transpose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## Check KL divergence\n",
    "\n",
    "\n",
    "\n",
    "        #KLNew = KL_factorized(n, M, K, Y, thetaNew, pi, Tmat, W, C)\n",
    "        #print(KLNew)\n",
    "        #criteria = abs(KLOld - KLNew)\n",
    "        if criteria < tol or iterations > maxit:\n",
    "            convergence = 1\n",
    "        #else:\n",
    "        #    convergence = 0\n",
    "        #    KLOld = KLNew\n",
    "        #    thetaOld = thetaNew\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    ## Find expectations\n",
    "    # St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "    # Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "    # Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "    St = [np.zeros((K[i], n)) for i in range(M)]\n",
    "    Smm = [np.zeros((K[i], K[i], n)) for i in range(M)]\n",
    "    Snm = np.zeros((np.sum(K), np.sum(K), n))\n",
    "    for i in range(M):\n",
    "        for t in range(n):\n",
    "            St[i][:, t] = thetaNew[i][:, t]\n",
    "            if t == 0:\n",
    "                Smm[i][:, :, t] = np.outer(pi[i], thetaNew[i][:, t])\n",
    "            else:\n",
    "                Smm[i][:, :, t] = np.outer(thetaNew[i][:, t-1], thetaNew[i][:, t])\n",
    "\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0) # indices for Snm matrix\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            for j in range(0, M):\n",
    "                if i == j:\n",
    "                    Snm[ind1[i]:ind2[i], ind1[i]:ind2[i], t] = np.diag(thetaNew[i][:, t])\n",
    "                else:\n",
    "                    Snm[ind1[i]:ind2[i], ind1[j]:ind2[j], t] = np.outer(thetaNew[i][:, t], thetaNew[j][:, t])\n",
    "                    \n",
    "    return(St, Smm, Snm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Structural VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Forward- Backward Algorithm\n",
    "#Function using the log-sum-exp trick#\n",
    "def logSumExp(a):\n",
    "    if np.all(np.isinf(a)):\n",
    "        return np.log(0)\n",
    "    else:\n",
    "        b = np.max(a)\n",
    "        return(b + np.log(np.sum(np.exp(a-b))))\n",
    "\n",
    "\n",
    "def pForwardFHMM(g):\n",
    "    n, m = g.shape\n",
    "    pXf = logSumExp(g[n-1,:])\n",
    "    return(pXf)\n",
    "\n",
    "    \n",
    "def forwardAlgFHMM(n, m, pi, Tmat, phi):\n",
    "    g = np.zeros((n,m))\n",
    "    for i in range(0,m):\n",
    "        g[0,i] = (pi[i]) + (phi[i, 0])\n",
    "    \n",
    "    \n",
    "    for j in range(1, n):\n",
    "        for l in range(0, m):\n",
    "            g[j,l] = logSumExp(np.asarray(g[j-1, :]) + np.asarray(Tmat[:,l]) + (phi[l, j]))\n",
    "    return(g)\n",
    "\n",
    "def backwardAlgFHMM(n, m, pi, Tmat, phi):\n",
    "    r = np.zeros((n,m))\n",
    "    for j in range(n-2, -1, -1):\n",
    "        for l in range(0, m):\n",
    "            r[j, l] = logSumExp(np.asarray(r[j+1,: ]) + np.asarray(Tmat[l,:]) + phi[:, j+1])\n",
    "    \n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# theta is a M long list of K[m] x n matrices from completely factorized VI approx\n",
    "# pi is M long list of initial distributions\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# tol is the tolerance for convergence of the KL divergence to stop the iterations\n",
    "# output is:\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "def structural_VI(n, M, K, Y, pi, Tmat, W, C, tol):\n",
    "    D = Y.shape[0]\n",
    "    small = 10E-10\n",
    "    ## Work with log of parameters\n",
    "    piL = [np.log(pi[i] + small) for i in range(M)]\n",
    "    TmatL = [np.log(Tmat[i] + small) for i in range(M)]\n",
    "    # St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "    St = [np.zeros((K[i], n)) for i in range(M)]\n",
    "    ## h matrices which serve as emission distributions for forward-backward\n",
    "    phi = [np.zeros(shape = (K[i], n)) for i in range(M)]\n",
    "    ## Randomly initialize St\n",
    "    for i in range(M):   \n",
    "        vals = np.random.rand(K[0], n)\n",
    "        St[i] = vals/np.sum(vals, axis=0)[None, :]\n",
    "    \n",
    "    \n",
    "    pOld = 10E10#*np.ones(M)\n",
    "    pNew = np.zeros(M)\n",
    "    convergence = 0\n",
    "    iterations = 0\n",
    "    criteria = 10E10\n",
    "    maxit = 20 ## max number of iterations\n",
    "    while(convergence == 0):\n",
    "        for i in range(M):\n",
    "            ## 1. Find ht = phi ##\n",
    "\n",
    "            ## Calculate delta term\n",
    "            delta = np.dot(W[i].transpose(), np.dot(np.linalg.inv(C), W[i])).diagonal()\n",
    "\n",
    "            for t in range(n):\n",
    "                ## Calculate Y tilde\n",
    "                s1 = np.zeros((D, 1))\n",
    "                for j in np.delete(np.arange(M), i):\n",
    "                    s1 += np.dot(W[j], St[j][:, t])[np.newaxis].transpose()\n",
    "                Ytilde = Y[:, t][np.newaxis].transpose() - s1\n",
    "                term1 = np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), Ytilde)\n",
    "                term2 = delta[np.newaxis].transpose()/2\n",
    "                #phi[i][:, t] = np.exp(term1 - term2).transpose()\n",
    "                phi[i][:, t] = (term1 - term2).transpose()\n",
    "\n",
    "\n",
    "            ## 2. Run Forwards-Backwards Algorithm\n",
    "\n",
    "            g = forwardAlgFHMM(n, K[i], piL[i], TmatL[i], phi[i])\n",
    "            h = backwardAlgFHMM(n, K[i], piL[i], TmatL[i], phi[i])\n",
    "            pNew[i] = pForwardFHMM(g)\n",
    "            #print(g)\n",
    "            #print(pForward(g))\n",
    "\n",
    "            ## 3. Update expectations\n",
    "            for t in range(0, n):\n",
    "                for j in range(0, K[i]):\n",
    "                    St[i][j, t] = np.exp(g[t, j] + h[t, j] - pNew[i])\n",
    "                    \n",
    "            #print(np.sum(St[i]))\n",
    "        ## Check log-likelihood\n",
    "        #print(KLNew)\n",
    "        #print(pOld)\n",
    "        #print(pNew)\n",
    "        criteria = abs(pOld - np.max(pNew))\n",
    "        if criteria < tol or iterations > maxit:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            pOld = np.max(pNew)\n",
    "            #thetaOld = thetaNew\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ## Find expectations\n",
    "    # St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "    # Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "    # Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "    \n",
    "    ## St already found above\n",
    "    Smm = [np.zeros((K[i], K[i], n)) for i in range(M)]\n",
    "    for i in range(M):\n",
    "        for t in range(n):\n",
    "            if t == 0:\n",
    "                Smm[i][:, :, t] = np.outer(pi[i], St[i][:, t])\n",
    "            else:\n",
    "                Smm[i][:, :, t] = np.outer(St[i][:, t-1], St[i][:, t])\n",
    "    \n",
    "    #intermed = Smm[m][:, :, t]/np.sum(Smm[m][:, :, t])\n",
    "    #Smm[m][:, :, t] = np.exp(intermed)/np.sum(np.exp(intermed)) ## renormalize\n",
    "    \n",
    "#     for m in range(M):\n",
    "#         for t in range(0, n):\n",
    "#             for i in range(0, K[m]):\n",
    "#                 for j in range(0, K[m]):\n",
    "#                     if t == 0:\n",
    "#                         #Smm[m][i, j, t] = np.exp(TmatL[m][i,j] + phi[m][j, t] + piL[m][i] + h[t, j] - pNew[m])\n",
    "#                         Smm[m][i, j, t] = TmatL[m][i,j] + phi[m][j, t] + piL[m][i] + h[t, j] - pNew[m]\n",
    "#                     else:\n",
    "#                         #Smm[m][i, j, t] = np.exp(TmatL[m][i,j] + phi[m][j, t] + g[t-1, i] + h[t, j] - pNew[m])\n",
    "#                         Smm[m][i, j, t] = TmatL[m][i,j] + phi[m][j, t] + g[t-1, i] + h[t, j] - pNew[m]\n",
    "            \n",
    "#             #print(np.sum(Smm[m][:, :, t]))\n",
    "#             if np.sum(Smm[m][:, :, t]) < small:\n",
    "#                 Smm[m][:, :, t] += small\n",
    "            \n",
    "#             intermed = Smm[m][:, :, t]/np.sum(Smm[m][:, :, t])\n",
    "#             Smm[m][:, :, t] = np.exp(intermed)/np.sum(np.exp(intermed)) ## renormalize\n",
    "    \n",
    "    \n",
    "    Snm = np.zeros((np.sum(K), np.sum(K), n))\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0) # indices for Snm matrix\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            for j in range(0, M):\n",
    "                if i == j:\n",
    "                    Snm[ind1[i]:ind2[i], ind1[i]:ind2[i], t] = np.diag(St[i][:, t])\n",
    "                else: ## Assume independence\n",
    "                    Snm[ind1[i]:ind2[i], ind1[j]:ind2[j], t] = np.outer(St[i][:, t], St[j][:, t])\n",
    "                    \n",
    "    return(St, Smm, Snm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# # warnings.simplefilter(\"always\")\n",
    "# # for i in range(10):\n",
    "# #     print i\n",
    "# #     warnings.warn('this is a warning message')\n",
    "# warnings.simplefilter('error')\n",
    "# for i in range(100):\n",
    "#     print(i)\n",
    "#     St, Smm, Snm = structural_VI(n, M, K, Y, pi, Tmat, W, C_new, tol = 1E-5)\n",
    "#     W, pi, Tmat, C_new = Mstep(M, K,  Y, St, Smm, Snm)\n",
    "#     if not np.all(np.linalg.eigvals(C_new) > 0):\n",
    "#         print(C_new)\n",
    "#         break\n",
    "#     #print(np.all(np.linalg.eigvals(C_new) > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for i in range(M):\n",
    "#    print(np.sum(St[i], axis = 0))\n",
    "#    for t in range(n):\n",
    "#        print(np.sum(Smm[i][:,:,  t]))\n",
    "#        print(np.sum(St[i][:, t]))\n",
    "#for t in range(n):\n",
    "#    print(np.sum(Snm[0:5, 0:5, t]), np.sum(Snm[0:5, 5:10, t]), np.sum(Snm[0:5, 10:15, t]))\n",
    "#    print(np.sum(Snm[5:10, 0:5, t]), np.sum(Snm[5:10, 5:10, t]), np.sum(Snm[5:10, 10:15, t]))\n",
    "#    print(np.sum(Snm[10:15, 10:15, t]), np.sum(Snm[10:15, 10:15, t]), np.sum(Snm[10:15, 10:15, t]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M-Step\n",
    "\n",
    "## 5. M-Step\n",
    "\n",
    "$$ n = T$$\n",
    "$$W^{new} = \\left(\\sum_{t=1}^T Y_t<S_t'>\\right)\\left(\\sum_{t=1}^T<S_tS_t'>\\right)^{\\dagger}$$\n",
    "\n",
    "** Add other update equations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# M is number of hidden state Markov chains\n",
    "# K is vector of number of hidden states for each Markov chain\n",
    "# Y is the D x n matrix of observations\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "# output is a tuple of updated values from the M step\n",
    "# W is a M long list of D x K[m] matrices\n",
    "# pi is a M long list of K[m] vectors for the initial distributions\n",
    "# Tmat is a M long list of K[m] x K[m] transition matrices\n",
    "# C is a D x D covariance matrix for the Gaussian observations\n",
    "\n",
    "def Mstep(M, K,  Y, St, Smm, Snm):\n",
    "    D, n = Y.shape\n",
    "    ### Update W ###\n",
    "    # Concatenate St to be sum(K) x 1 x t\n",
    "    cSt = np.vstack([np.vstack(St[i]) for i in range(0, len(St))])\n",
    "    s1 = np.dot(Y, cSt.transpose()) # first sum for Wnew\n",
    "    s2 = np.linalg.pinv(np.sum(Snm, axis = 2)) # second sum for Wnew\n",
    "    Wnew = np.dot(s1, s2)\n",
    "    # make Wnew back into list of matrices\n",
    "    W = []\n",
    "    pi = []\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for i in range(0, M):\n",
    "        W.append(Wnew[:, ind1[i]:ind2[i]])\n",
    "        ### Update pi ###\n",
    "        pi.append(cSt[ind1[i]:ind2[i], 0])\n",
    "\n",
    "    ### Update Transition matrices ###\n",
    "    Tmat = []\n",
    "    #St = [np.vstack(St[i]) for i in range(0, M)] ## stack St matrices for easier indexing\n",
    "    for i in range(0, M):\n",
    "        Tnew = np.zeros((K[i], K[i]))\n",
    "        for j in range(0, K[i]):\n",
    "            for l in range(0, K[i]):\n",
    "                Tnew[j,l] =  np.sum(Smm[i][j, l, :])/np.max([np.sum(St[i][l, 0:(n-1)]), 10E-5])\n",
    "        #print(np.sum(Tnew, axis=1)[:,None])\n",
    "        if np.any(np.sum(Tnew, axis=1)[:,None]):\n",
    "            #print(\"Yes\")\n",
    "            Tnew = Tnew + 10E-5\n",
    "        #print(np.sum(Tnew, axis=1)[:,None])\n",
    "        Tnew = Tnew/np.sum(Tnew, axis=1)[:,None]\n",
    "        Tmat.append(Tnew)\n",
    "\n",
    "    ### Update C covariance ###\n",
    "    #s1 = np.dot(Y, Y.transpose())/n\n",
    "    #s2 = np.zeros((D, D))\n",
    "    #for t in range(0, n):\n",
    "    #    for i in range(0, M):\n",
    "    #        mult1 = np.dot(W[i], St[i][t, :])\n",
    "    #        s2 += np.outer(mult1, Y[:, t].transpose())\n",
    "    #C = s1 - s2/n\n",
    "    \n",
    "    #mutemp = np.zeros((D, n))\n",
    "    #for i in range(0, M):\n",
    "    #    mutemp += np.dot(W[i], np.vstack(St[i]))\n",
    "    #C = np.dot(Y - mutemp, (Y - mutemp).transpose())/n\n",
    "    \n",
    "    term2 = np.zeros((D, D))\n",
    "    for i in range(M):\n",
    "        for t in range(n):\n",
    "            term2 += np.dot(np.dot(W[i], St[i][:, t][:, np.newaxis]), Y[:, t][np.newaxis])\n",
    "\n",
    "\n",
    "    C = np.dot(Y, Y.transpose())/n - term2/n\n",
    "    \n",
    "    return(W, pi, Tmat, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Inference: Run E-M Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y is D x n observation matrix\n",
    "# M is number of hidden markov chains\n",
    "# K is an 1 x M vector of the number of hidden states for each chain\n",
    "# tol = tolerance for convergence\n",
    "# inference is inference method to use, choices = Gibbs, FactorizedVI, StructuralVI\n",
    "def FHMM(Y, M, K, tol, inference):\n",
    "    D, n = Y.shape\n",
    "    print(D, n)\n",
    "    ## Initialize params\n",
    "    pi = [] ## initial distribution\n",
    "    Tmat = []  ## transition distribution\n",
    "    W = [] ## contribution to means matrices D x K\n",
    "    for i in range(0, M):\n",
    "        vals = np.random.rand(K[i])\n",
    "        pi.append(vals/np.sum(vals))\n",
    "        vals1 = np.random.rand(K[i], K[i])\n",
    "        Tmat.append(vals1/np.sum(vals1, axis=1)[:,None])\n",
    "        W.append(10*np.random.rand(D, K[i]))\n",
    "    C_old = np.identity(D)\n",
    "    print(C_old)\n",
    "    convergence = 0\n",
    "    pOld = 10E10\n",
    "    iterations = 0\n",
    "    while(convergence == 0):\n",
    "        \n",
    "        ## E - Step\n",
    "        if inference == \"Gibbs\":\n",
    "            St, Smm, Snm = gibbs_sampler(n, M, K, Y, Tmat, W, C_old, it = 10)\n",
    "            \n",
    "        if inference == \"FactorizedVI\":\n",
    "            St, Smm, Snm = factorized_VI(n, M, K, Y, pi, Tmat, W, C_old, tol = 1E-5)\n",
    "            \n",
    "        if inference == \"StructuralVI\":\n",
    "            St, Smm, Snm = structural_VI(n, M, K, Y, pi, Tmat, W, C_old, tol = 1E-5)\n",
    "        \n",
    "        ## M - Step\n",
    "        W, pi, Tmat, C_new = Mstep(M, K,  Y, St, Smm, Snm)\n",
    "        pi = [pi[i]/np.sum(pi[i]) for i in range(M)]\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Check tolerance\n",
    "        # sample S with new params\n",
    "        ## Generate state variables\n",
    "        #S = []\n",
    "        #mu = np.zeros((D, n))\n",
    "        #zstore = []\n",
    "        #for i in range(0, M):\n",
    "        #    zstates = np.arange(0, K[i], dtype = int)\n",
    "        #    z = np.zeros(n, dtype = int)\n",
    "        #    zmat = np.zeros((K[i], n), dtype = int)\n",
    "        #    z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "        #    zmat[z[0], 0] = 1\n",
    "        #    for j in range(1, n):\n",
    "        #        z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "        #        zmat[z[j], j] = 1\n",
    "        #    S.append(zmat)\n",
    "        #    zstore.append(z)\n",
    "        #for i in range(0, M):\n",
    "        #    for j in range(1, n):\n",
    "        #        mu[:, j] += np.dot(W[i], S[i][:, j])\n",
    "        \n",
    "        #pNew = log_like(n, pi, Tmat, mu, C, Y, zstore) \n",
    "        \n",
    "        \n",
    "        ## Monitor convergence of C since does not have label switching issues like other params\n",
    "        criteria = np.linalg.norm(C_old - C_new)\n",
    "        #criteria = abs(pOld - pNew)\n",
    "        if criteria < tol or iterations > 500:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            #pOld = pNew\n",
    "            C_old = C_new\n",
    "    \n",
    "        iterations += 1\n",
    "        if iterations%10 == 0:\n",
    "            print(iterations)\n",
    "            print(criteria)\n",
    "            \n",
    "    if not np.all(np.linalg.eigvals(C_new) > 0):\n",
    "           C_new = np.dot(C_new.transpose(), C_new)\n",
    "    return(iterations, pi, Tmat, C_new, W)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pi_new, Tmat_new, mu_new, C_new, W_new = FHMM(Y, M, K, 0.1, \"FactorizedVI\")\n",
    "# print(C_new)\n",
    "# np.all(np.linalg.eigvals(C_new) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_sequence(n, D, M, K, pi, Tmat, C, W):\n",
    "    ## Generate state variables\n",
    "    S = []\n",
    "    for i in range(0, M):\n",
    "        zstates = np.arange(0, K[i], dtype = int)\n",
    "        z = np.zeros(n, dtype = int)\n",
    "        zmat = np.zeros((K[i], n), dtype = int)\n",
    "        z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "        zmat[z[0], 0] = 1\n",
    "        for j in range(1, n):\n",
    "            z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "            zmat[z[j], j] = 1\n",
    "        S.append(zmat)\n",
    "    mu = np.zeros((D, n))\n",
    "    Y = np.zeros((D, n))\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            mu[:, t] += np.dot(W[i], S[i][:, t])\n",
    "        Y[:, t] = np.random.multivariate_normal(mu[:, t], C, 1)\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_sequence(n, D, M, K, pi_new, Tmat_new, C_new, W_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Models\n",
    "\n",
    "Assumes univariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from scipy.stats import norm\n",
    "# norm.logpdf(Y, loc = np.zeros(3), scale = np.ones(3))\n",
    "# np.ones(3)*(5*np.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "\n",
    "# mu, Sigma vectors of params for each possible value of hidden states each is 1 x K[i]\n",
    "# make emission distribution matrix for normal case\n",
    "# X is D x n\n",
    "def make_phi(n, m, mu, Sigma, X):\n",
    "    phi = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        #phi[i, :] = multivariate_normal.logpdf(X.transpose(), mean = mu[i], cov = Sigma[i])\n",
    "        phi[i, :] = norm.logpdf(X, loc = mu[i], scale = Sigma[i]) ## need standard dev\n",
    "    return(phi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forwardAlgGAM(n, m, pi, Tmat, phi):\n",
    "    g = np.zeros((n,m))\n",
    "    for i in range(0,m):\n",
    "        g[0,i] = (pi[i]) + (phi[i, 0])\n",
    "    \n",
    "    for j in range(1, n):\n",
    "        for l in range(0, m):\n",
    "            g[j,l] = logSumExp(np.asarray(g[j-1, :]) + np.asarray(Tmat[:,l]) + (phi[l, j]))\n",
    "    return(g)\n",
    "\n",
    "def backwardAlgGAM(n, m, pi, Tmat, phi):\n",
    "    r = np.zeros((n,m))\n",
    "    for j in range(n-2, -1, -1):\n",
    "        for l in range(0, m):\n",
    "            r[j, l] = logSumExp(np.asarray(r[j+1,: ]) + np.asarray(Tmat[l,:]) + phi[:, j+1])\n",
    "    return(r)\n",
    "\n",
    "def ViterbiGAM(n, m, pi, Tmat, phi, x):\n",
    "    f = np.zeros(shape = (n,m))\n",
    "    alpha = np.zeros(shape = (n,m))\n",
    "    zStar = np.zeros(n)\n",
    "    \n",
    "    for t in range(0, n):\n",
    "        for i in range(0,m):\n",
    "            if t == 0:\n",
    "                f[0, i] = pi[i] + phi[i, 0]\n",
    "            else:\n",
    "                u = np.asarray(f[t-1, :]) + np.asarray(Tmat[:, i]) + phi[i, t]\n",
    "                f[t,i] = np.max(u)\n",
    "                alpha[t,i] = np.argmax(u)\n",
    "    zStar[n-1] = np.argmax(np.asarray(f[n-1, :]))\n",
    "    for i in range(n-2, -1, -1):\n",
    "        zStar[i] = alpha[i+1, int(zStar[i+1])]\n",
    "    return zStar\n",
    "\n",
    "## method = type of expectation to find, choices are \"gamma\" and \"V\", see paper pg. 2428\n",
    "def first_orderGAM(n, m, x, w, tol, method):\n",
    "    #randomly initialize pi, phi and T#\n",
    "    vals = np.random.rand(m)\n",
    "    pi = np.log(vals/np.sum(vals))\n",
    "    Tmat = np.zeros(shape = (m, m))\n",
    "    mu = np.zeros(m)\n",
    "    Sigma = np.ones(m)\n",
    "    phi = make_phi(n, m, mu, Sigma, x)\n",
    "    gamma = np.zeros(shape = (n, m))\n",
    "    beta = np.zeros(shape = (n,m,m))\n",
    "    iterations = 0\n",
    "    convergence = 0\n",
    "    count = 0\n",
    "    pOld = 1E10\n",
    "    pNew = 0\n",
    "    criteria = 0\n",
    "    \n",
    "    vals1 = np.random.rand(m,m)\n",
    "    Tmat = np.log(vals1/np.sum(vals1, axis=1)[:,None])\n",
    "    \n",
    "    \n",
    "    #Stop iterations when log(p(x_1:n)) differs by tol between iterations#\n",
    "    while convergence == 0:\n",
    "        #Perform forward and backward algorithms# \n",
    "        g = forwardAlgGAM(n, m, pi, Tmat, phi)\n",
    "        h = backwardAlgGAM(n, m, pi, Tmat, phi)\n",
    "        pNew = pForwardFHMM(g)\n",
    "        \n",
    "        ##E-Step##\n",
    "    \n",
    "        #Calculate gamma and beta#\n",
    "        for t in range(0, n):\n",
    "            for i in range(0,m):\n",
    "                gamma[t,i] = g[t,i] + h[t,i] - pNew\n",
    "        #p = np.full((n,m), pNew)\n",
    "        #gamma = g+h-p\n",
    "        for t in range(1, n):\n",
    "            for i in range(0, m):\n",
    "                for j in range(0, m):\n",
    "                    beta[t,i,j] = Tmat[i,j] + phi[j, t] + g[t-1, i] + h[t, j] - pNew\n",
    "        ##M-Step##\n",
    "    \n",
    "        #Update pi, phi and Tmat#\n",
    "        pi = gamma[0,:] - logSumExp(gamma[0,:])\n",
    "        for i in range(0, m):\n",
    "            for j in range(0, m):\n",
    "                Tmat[i,j] = logSumExp(beta[1::, i, j]) - logSumExp(beta[1::, i,:])\n",
    "        \n",
    "        \n",
    "        ## Update mu, Sigma\n",
    "        for i in range(0, m):\n",
    "            mu[i] = np.sum(np.exp(gamma[:, i])*w*x)/np.sum(np.exp(gamma[:, i])*w)\n",
    "            Sigma[i] = np.sum(np.exp(gamma[:, i])*w*(x - mu[i])**2)/np.sum(np.exp(gamma[:, i])*w)\n",
    "            \n",
    "        # Update phi\n",
    "#         Sigma = np.sqrt(Sigma)\n",
    "#         for i in range(m):\n",
    "#             if Sigma[i] == 0 or iterations == 1:\n",
    "#                 print(np.exp(phi))\n",
    "#                 print(g)\n",
    "#                 print(h)\n",
    "#                 print(pNew)\n",
    "#                 print(Sigma)\n",
    "#                 print(gamma[:, i])\n",
    "#                 print(np.sum(np.exp(gamma[:, i])*w*(x - mu[i])**2))\n",
    "#                 print(np.sum((x - mu[i])**2))\n",
    "#                 print(np.sum(np.exp(gamma[:, i])*w))\n",
    "#                 print(mu[i])\n",
    "#                 print(\"\\n\")\n",
    "        phi = make_phi(n, m, mu, Sigma, x)\n",
    "        \n",
    "        \n",
    "        criteria = abs(pOld - pNew)\n",
    "        if criteria < tol:\n",
    "            convergence = 1\n",
    "        \n",
    "        elif iterations > 10:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            pOld = pNew\n",
    "            iterations +=1\n",
    "            #print(iterations)\n",
    "            \n",
    "    if method == \"gamma\":\n",
    "        expect = gamma.transpose()\n",
    "    if method == \"V\":\n",
    "        most_likely = ViterbiGAM(n, m, np.exp(pi), np.exp(Tmat), np.exp(phi), x) ## Viterbi\n",
    "        # Use one-hot encoding\n",
    "        expect = np.zeros((m, n))\n",
    "        for t in range(n):\n",
    "            expect[int(most_likely[t]), t] = 1\n",
    "    return (iterations, pNew, np.exp(pi), np.exp(phi), np.exp(Tmat), mu, Sigma, expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# w = np.ones(n)\n",
    "# tol = 1E-3\n",
    "# iterations, pNew, pi, phi, Tmat, mu, Sigma, expect = first_order(n, K[0], Y[0, :], w, tol, \"V\")\n",
    "# #Viterbi(n, K[0], pi, Tmat, phi, Y[0, :])\n",
    "# expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y is D x n observation matrix\n",
    "# M is number of hidden markov chains\n",
    "# K is an 1 x M vector of the number of hidden states for each chain\n",
    "# tol = tolerance for convergence\n",
    "# method is type of expectation to find, choices are \"gamma\" and \"V\"\n",
    "# inference is type of observed data, choices = Gaussian\n",
    "def GAM_FHMM(x, M, K, tol, inference, method):\n",
    "    n = len(x)\n",
    "    ## Initialize params\n",
    "    pi = [np.zeros(K[i]) for i in range(M)] ## initial distribution\n",
    "    Tmat = [np.ones((K[i], K[i])) for i in range(M)]  ## transition distribution\n",
    "    mu = [np.ones(K[i]) for i in range(M)] ## contribution to means, initially 0 for all chains\n",
    "    Sigma = [np.ones(K[i]) for i in range(M)] ## variance for emission distributions, initially one for all chains\n",
    "    W = [np.random.rand(n) for i in range(M)] ## weights for GAM\n",
    "    expect = [np.ones((K[i], n)) for i in range(M)] ## expected values for f updates\n",
    "    phi = [make_phi(n, K[i], mu[i], Sigma[i], x) for i in range(M)]\n",
    "    convergence = 0\n",
    "    pOld = 10E10\n",
    "    iterations = 0\n",
    "    output = np.zeros((M, n))\n",
    "    while(convergence == 0):\n",
    "        \n",
    "        ## E - Step\n",
    "        for i in range(M):\n",
    "            if inference == \"Gaussian\":\n",
    "                W = [np.ones(n) for i in range(M)]\n",
    "                err = np.zeros(n)\n",
    "                for t in range(n):\n",
    "                    sterm = 0\n",
    "                    for j in np.delete(np.arange(M), i):\n",
    "                        sterm += np.dot(mu[j], expect[j][:, t])\n",
    "\n",
    "                    err[t] = x[t] - sterm\n",
    "#                     output[i, t] = err[t]\n",
    "                _, pNew, pi[i], phi[i], Tmat[i], mu[i], Sigma[i], expect[i] = first_orderGAM(n, K[i], \n",
    "                                                                                          err, W[i], tol, method)\n",
    "                Sigma[i] = np.sqrt(Sigma[i])\n",
    "                #print(err)\n",
    "            \n",
    "        ## Check tolerance\n",
    "        \n",
    "        \n",
    "        ## Monitor convergence of C since does not have label switching issues like other params\n",
    "        criteria = abs(pOld - pNew)\n",
    "        if criteria < tol or iterations > 500:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            pOld = pNew\n",
    "    \n",
    "        iterations += 1\n",
    "        if iterations%10 == 0:\n",
    "            print(iterations)\n",
    "            print(criteria)\n",
    "            \n",
    "    return(iterations, pi, Tmat, phi, mu, Sigma)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pi, Tmat, phi, mu, Sigma = GAM_FHMM(Y[0, :], M, K, 1E-2, \"Gaussian\", \"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_GAM(n, M, K, pi, Tmat, mu, Sigma):\n",
    "    ## Generate state variables\n",
    "    S = []\n",
    "    for i in range(0, M):\n",
    "        zstates = np.arange(0, K[i], dtype = int)\n",
    "        z = np.zeros(n, dtype = int)\n",
    "        zmat = np.zeros((K[i], n), dtype = int)\n",
    "        z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "        zmat[z[0], 0] = 1\n",
    "        for j in range(1, n):\n",
    "            z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "            zmat[z[j], j] = 1\n",
    "        S.append(zmat)\n",
    "    Y = np.zeros(n)\n",
    "    for t in range(0, n):\n",
    "        mean = 0\n",
    "        sig = 0\n",
    "        for i in range(0, M):\n",
    "            mean += np.dot(mu[i], S[i][:, t])\n",
    "            sig += Sigma[i][np.where(S[i][:, t] == 1)[0]]\n",
    "        Y[t] = np.random.normal(loc = mean, scale = sig/n, size = 1)\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# new_GAM(n, M, K, pi, Tmat, mu, Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class pre_process(object):\n",
    "    def __init__(self, input_filename, min_note):\n",
    "        self.input_filename = input_filename\n",
    "        self.min_note = min_note\n",
    "      \n",
    "    \n",
    "    def read_process(self):\n",
    "        with open(self.input_filename,encoding = \"ISO-8859-1\") as fd:\n",
    "            reader=csv.reader(fd)\n",
    "            rows= [row for idx, row in enumerate(reader)]\n",
    "        song = pd.DataFrame(rows)\n",
    "        r,c = np.where(song == ' Header')\n",
    "        quarter_note = song.iloc[r,5].values.astype(int)[0]\n",
    "        r, c = np.where(song == ' Time_signature')\n",
    "        num = song.iloc[r, 3].values.astype(int)[0]\n",
    "        denom = song.iloc[r, 4].values.astype(int)[0]**2\n",
    "        try:\n",
    "            r, c = np.where(song == ' Key_signature')\n",
    "            key = song.iloc[r,3].values.astype(int)[0]\n",
    "        except:\n",
    "            key = None\n",
    "        \n",
    "        song_model = song.loc[song.iloc[:,0] == np.max(song.iloc[:,0])]\n",
    "        song_model = song_model[song_model.iloc[:, 2].isin([' Note_on_c', ' Note_off_c'])]\n",
    "        time = np.array(song_model.iloc[:,1]).astype(int)\n",
    "        notes = np.array(song_model.iloc[:,4]).astype(int)\n",
    "        velocity = np.array(song_model.iloc[:,5]).astype(int)\n",
    "        measures = np.round(np.max(time)/quarter_note)/num\n",
    "        min_note = quarter_note\n",
    "        actual = np.arange(0, min_note*measures*num, min_note).astype(int) \n",
    "        time2 = np.array([find_nearest(actual, time[i]) for i in range(len(time))]).astype(int)\n",
    "        return(quarter_note, num, denom, key, measures, time, time2,  notes, velocity, song, song_model.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FHMM_compose(input_filename, output_filename, min_note, model, inference, method, M, K,  \n",
    "                 tol, it, metrics_calc = False, case_study = False):\n",
    "    quarter_note, num, denom, key, measures, time_piece, time_metrics, \\\n",
    "            notes, velocity, song, ind = pre_process(input_filename, min_note).read_process()\n",
    "\n",
    "    #Find possible unique notes and velocities\n",
    "    possibleNotes = np.unique(notes)\n",
    "    possibleVelocities =  np.unique(velocity)\n",
    "\n",
    "    ## Assume notes normally distributed\n",
    "    xNotes = (notes - np.mean(notes)) \n",
    "    n = len(xNotes)\n",
    "    \n",
    "\n",
    "    if metrics_calc:\n",
    "        orig_metrics = calc_metrics(time_metrics, notes, notes, velocity, measures, min_note, num)\n",
    "        metrics = np.zeros(shape = (it+1, len(orig_metrics)))\n",
    "        metrics[0,:] = orig_metrics\n",
    "    \n",
    "\n",
    "    #Run BaumWelch for specified model\n",
    "    if model == \"FHMM\":\n",
    "        if len(xNotes.shape) == 1:\n",
    "            Y = xNotes[np.newaxis]\n",
    "        else:\n",
    "            Y = xNotes\n",
    "        D = Y.shape[0]\n",
    "        t1 = time.time()\n",
    "        iterations, pi, Tmat, C_new, W = FHMM(Y, M, K, tol, inference)\n",
    "        t2 = time.time()\n",
    "        params = [pi, Tmat, C_new, W]\n",
    "        newNotes = new_sequence(n, D, M, K, pi, Tmat, C_new, W)\n",
    "#         print(np.round(newNotes + np.mean(notes)))\n",
    "        ## Convert back to integers\n",
    "        newNotes = np.round(newNotes + np.mean(notes))[0]\n",
    "\n",
    "        for j in range(len(notes)):\n",
    "            if newNotes[j] not in possibleNotes:\n",
    "                newNotes[j] = find_nearest(possibleNotes, newNotes[j])\n",
    "        newVelocities = find_vel(newNotes, velocity)\n",
    "        print(newNotes)\n",
    "        if metrics_calc:\n",
    "            for i in range(it):\n",
    "                newNotes = new_sequence(n, D, M, K, pi, Tmat, C_new, W)\n",
    "                ## Convert back to integers\n",
    "                newNotes = np.round(newNotes + np.mean(notes))[0]          \n",
    "                for j in range(len(notes)):\n",
    "                    if newNotes[j] not in possibleNotes:\n",
    "                        newNotes[j] = find_nearest(possibleNotes, newNotes[j])\n",
    "                newVelocities = find_vel(newNotes, velocity)\n",
    "                metrics[i+1, :] = calc_metrics(time_metrics, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "        \n",
    "    \n",
    "    \n",
    "    if model == 'GAM':\n",
    "        t1 = time.time()\n",
    "        iterations, pi, Tmat, phi, mu, Sigma = GAM_FHMM(xNotes, M, K, tol, inference, method)\n",
    "        t2 = time.time()\n",
    "        params = [pi, Tmat, phi, mu, Sigma]\n",
    "        newNotes = new_GAM(n, M, K, pi, Tmat, mu, Sigma)\n",
    "        ## Convert back to integers\n",
    "#         newNotes = np.round(np.std(notes)*newNotes + np.mean(notes))\n",
    "        newNotes = np.round(50*newNotes + np.mean(notes))         \n",
    "        for j in range(len(notes)):\n",
    "            if newNotes[j] not in possibleNotes:\n",
    "                newNotes[j] = find_nearest(possibleNotes, newNotes[j])\n",
    "        newVelocities = find_vel(newNotes, velocity)\n",
    "        print(newNotes)\n",
    "        if metrics_calc:\n",
    "            for i in range(it):\n",
    "                newNotes = new_GAM(n, M, K, pi, Tmat, mu, Sigma)\n",
    "                ## Convert back to integers\n",
    "                newNotes = np.round(50*newNotes + np.mean(notes))         \n",
    "                for j in range(len(notes)):\n",
    "                    if newNotes[j] not in possibleNotes:\n",
    "                        newNotes[j] = find_nearest(possibleNotes, newNotes[j])\n",
    "                newVelocities = find_vel(newNotes, velocity)\n",
    "                metrics[i+1, :] = calc_metrics(time_metrics, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "            \n",
    "                \n",
    "                \n",
    "    if model == 'SequentialMC':\n",
    "        print(\"To Do\")\n",
    "    if model == \"Advanced\":\n",
    "        print(\"To Do\")\n",
    "#         vals = np.random.rand(m)\n",
    "#         pi1 = vals/np.sum(vals)\n",
    "#         Tmat1 = np.zeros(shape = (m, m))\n",
    "#         phi1 = np.zeros(shape = (m, k))\n",
    "#         vals1 = np.random.rand(m,m)\n",
    "#         vals2 = np.random.rand(m,k)\n",
    "#         Tmat1 = vals1/np.sum(vals1, axis=1)[:,None]\n",
    "#         phi1 = vals2/np.sum(vals2, axis = 1)[:,None]\n",
    "#         newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "#         newVelocities = find_vel(newNotes, velocity)\n",
    "        \n",
    "#         if metrics_calc:\n",
    "#             for i in range(it):\n",
    "#                 newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "#                 newVelocities = find_vel(newNotes, velocity)\n",
    "#                 metrics[i+1, :] = calc_metrics(time, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "\n",
    "    song.iloc[ind, 1] = time_piece\n",
    "    song.iloc[ind, 4] = newNotes\n",
    "    song.iloc[ind, 5] = newVelocities\n",
    "    song.iloc[ind[np.where(newVelocities !=0)], 2] = ' Note_on_c'\n",
    "    song.iloc[ind[np.where(newVelocities ==0)], 2] = ' Note_off_c'\n",
    "    split = output_filename.split('.')\n",
    "    output_filename = split[0] + '__'+ model + inference + '_' + str(M)+  '-tol' +str(tol)+'.' + split[1]\n",
    "    if metrics_calc:\n",
    "        song_name = split[0].split('/')\n",
    "        metrics_filename = 'metrics/'+song_name[1]+ '__'+ model+ inference + '_' + str(M)+  '-tol' +str(tol)+ '.' + split[1] \n",
    "        pd.DataFrame(metrics).to_csv(metrics_filename, header = None, index = False)\n",
    "        print(metrics_filename)\n",
    "    song.to_csv(output_filename, header = None, index = False)\n",
    "    \n",
    "    \n",
    "    return(iterations, t2-t1, time_metrics, notes, newNotes, params) #quarter_note, num, denom, key, measures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM_compose\n",
    "\n",
    "This is the main function to take in an original piece, learn the appropriate model parameters, generate a new piece, calculate metrics and output the results.\n",
    "**Inputs:**\n",
    "- input_filename = csv file of original piece (converted from MIDI using http://www.fourmilab.ch/webtools/midicsv/#midicsv.5)\n",
    "- output_filename = filename for csvs of generated pieces and metrics\n",
    "- min_note = length of shortest note occurring in original piece\n",
    "- model = appropriate HMM model to fit, options include 'first_order', 'random', 'first_order-LR', 'second_order', 'second_order-LR', 'third_order', 'third_order-LR', 'TSHMM', 'ARHMM', 'HSMM', 'TVAR', 'factorial' and 'layered'\n",
    "- m = number of hidden states for model \n",
    "- tol = tolerance for convergence of inference algorithms\n",
    "- it = number of generated pieces to produce to calculate metrics\n",
    "- m2 = number of hidden states for the top level of the TSHMM\n",
    "- metrics_calc = True (calculate metrics) or False (generate piece only)\n",
    "- case_study = True (return parameters to explore), False (only save generated piece and metrics to CSV, no other outputs)\n",
    "\n",
    "**Outputs:**\n",
    "- generated piece to 'output_filename', if multiple pieces are generated for metrics, last generated piece is saved by default\n",
    "- metrics for number of generated pieces specified by it are saved to metrics folder\n",
    "- If case_study = True:\n",
    "    - time = time stamp for each note in the original and generated pieces\n",
    "    - notes = original notes\n",
    "    - newNotes = generated note pitches\n",
    "    - z = sequence of generated hidden states\n",
    "    - pi1 = learned initial distribution\n",
    "    - phi1 = learned emission distribution\n",
    "    - Tmat1 = learned transition distribution\n",
    "\n",
    "Note: printed intergers correspond to iteration of inference algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hmm_compose(input_filename, output_filename, min_note, model, m,  tol, it, m2 = None, metrics_calc = False,\n",
    "               case_study = False):\n",
    "    quarter_note, num, denom, key, measures, time_piece, time_metrics, \\\n",
    "            notes, velocity, song, ind = pre_process(input_filename, min_note).read_process()\n",
    "\n",
    "    #Find possible unique notes and velocities\n",
    "    possibleNotes = np.unique(notes)\n",
    "    possibleVelocities =  np.unique(velocity)\n",
    "\n",
    "    k = len(possibleNotes)\n",
    "    xNotes = encode(notes, possibleNotes)\n",
    "    n = len(xNotes)\n",
    "    \n",
    "\n",
    "    if metrics_calc:\n",
    "        orig_metrics = calc_metrics(time_metrics, notes, notes, velocity, measures, min_note, num)\n",
    "        metrics = np.zeros(shape = (it+1, len(orig_metrics)))\n",
    "        metrics[0,:] = orig_metrics\n",
    "    \n",
    "\n",
    "    #Run BaumWelch for specified model\n",
    "    if model == 'first_order':\n",
    "        t1 = time.time()\n",
    "        it1, p1, pi1, phi1, Tmat1 = first_order(n, m, k, xNotes, tol)\n",
    "        t2 = time.time()\n",
    "        newNotes, z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "        newVelocities = find_vel(newNotes, velocity)\n",
    "        iterations = it1\n",
    "        if metrics_calc:\n",
    "            for i in range(it):\n",
    "                newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "                newVelocities = find_vel(newNotes, velocity)\n",
    "                metrics[i+1, :] = calc_metrics(time_metrics, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "            \n",
    "                \n",
    "                \n",
    "    if model == 'random':\n",
    "        iterations = 1\n",
    "        t1 = time.time()\n",
    "        vals = np.random.rand(m)\n",
    "        pi1 = vals/np.sum(vals)\n",
    "        Tmat1 = np.zeros(shape = (m, m))\n",
    "        phi1 = np.zeros(shape = (m, k))\n",
    "        vals1 = np.random.rand(m,m)\n",
    "        vals2 = np.random.rand(m,k)\n",
    "        Tmat1 = vals1/np.sum(vals1, axis=1)[:,None]\n",
    "        phi1 = vals2/np.sum(vals2, axis = 1)[:,None]\n",
    "        t2 = time.time()\n",
    "        newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "        newVelocities = find_vel(newNotes, velocity)\n",
    "        \n",
    "        if metrics_calc:\n",
    "            for i in range(it):\n",
    "                newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "                newVelocities = find_vel(newNotes, velocity)\n",
    "                metrics[i+1, :] = calc_metrics(time_metrics, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "\n",
    "\n",
    "    if model == 'factorial':  #originally 15, 10, 5, but 5,5,5 for case_study\n",
    "        xstates = range(0, k)\n",
    "        noteArray = np.zeros(shape = (3, n))\n",
    "        if case_study:\n",
    "            it1, p1, pi1, phi15, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar15 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi15), xNotes)\n",
    "            zStar15 = np.array(zStar15).astype(int)\n",
    "            it1, p1, pi1, phi10, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar10 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi10), xNotes)\n",
    "            zStar10 = np.array(zStar10).astype(int)\n",
    "            it1, p1, pi1, phi5, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar5 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi5), xNotes)\n",
    "            zStar5 = np.array(zStar5).astype(int)\n",
    "            z = [zStar15, zStar10, zStar5]\n",
    "            phi1 = [phi15, phi10, phi5]\n",
    "        \n",
    "        else:\n",
    "            t1 = time.time()\n",
    "            it1, p1, pi1, phi15, Tmat1 = first_order(n, 15, k, xNotes, tol)\n",
    "            zStar15 = Viterbi(n, 15, k, np.log(pi1), np.log(Tmat1), np.log(phi15), xNotes)\n",
    "            zStar15 = np.array(zStar15).astype(int)\n",
    "            it2, p1, pi1, phi10, Tmat1 = first_order(n, 10, k, xNotes, tol)\n",
    "            zStar10 = Viterbi(n, 10, k, np.log(pi1), np.log(Tmat1), np.log(phi10), xNotes)\n",
    "            zStar10 = np.array(zStar10).astype(int)\n",
    "            it3, p1, pi1, phi5, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar5 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi5), xNotes)\n",
    "            zStar5 = np.array(zStar5).astype(int)\n",
    "            z = [zStar15, zStar10, zStar5]\n",
    "            phi1 = [phi15, phi10, phi5]\n",
    "            iterations = it1+it2+it3\n",
    "            t2 = time.time()\n",
    "\n",
    "        for i in range(it):\n",
    "            for j in range(0, n):\n",
    "                noteArray[0,j] = np.random.choice(xstates, size = 1, p = phi15[zStar15[j], :])\n",
    "                noteArray[1,j] = np.random.choice(xstates, size = 1, p = phi10[zStar10[j], :])\n",
    "                noteArray[2,j] = np.random.choice(xstates, size = 1, p = phi5[zStar5[j], :])\n",
    "            temp_notes = np.rint(np.mean(noteArray, axis=0)).astype(int)\n",
    "            temp_notes = decode(temp_notes, possibleNotes)\n",
    "            newNotes = temp_notes\n",
    "            newVelocities = find_vel(newNotes, velocity)\n",
    "            if metrics_calc:\n",
    "                metrics[i+1, :] = calc_metrics(time_metrics, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "\n",
    "\n",
    "    if model == 'layered':\n",
    "        t1 = time.time()\n",
    "        it1, p1, pi1, phi1, Tmat1 = first_order(n, m, k, xNotes, tol)\n",
    "        zStar1 = Viterbi(n, m, k, np.log(pi1), np.log(Tmat1), np.log(phi1), xNotes)\n",
    "        zStar1 = np.array(zStar1).astype(int)\n",
    "        it2, p2, pi2, phi2, Tmat2 = first_order(n, m, m, zStar1, tol)\n",
    "        zStar2 = Viterbi(n, m, m, np.log(pi2), np.log(Tmat2), np.log(phi2), zStar1)\n",
    "        zStar2 = np.array(zStar2).astype(int)\n",
    "        it3, p3, pi3, phi3, Tmat3 = first_order(n, m, m, zStar2, tol)\n",
    "        zStar3 = Viterbi(n, m, m, np.log(pi3), np.log(Tmat3), np.log(phi3), zStar2)\n",
    "        zStar3 = np.array(zStar3).astype(int)\n",
    "        output = np.zeros(shape = (3,n), dtype = int)\n",
    "        z = [zStar1, zStar2, zStar3]\n",
    "        iterations = it1+it2+it3\n",
    "        t2 = time.time()\n",
    "        \n",
    "        xstates = range(0, k)\n",
    "        zstates = range(0, m)\n",
    "        for i in range(it):\n",
    "            for j in range(0,n):\n",
    "                output[2, j] = np.random.choice(zstates, size = 1, p = phi3[zStar3[j], :])\n",
    "                output[1, j] = np.random.choice(zstates, size = 1, p = phi2[output[2, j], :])\n",
    "                output[0, j] = np.random.choice(xstates, size = 1, p = phi1[output[1, j], :])\n",
    "            temp_notes = decode(output[0,:], possibleNotes).astype(int)\n",
    "            newNotes = temp_notes\n",
    "            newVelocities = find_vel(newNotes, velocity)\n",
    "            if metrics_calc:\n",
    "                metrics[i+1, :] = calc_metrics(time_metrics, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "        phi1 = [phi1, phi2, phi3]\n",
    "        \n",
    "\n",
    "    song.iloc[ind, 1] = time_piece\n",
    "    song.iloc[ind, 4] = newNotes\n",
    "    song.iloc[ind, 5] = newVelocities\n",
    "    song.iloc[ind[np.where(newVelocities !=0)], 2] = ' Note_on_c'\n",
    "    song.iloc[ind[np.where(newVelocities ==0)], 2] = ' Note_off_c'\n",
    "    split = output_filename.split('.')\n",
    "    output_filename = split[0] + '__'+ model + '_' + str(m)+  '-tol' +str(tol)+'.' + split[1]\n",
    "    if m2 != None:\n",
    "        output_filename = split[0] + '__'+ model + '_' + str(m)+'-'+str(m2)+ '-tol' +str(tol)+ '.' + split[1]\n",
    "\n",
    "    if metrics_calc:\n",
    "        song_name = split[0].split('/')\n",
    "        metrics_filename = 'metrics/'+song_name[1]+ '__'+ model + '_' + str(m)+  '-tol' +str(tol)+ '.' + split[1] \n",
    "        pd.DataFrame(metrics).to_csv(metrics_filename, header = None, index = False)\n",
    "        print(metrics_filename)\n",
    "    song.to_csv(output_filename, header = None, index = False)\n",
    "    \n",
    "    return(iterations, t2-t1, time_metrics, notes, newNotes, pi1, phi1, Tmat1) #quarter_note, num, denom, key, measures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Original HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "metrics/twinkle-twinkle-little-star__first_order_5-tol0.01.csv\n",
      "first order done\n",
      "metrics/twinkle-twinkle-little-star__random_5-tol0.01.csv\n",
      "random done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "metrics/twinkle-twinkle-little-star__layered_5-tol0.01.csv\n",
      "layered done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "metrics/twinkle-twinkle-little-star__factorial_5-tol0.01.csv\n",
      "factorial done\n",
      "NewCSV/twinkle-twinkle-little-star.csv\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "metrics/book2-fugue07__first_order_5-tol0.01.csv\n",
      "first order done\n",
      "metrics/book2-fugue07__random_5-tol0.01.csv\n",
      "random done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "metrics/book2-fugue07__layered_5-tol0.01.csv\n",
      "layered done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "metrics/book2-fugue07__factorial_5-tol0.01.csv\n",
      "factorial done\n",
      "NewCSV/book2-fugue07.csv\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "metrics/ode-to-joy__first_order_5-tol0.01.csv\n",
      "first order done\n",
      "metrics/ode-to-joy__random_5-tol0.01.csv\n",
      "random done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "metrics/ode-to-joy__layered_5-tol0.01.csv\n",
      "layered done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "metrics/ode-to-joy__factorial_5-tol0.01.csv\n",
      "factorial done\n",
      "NewCSV/ode-to-joy.csv\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "metrics/Jupiter__first_order_5-tol0.01.csv\n",
      "first order done\n",
      "metrics/Jupiter__random_5-tol0.01.csv\n",
      "random done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "metrics/Jupiter__layered_5-tol0.01.csv\n",
      "layered done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "metrics/Jupiter__factorial_5-tol0.01.csv\n",
      "factorial done\n",
      "NewCSV/Jupiter.csv\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "metrics/pachelbel__first_order_5-tol0.01.csv\n",
      "first order done\n",
      "metrics/pachelbel__random_5-tol0.01.csv\n",
      "random done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "metrics/pachelbel__layered_5-tol0.01.csv\n",
      "layered done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "metrics/pachelbel__factorial_5-tol0.01.csv\n",
      "factorial done\n",
      "NewCSV/pachelbel.csv\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "metrics/westworld__first_order_5-tol0.01.csv\n",
      "first order done\n",
      "metrics/westworld__random_5-tol0.01.csv\n",
      "random done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "metrics/westworld__layered_5-tol0.01.csv\n",
      "layered done\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "metrics/westworld__factorial_5-tol0.01.csv\n",
      "factorial done\n",
      "NewCSV/westworld.csv\n"
     ]
    }
   ],
   "source": [
    "orig_list = ['twinkle-twinkle-little-star-orig.csv', 'book2-fugue07.csv', \n",
    "            'beethoven-symphony9-4-ode-to-joy-piano-solo.csv', 'Jupiter.csv', 'pachelbel.csv',\n",
    "            'Ramin_Djawadi_-_Westworld_Theme.csv']\n",
    "new_list = ['twinkle-twinkle-little-star.csv', 'book2-fugue07.csv', 'ode-to-joy.csv', 'Jupiter.csv',\n",
    "           'pachelbel.csv', 'westworld.csv']\n",
    "quarter_note = [256, 64, 128, 64, 64, 80]\n",
    "\n",
    "it_1 = np.zeros(len(orig_list))\n",
    "elapsed_1 = np.zeros(len(orig_list))\n",
    "it_r = np.zeros(len(orig_list))\n",
    "elapsed_r = np.zeros(len(orig_list))\n",
    "it_lay = np.zeros(len(orig_list))\n",
    "elapsed_lay = np.zeros(len(orig_list))\n",
    "it_f = np.zeros(len(orig_list))\n",
    "elapsed_f = np.zeros(len(orig_list))\n",
    "\n",
    "for i in range(len(orig_list)):\n",
    "    oldfile = 'OriginalCSV/' + orig_list[i]\n",
    "    newfile = 'NewCSV/' + new_list[i]\n",
    "    it_1[i], elapsed_1[i], _, old_1, new_1, z_1, phi_1, Tmat_1 = hmm_compose(oldfile, newfile, \n",
    "                                                                                quarter_note[i], 'first_order', \n",
    "                                                         5, 0.01, 1000, None, metrics_calc = True)\n",
    "    print(\"first order done\")\n",
    "    it_r[i], elapsed_r[i], _, old_r, new_r, z_r, phi_r, Tmat_r = hmm_compose(oldfile, newfile, \n",
    "                                                                                 quarter_note[i], 'random', \n",
    "                                                         5, 0.01, 1000, None, metrics_calc = True)\n",
    "    print(\"random done\")\n",
    "    it_lay[i], elapsed_lay[i], _, old_l, new_l, z_l, phi_l, Tmat_l = hmm_compose(oldfile, newfile, \n",
    "                                                                                 quarter_note[i], 'layered', \n",
    "                                                         5, 0.01, 1000, None, metrics_calc = True)\n",
    "    print(\"layered done\")\n",
    "    it_f[i], elapsed_f[i], _, old_f, new_f, z_f, phi_f, Tmat_f = hmm_compose(oldfile, newfile, \n",
    "                                                                                 quarter_note[i], 'factorial', \n",
    "                                                         5, 0.01, 1000, None, metrics_calc = True)\n",
    "    print(\"factorial done\")\n",
    "    print(newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time, old_1, new_1, z_1, phi_1, Tmat_1 = hmm_compose('OriginalCSV/twinkle-twinkle-little-star-orig.csv', \n",
    "#                                                    'NewCSV/twinkle-twinkle-little-star.csv', 256, \n",
    "#                                                    'first_order', 5, 10E-7, 1000, None, metrics_calc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 'OriginalCSV/' + ['twinkle-twinkle-little-star-orig.csv', 'twinkle-twinkle-little-star-orig.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FHMMs\n",
    "\n",
    "### a. M = 3, K = [5, 5, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 532\n",
      "[[ 1.]]\n",
      "[ 54.  61.  59.  61.  66.  56.  52.  50.  45.  47.  64.  50.  69.  52.  59.\n",
      "  67.  66.  56.  45.  59.  61.  67.  54.  62.  59.  50.  67.  62.  59.  52.\n",
      "  67.  54.  47.  67.  57.  52.  52.  50.  47.  57.  62.  66.  69.  62.  57.\n",
      "  57.  54.  56.  62.  59.  61.  52.  62.  61.  52.  57.  45.  45.  59.  69.\n",
      "  50.  59.  52.  46.  56.  45.  69.  62.  57.  69.  61.  50.  69.  52.  59.\n",
      "  57.  69.  69.  61.  50.  50.  56.  50.  69.  47.  59.  56.  61.  54.  67.\n",
      "  54.  69.  56.  46.  56.  52.  47.  57.  59.  54.  61.  62.  54.  59.  69.\n",
      "  46.  50.  50.  67.  57.  47.  56.  45.  69.  59.  57.  57.  54.  57.  52.\n",
      "  59.  64.  56.  50.  62.  69.  61.  66.  62.  50.  52.  61.  57.  57.  59.\n",
      "  56.  62.  54.  69.  47.  56.  62.  47.  57.  62.  52.  67.  61.  59.  54.\n",
      "  59.  62.  47.  54.  52.  52.  62.  56.  52.  61.  54.  54.  59.  69.  52.\n",
      "  57.  62.  54.  56.  59.  59.  47.  57.  66.  56.  61.  52.  50.  54.  66.\n",
      "  46.  45.  50.  45.  57.  59.  62.  56.  61.  45.  59.  69.  57.  61.  61.\n",
      "  69.  59.  62.  50.  64.  59.  52.  64.  61.  50.  50.  59.  69.  56.  61.\n",
      "  59.  57.  56.  59.  54.  50.  54.  62.  64.  62.  59.  57.  59.  61.  59.\n",
      "  59.  59.  64.  57.  64.  61.  57.  61.  66.  54.  52.  47.  64.  57.  61.\n",
      "  57.  46.  66.  50.  50.  50.  57.  56.  57.  69.  50.  59.  67.  61.  52.\n",
      "  54.  67.  69.  50.  64.  54.  54.  59.  50.  59.  64.  59.  61.  56.  59.\n",
      "  52.  57.  67.  59.  61.  67.  59.  62.  52.  61.  64.  50.  50.  52.  62.\n",
      "  67.  69.  69.  54.  52.  52.  62.  57.  62.  62.  50.  47.  54.  57.  50.\n",
      "  61.  59.  59.  54.  62.  56.  69.  56.  52.  45.  45.  67.  61.  69.  52.\n",
      "  57.  62.  50.  50.  57.  52.  57.  57.  69.  61.  50.  62.  59.  69.  61.\n",
      "  62.  54.  45.  45.  57.  47.  64.  50.  54.  66.  56.  62.  69.  52.  62.\n",
      "  57.  54.  66.  46.  50.  69.  61.  69.  69.  45.  54.  52.  45.  62.  54.\n",
      "  59.  57.  57.  57.  54.  66.  61.  59.  57.  45.  66.  62.  62.  54.  45.\n",
      "  59.  50.  52.  69.  54.  69.  54.  59.  50.  64.  50.  64.  62.  66.  45.\n",
      "  45.  47.  54.  56.  61.  45.  62.  57.  64.  50.  59.  64.  64.  64.  62.\n",
      "  52.  67.  50.  59.  47.  69.  54.  56.  47.  62.  54.  52.  57.  61.  56.\n",
      "  62.  67.  67.  62.  57.  57.  54.  54.  50.  64.  64.  62.  52.  50.  45.\n",
      "  69.  56.  57.  50.  62.  45.  62.  52.  45.  67.  64.  61.  56.  47.  67.\n",
      "  50.  62.  47.  56.  52.  57.  69.  69.  61.  69.  57.  67.  56.  67.  64.\n",
      "  59.  64.  67.  59.  64.  61.  67.  50.  45.  62.  62.  59.  61.  52.  57.\n",
      "  64.  50.  59.  57.  61.  62.  45.  54.  64.  66.  47.  61.  52.  69.  66.\n",
      "  67.  62.  59.  57.  50.  52.  59.  59.  59.  64.  69.  57.  57.  64.  69.\n",
      "  61.  64.  61.  56.  69.  69.  66.  59.  69.  59.  47.  54.  47.  46.  45.\n",
      "  61.  52.  52.  66.  62.  57.  64.]\n",
      "metrics/ode-to-joy__FHMMGibbs_3-tol0.01.csv\n",
      "Gibbs Done\n",
      "1 532\n",
      "[[ 1.]]\n",
      "10\n",
      "2.2298455807\n",
      "[ 66.  59.  50.  61.  64.  61.  57.  56.  56.  54.  64.  62.  62.  61.  61.\n",
      "  61.  50.  59.  62.  67.  52.  66.  57.  52.  52.  59.  62.  64.  52.  61.\n",
      "  66.  69.  62.  69.  62.  69.  67.  59.  45.  67.  66.  54.  64.  50.  59.\n",
      "  62.  62.  64.  62.  64.  54.  62.  62.  64.  52.  57.  64.  66.  66.  59.\n",
      "  57.  64.  59.  61.  61.  62.  54.  59.  59.  57.  52.  67.  64.  54.  54.\n",
      "  64.  62.  59.  59.  54.  47.  52.  62.  57.  57.  54.  62.  46.  59.  54.\n",
      "  52.  61.  67.  59.  69.  56.  62.  59.  64.  62.  62.  67.  67.  57.  56.\n",
      "  57.  47.  54.  59.  61.  67.  59.  52.  64.  67.  64.  50.  52.  62.  47.\n",
      "  50.  64.  64.  59.  56.  52.  67.  67.  54.  64.  62.  50.  62.  56.  59.\n",
      "  66.  56.  59.  56.  56.  64.  50.  64.  47.  64.  62.  54.  64.  50.  52.\n",
      "  59.  59.  66.  59.  54.  64.  61.  62.  62.  56.  59.  59.  62.  57.  62.\n",
      "  62.  64.  64.  64.  61.  64.  67.  61.  59.  66.  56.  50.  59.  62.  64.\n",
      "  61.  52.  66.  62.  62.  62.  64.  67.  54.  57.  66.  47.  61.  61.  61.\n",
      "  61.  52.  59.  64.  47.  50.  62.  61.  57.  64.  57.  59.  64.  56.  62.\n",
      "  59.  54.  54.  69.  59.  62.  57.  61.  62.  59.  69.  64.  62.  56.  57.\n",
      "  64.  52.  64.  52.  54.  64.  69.  47.  62.  59.  50.  61.  50.  64.  52.\n",
      "  54.  57.  69.  69.  57.  57.  56.  54.  59.  64.  64.  64.  59.  50.  66.\n",
      "  59.  62.  59.  64.  62.  59.  69.  67.  59.  67.  61.  62.  52.  67.  62.\n",
      "  59.  62.  54.  64.  45.  50.  50.  62.  54.  52.  57.  64.  57.  64.  50.\n",
      "  62.  64.  64.  61.  57.  69.  64.  62.  59.  57.  62.  59.  61.  54.  61.\n",
      "  62.  67.  52.  66.  61.  59.  57.  64.  67.  54.  57.  52.  64.  57.  62.\n",
      "  62.  54.  56.  52.  52.  57.  57.  59.  66.  66.  64.  61.  66.  62.  57.\n",
      "  59.  64.  62.  64.  59.  50.  66.  61.  69.  64.  45.  56.  52.  59.  47.\n",
      "  52.  61.  64.  61.  64.  59.  66.  47.  59.  59.  61.  57.  69.  59.  50.\n",
      "  54.  59.  67.  54.  62.  62.  61.  61.  67.  62.  67.  69.  56.  62.  59.\n",
      "  59.  47.  62.  64.  57.  67.  59.  64.  64.  64.  59.  54.  45.  61.  59.\n",
      "  62.  61.  62.  62.  67.  59.  57.  64.  67.  67.  64.  64.  62.  62.  69.\n",
      "  64.  62.  59.  50.  47.  57.  62.  64.  61.  67.  62.  54.  50.  62.  59.\n",
      "  56.  69.  61.  69.  54.  54.  62.  61.  66.  59.  56.  56.  52.  64.  62.\n",
      "  57.  62.  62.  61.  56.  52.  67.  67.  61.  64.  59.  52.  69.  57.  66.\n",
      "  57.  54.  62.  61.  45.  64.  62.  67.  59.  69.  61.  61.  62.  46.  59.\n",
      "  66.  62.  61.  67.  62.  69.  69.  47.  54.  66.  62.  62.  62.  56.  50.\n",
      "  64.  61.  59.  59.  62.  54.  67.  62.  62.  59.  66.  64.  62.  45.  45.\n",
      "  52.  64.  54.  64.  47.  61.  69.  66.  47.  56.  64.  64.  59.  59.  57.\n",
      "  67.  59.  64.  66.  47.  66.  54.  59.  62.  57.  59.  64.  66.  57.  62.\n",
      "  57.  64.  57.  64.  52.  66.  62.]\n",
      "metrics/ode-to-joy__FHMMFactorizedVI_3-tol0.01.csv\n",
      "Factorized Done\n",
      "1 532\n",
      "[[ 1.]]\n",
      "10\n",
      "0.342421203123\n",
      "20\n",
      "0.165818999497\n",
      "[ 62.  66.  62.  67.  62.  67.  50.  62.  67.  64.  64.  56.  62.  62.  67.\n",
      "  47.  50.  47.  57.  64.  54.  61.  45.  45.  54.  57.  61.  46.  45.  54.\n",
      "  64.  45.  56.  62.  47.  59.  64.  52.  64.  47.  61.  67.  47.  57.  67.\n",
      "  54.  64.  54.  64.  52.  61.  57.  62.  59.  62.  62.  46.  57.  61.  56.\n",
      "  64.  62.  67.  62.  64.  47.  50.  59.  64.  59.  64.  59.  67.  59.  64.\n",
      "  46.  62.  64.  50.  61.  59.  59.  52.  62.  62.  64.  50.  54.  64.  54.\n",
      "  59.  56.  47.  64.  69.  47.  62.  66.  57.  67.  66.  61.  61.  69.  62.\n",
      "  66.  50.  52.  61.  56.  64.  62.  62.  62.  67.  64.  67.  50.  59.  67.\n",
      "  57.  64.  56.  62.  54.  67.  45.  57.  61.  50.  64.  67.  54.  62.  56.\n",
      "  62.  47.  54.  66.  54.  62.  47.  64.  67.  46.  56.  61.  59.  67.  64.\n",
      "  67.  47.  57.  59.  47.  64.  64.  62.  66.  56.  59.  54.  62.  54.  59.\n",
      "  56.  62.  57.  57.  64.  66.  54.  66.  64.  64.  62.  66.  57.  62.  59.\n",
      "  64.  57.  66.  50.  54.  59.  57.  61.  54.  66.  61.  59.  56.  62.  57.\n",
      "  62.  56.  62.  59.  64.  61.  66.  57.  61.  59.  67.  61.  69.  46.  62.\n",
      "  66.  50.  62.  67.  62.  66.  54.  66.  56.  64.  64.  66.  62.  64.  56.\n",
      "  62.  50.  61.  69.  57.  64.  50.  61.  69.  56.  64.  47.  59.  69.  66.\n",
      "  66.  50.  61.  66.  47.  56.  59.  62.  47.  45.  47.  57.  66.  57.  64.\n",
      "  64.  64.  46.  57.  57.  47.  50.  61.  67.  62.  64.  64.  62.  69.  64.\n",
      "  67.  61.  64.  47.  50.  59.  62.  59.  66.  62.  69.  57.  64.  54.  62.\n",
      "  52.  66.  57.  62.  52.  62.  45.  47.  61.  69.  45.  62.  62.  45.  52.\n",
      "  62.  52.  62.  54.  66.  62.  62.  57.  67.  59.  64.  46.  47.  64.  64.\n",
      "  62.  67.  46.  59.  66.  64.  67.  64.  67.  62.  67.  62.  66.  54.  67.\n",
      "  56.  57.  56.  67.  54.  66.  50.  47.  47.  62.  66.  61.  66.  66.  67.\n",
      "  59.  62.  50.  62.  67.  46.  45.  61.  62.  66.  64.  54.  64.  62.  64.\n",
      "  62.  66.  45.  52.  61.  46.  46.  54.  62.  57.  64.  54.  62.  50.  56.\n",
      "  64.  54.  62.  54.  59.  62.  66.  62.  64.  50.  64.  67.  46.  45.  50.\n",
      "  62.  67.  46.  61.  67.  50.  56.  52.  64.  57.  64.  46.  47.  59.  64.\n",
      "  62.  66.  46.  52.  59.  59.  64.  47.  56.  54.  64.  54.  66.  46.  66.\n",
      "  64.  50.  59.  67.  54.  64.  52.  64.  54.  62.  54.  62.  50.  64.  61.\n",
      "  64.  50.  50.  57.  59.  57.  62.  66.  64.  69.  67.  47.  47.  46.  56.\n",
      "  64.  45.  64.  69.  62.  69.  62.  62.  47.  47.  66.  64.  57.  62.  52.\n",
      "  62.  57.  62.  56.  59.  47.  62.  64.  45.  54.  62.  69.  46.  54.  61.\n",
      "  46.  64.  64.  47.  62.  66.  50.  62.  66.  47.  57.  62.  54.  64.  54.\n",
      "  45.  50.  61.  66.  59.  64.  59.  66.  47.  56.  62.  56.  61.  50.  54.\n",
      "  62.  56.  66.  52.  64.  59.  47.  62.  66.  62.  62.  46.  45.  56.  64.\n",
      "  46.  45.  46.  62.  64.  54.  59.]\n",
      "metrics/ode-to-joy__FHMMStructuralVI_3-tol0.01.csv\n",
      "Structural Done\n",
      "NewCSV/ode-to-joy.csv\n",
      "1 1168\n",
      "[[ 1.]]\n",
      "10\n",
      "2.24407855438\n",
      "20\n",
      "0.56970807292\n",
      "30\n",
      "1.74981361061\n",
      "40\n",
      "0.900045916601\n",
      "50\n",
      "0.312547905741\n",
      "60\n",
      "0.374837137788\n",
      "70\n",
      "0.47924640869\n",
      "80\n",
      "0.635598493302\n",
      "90\n",
      "0.0849975233877\n",
      "100\n",
      "0.296365516445\n",
      "110\n",
      "0.0652486830748\n",
      "120\n",
      "1.80480799977\n",
      "130\n",
      "0.732539475293\n",
      "140\n",
      "0.61025033045\n",
      "150\n",
      "1.98576638428\n",
      "160\n",
      "0.758626207469\n",
      "170\n",
      "1.35541567552\n",
      "180\n",
      "1.32672508875\n",
      "190\n",
      "3.57898563123\n",
      "200\n",
      "0.834835825987\n",
      "210\n",
      "1.84982351173\n",
      "220\n",
      "0.446534117264\n",
      "230\n",
      "0.174817998758\n",
      "240\n",
      "1.9358314622\n",
      "250\n",
      "1.64300289295\n",
      "260\n",
      "1.37473575247\n",
      "270\n",
      "0.162607359499\n",
      "280\n",
      "1.09831430076\n",
      "290\n",
      "0.812264701788\n",
      "300\n",
      "1.50739307149\n",
      "310\n",
      "0.893755546005\n",
      "320\n",
      "0.517150281224\n",
      "330\n",
      "1.0901716131\n",
      "340\n",
      "2.81075663223\n",
      "[ 44.  63.  60. ...,  67.  58.  65.]\n",
      "metrics/Jupiter__FHMMGibbs_3-tol0.01.csv\n",
      "Gibbs Done\n",
      "1 1168\n",
      "[[ 1.]]\n",
      "10\n",
      "1.44947404156\n",
      "20\n",
      "0.320053733285\n",
      "[ 72.  58.  67. ...,  68.  67.  65.]\n",
      "metrics/Jupiter__FHMMFactorizedVI_3-tol0.01.csv\n",
      "Factorized Done\n",
      "1 1168\n",
      "[[ 1.]]\n",
      "10\n",
      "0.19976731983\n",
      "20\n",
      "0.427585045475\n",
      "30\n",
      "0.0184902368292\n",
      "[ 56.  60.  63. ...,  62.  55.  58.]\n",
      "metrics/Jupiter__FHMMStructuralVI_3-tol0.01.csv\n",
      "Structural Done\n",
      "NewCSV/Jupiter.csv\n",
      "1 1050\n",
      "[[ 1.]]\n",
      "[ 61.  45.  71. ...,  66.  45.  62.]\n",
      "metrics/pachelbel__FHMMGibbs_3-tol0.01.csv\n",
      "Gibbs Done\n",
      "1 1050\n",
      "[[ 1.]]\n",
      "10\n",
      "0.534167346714\n",
      "20\n",
      "0.633245520727\n",
      "30\n",
      "3.30554690964\n",
      "[ 59.  72.  74. ...,  64.  71.  79.]\n",
      "metrics/pachelbel__FHMMFactorizedVI_3-tol0.01.csv\n",
      "Factorized Done\n",
      "1 1050\n",
      "[[ 1.]]\n",
      "10\n",
      "0.778873471304\n",
      "20\n",
      "1.59499919253\n",
      "30\n",
      "0.881166490667\n",
      "40\n",
      "0.0230979189157\n",
      "50\n",
      "0.0627949235435\n",
      "60\n",
      "0.0201041025439\n",
      "70\n",
      "0.016322513166\n",
      "80\n",
      "0.0207465374329\n",
      "90\n",
      "0.032765859624\n",
      "100\n",
      "0.0511845543403\n",
      "110\n",
      "0.0374343082454\n",
      "[ 64.  61.  62. ...,  43.  50.  55.]\n",
      "metrics/pachelbel__FHMMStructuralVI_3-tol0.01.csv\n",
      "Structural Done\n",
      "NewCSV/pachelbel.csv\n",
      "1 1164\n",
      "[[ 1.]]\n",
      "10\n",
      "1.92273975655\n",
      "20\n",
      "0.214613237571\n",
      "30\n",
      "0.206624663882\n",
      "40\n",
      "0.56047864578\n",
      "50\n",
      "3.26638176244\n",
      "60\n",
      "0.966579093135\n",
      "70\n",
      "5.19389620255\n",
      "80\n",
      "2.57432737214\n",
      "90\n",
      "0.049579756337\n",
      "100\n",
      "0.448741957644\n",
      "110\n",
      "1.35626224814\n",
      "120\n",
      "1.52525923322\n",
      "130\n",
      "0.788279986911\n",
      "140\n",
      "3.75730442796\n",
      "150\n",
      "4.83819155624\n",
      "160\n",
      "5.10720358695\n",
      "170\n",
      "2.90016899875\n",
      "180\n",
      "1.82141253494\n",
      "190\n",
      "0.722570872389\n",
      "200\n",
      "1.53635440363\n",
      "210\n",
      "0.159022408143\n",
      "220\n",
      "4.71350086554\n",
      "230\n",
      "0.630191240955\n",
      "240\n",
      "0.86644300916\n",
      "250\n",
      "1.22731782308\n",
      "260\n",
      "1.45363193187\n",
      "270\n",
      "0.917141956817\n",
      "280\n",
      "2.65797333931\n",
      "290\n",
      "1.9908168736\n",
      "300\n",
      "2.14352034764\n",
      "310\n",
      "0.310722930259\n",
      "320\n",
      "4.36476071024\n",
      "330\n",
      "0.691098326308\n",
      "340\n",
      "1.34982795735\n",
      "350\n",
      "1.54111126409\n",
      "360\n",
      "0.615779490039\n",
      "370\n",
      "3.26654512387\n",
      "380\n",
      "1.30546485982\n",
      "390\n",
      "2.88609739083\n",
      "400\n",
      "2.69698040454\n",
      "410\n",
      "1.6780363038\n",
      "420\n",
      "0.00402440010004\n",
      "[ 29.  65.  34. ...,  60.  71.  28.]\n",
      "metrics/westworld__FHMMGibbs_3-tol0.01.csv\n",
      "Gibbs Done\n",
      "1 1164\n",
      "[[ 1.]]\n",
      "10\n",
      "0.219671795322\n",
      "20\n",
      "0.545549961396\n",
      "30\n",
      "0.107234105543\n",
      "40\n",
      "0.0940894470111\n",
      "[ 48.  43.  33. ...,  52.  38.  53.]\n",
      "metrics/westworld__FHMMFactorizedVI_3-tol0.01.csv\n",
      "Factorized Done\n",
      "1 1164\n",
      "[[ 1.]]\n",
      "10\n",
      "1.29859343256\n",
      "20\n",
      "1.11859471503\n",
      "30\n",
      "0.317227940768\n",
      "40\n",
      "0.0413315604926\n",
      "[ 44.  29.  38. ...,  52.  55.  53.]\n",
      "metrics/westworld__FHMMStructuralVI_3-tol0.01.csv\n",
      "Structural Done\n",
      "NewCSV/westworld.csv\n",
      "1 180\n",
      "[[ 1.]]\n",
      "10\n",
      "0.192121072483\n",
      "[ 57.  67.  43.  62.  57.  60.  69.  55.  55.  62.  55.  48.  69.  52.  52.\n",
      "  52.  48.  69.  60.  67.  55.  60.  57.  65.  60.  52.  48.  62.  48.  60.\n",
      "  52.  69.  62.  55.  60.  60.  55.  52.  52.  62.  60.  65.  48.  67.  60.\n",
      "  55.  48.  52.  48.  57.  64.  55.  52.  43.  65.  43.  60.  60.  64.  62.\n",
      "  48.  55.  55.  67.  57.  62.  41.  48.  48.  55.  60.  48.  48.  52.  43.\n",
      "  65.  57.  55.  69.  55.  62.  52.  65.  55.  60.  60.  60.  55.  52.  48.\n",
      "  48.  57.  52.  60.  52.  62.  69.  48.  41.  55.  48.  65.  64.  55.  55.\n",
      "  60.  69.  48.  69.  52.  69.  65.  65.  65.  57.  55.  48.  48.  55.  67.\n",
      "  55.  57.  69.  64.  43.  52.  65.  57.  48.  60.  62.  57.  55.  65.  57.\n",
      "  57.  60.  62.  57.  69.  57.  55.  60.  52.  57.  55.  69.  67.  52.  60.\n",
      "  48.  55.  60.  64.  55.  62.  65.  65.  64.  69.  57.  55.  43.  52.  57.\n",
      "  48.  52.  52.  57.  55.  55.  48.  48.  65.  60.  65.  48.  64.  62.  62.]\n",
      "metrics/twinkle-twinkle-little-star__FHMMGibbs_3-tol0.01.csv\n",
      "Gibbs Done\n",
      "1 180\n",
      "[[ 1.]]\n",
      "10\n",
      "4.46848020911\n",
      "20\n",
      "0.0927846283397\n",
      "30\n",
      "0.0101261756505\n",
      "[ 62.  52.  52.  60.  62.  52.  64.  62.  55.  55.  65.  69.  57.  57.  62.\n",
      "  62.  69.  69.  60.  55.  60.  64.  60.  65.  57.  60.  62.  62.  62.  52.\n",
      "  57.  62.  65.  69.  60.  55.  69.  67.  62.  55.  67.  62.  62.  60.  67.\n",
      "  62.  62.  52.  57.  64.  60.  55.  57.  65.  62.  57.  64.  62.  65.  65.\n",
      "  60.  62.  67.  55.  60.  60.  55.  60.  57.  64.  65.  62.  55.  52.  57.\n",
      "  55.  52.  55.  65.  65.  57.  43.  67.  62.  62.  55.  65.  65.  55.  57.\n",
      "  67.  55.  67.  60.  69.  69.  57.  65.  60.  65.  57.  60.  65.  65.  60.\n",
      "  57.  69.  64.  62.  60.  55.  65.  65.  55.  55.  69.  62.  69.  65.  52.\n",
      "  60.  55.  64.  52.  55.  64.  48.  60.  62.  55.  62.  60.  55.  60.  69.\n",
      "  55.  57.  55.  62.  62.  65.  60.  64.  65.  55.  65.  67.  65.  52.  62.\n",
      "  65.  62.  55.  52.  60.  60.  65.  64.  60.  55.  60.  65.  60.  62.  65.\n",
      "  60.  60.  60.  62.  62.  60.  62.  55.  57.  48.  60.  64.  65.  55.  64.]\n",
      "metrics/twinkle-twinkle-little-star__FHMMFactorizedVI_3-tol0.01.csv\n",
      "Factorized Done\n",
      "1 180\n",
      "[[ 1.]]\n",
      "[ 60.  41.  64.  57.  43.  64.  60.  62.  57.  43.  64.  60.  60.  65.  52.\n",
      "  41.  65.  55.  60.  43.  65.  52.  43.  64.  62.  62.  52.  48.  62.  67.\n",
      "  60.  48.  62.  55.  48.  64.  67.  60.  62.  55.  48.  62.  60.  55.  41.\n",
      "  67.  57.  43.  65.  57.  43.  62.  62.  60.  55.  48.  62.  55.  43.  64.\n",
      "  60.  43.  64.  65.  55.  48.  62.  60.  43.  62.  65.  55.  48.  60.  62.\n",
      "  67.  55.  41.  67.  57.  41.  62.  62.  69.  57.  48.  69.  67.  55.  48.\n",
      "  62.  65.  67.  60.  57.  48.  65.  52.  43.  69.  65.  57.  43.  64.  62.\n",
      "  62.  43.  67.  62.  60.  41.  65.  69.  62.  60.  48.  65.  62.  60.  43.\n",
      "  67.  62.  60.  60.  48.  67.  65.  57.  48.  65.  64.  65.  55.  48.  64.\n",
      "  55.  43.  62.  65.  55.  43.  64.  64.  65.  55.  41.  69.  62.  65.  52.\n",
      "  48.  62.  57.  55.  41.  62.  64.  55.  48.  62.  60.  48.  62.  62.  43.\n",
      "  69.  57.  41.  64.  67.  55.  48.  69.  55.  48.  69.  60.  62.  60.  43.]\n",
      "metrics/twinkle-twinkle-little-star__FHMMStructuralVI_3-tol0.01.csv\n",
      "Structural Done\n",
      "NewCSV/twinkle-twinkle-little-star.csv\n"
     ]
    }
   ],
   "source": [
    "# # 'book2-fugue07.csv', \n",
    "# # 'book2-fugue07.csv', \n",
    "# # 64, \n",
    "# orig_list = ['beethoven-symphony9-4-ode-to-joy-piano-solo.csv', 'Jupiter.csv', \n",
    "#              'pachelbel.csv', 'Ramin_Djawadi_-_Westworld_Theme.csv', 'twinkle-twinkle-little-star-orig.csv']\n",
    "# new_list = ['ode-to-joy.csv', 'Jupiter.csv','pachelbel.csv', 'westworld.csv', \n",
    "#             'twinkle-twinkle-little-star.csv']\n",
    "# quarter_note = [128, 64, 64, 80, 256]\n",
    "# M = 3\n",
    "# K = np.array([5, 5, 5])\n",
    "\n",
    "# it_G = np.zeros(len(orig_list))\n",
    "# elapsed_G = np.zeros(len(orig_list))\n",
    "# it_F = np.zeros(len(orig_list))\n",
    "# elapsed_F = np.zeros(len(orig_list))\n",
    "# it_S = np.zeros(len(orig_list))\n",
    "# elapsed_S = np.zeros(len(orig_list))\n",
    "\n",
    "# for i in range(len(orig_list)):\n",
    "#     oldfile = 'OriginalCSV/' + orig_list[i]\n",
    "#     newfile = 'NewCSV/' + new_list[i]\n",
    "#     it_G[i], elapsed_G[i], timeT, notes, newNotes_G, params_G = FHMM_compose(oldfile, newfile, quarter_note[i], \n",
    "#                                                                       \"FHMM\", \"Gibbs\", None, \n",
    "#                                                  M, K, 0.01, 1000, metrics_calc = True)\n",
    "#     print(\"Gibbs Done\")\n",
    "#     it_F[i], elapsed_F[i], timeT, notes, newNotes_F, params_F = FHMM_compose(oldfile, newfile, quarter_note[i], \n",
    "#                                                                       \"FHMM\", \"FactorizedVI\", None, \n",
    "#                                                  M, K, 0.01, 1000, metrics_calc = True)\n",
    "#     print(\"Factorized Done\")\n",
    "#     it_S[i], elapsed_S[i], timeT, notes, newNotes_S, params_S = FHMM_compose(oldfile, newfile, quarter_note[i], \n",
    "#                                                                           \"FHMM\", \"StructuralVI\", None, \n",
    "#                                                  M, K, 0.01, 1000, metrics_calc = True)\n",
    "#     print(\"Structural Done\")\n",
    "#     print(newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 532\n",
      "[[ 1.]]\n",
      "10\n",
      "0.100133837284\n",
      "[ 47.  52.  50.  62.  54.  46.  59.  50.  54.  52.  52.  59.  47.  69.  57.\n",
      "  66.  52.  62.  59.  62.  62.  50.  47.  59.  66.  50.  59.  59.  57.  52.\n",
      "  69.  59.  50.  62.  67.  59.  50.  50.  45.  52.  47.  50.  57.  54.  62.\n",
      "  62.  46.  67.  54.  57.  62.  54.  67.  61.  54.  59.  67.  62.  59.  64.\n",
      "  62.  69.  67.  52.  64.  62.  57.  67.  69.  47.  54.  66.  50.  69.  52.\n",
      "  54.  57.  69.  52.  46.  54.  57.  56.  50.  54.  54.  56.  67.  52.  67.\n",
      "  66.  50.  69.  69.  67.  47.  64.  64.  50.  62.  57.  52.  57.  54.  61.\n",
      "  57.  61.  54.  50.  62.  45.  69.  62.  54.  61.  66.  45.  57.  62.  61.\n",
      "  67.  57.  59.  59.  57.  59.  50.  50.  61.  56.  62.  54.  54.  69.  59.\n",
      "  45.  54.  52.  69.  54.  57.  50.  52.  67.  45.  57.  50.  50.  54.  59.\n",
      "  47.  59.  52.  46.  64.  54.  54.  52.  45.  45.  52.  54.  69.  64.  57.\n",
      "  45.  50.  61.  50.  57.  62.  57.  54.  67.  50.  64.  56.  57.  59.  67.\n",
      "  57.  46.  57.  64.  62.  45.  59.  50.  69.  57.  62.  64.  67.  57.  67.\n",
      "  45.  45.  61.  57.  52.  52.  50.  69.  64.  57.  64.  59.  50.  45.  69.\n",
      "  52.  46.  50.  54.  59.  45.  57.  69.  62.  45.  57.  59.  50.  56.  59.\n",
      "  45.  50.  59.  45.  50.  57.  61.  57.  66.  52.  50.  61.  56.  64.  47.\n",
      "  69.  50.  61.  46.  52.  47.  54.  50.  61.  52.  54.  62.  62.  66.  59.\n",
      "  61.  64.  62.  62.  45.  54.  54.  47.  50.  52.  57.  52.  69.  54.  62.\n",
      "  50.  47.  52.  69.  54.  45.  50.  57.  66.  50.  50.  52.  59.  50.  69.\n",
      "  52.  47.  54.  69.  50.  59.  66.  62.  52.  69.  61.  56.  56.  64.  62.\n",
      "  64.  62.  57.  57.  69.  52.  61.  67.  69.  62.  69.  52.  64.  59.  59.\n",
      "  54.  67.  59.  57.  59.  46.  50.  66.  50.  61.  69.  59.  45.  54.  66.\n",
      "  50.  57.  67.  62.  45.  64.  64.  47.  54.  59.  69.  45.  57.  57.  66.\n",
      "  54.  57.  54.  57.  50.  57.  62.  67.  57.  59.  50.  64.  56.  50.  67.\n",
      "  69.  45.  59.  50.  57.  67.  45.  50.  59.  69.  47.  45.  69.  61.  54.\n",
      "  52.  52.  45.  54.  62.  50.  50.  59.  69.  57.  69.  54.  47.  50.  54.\n",
      "  50.  54.  62.  52.  67.  62.  56.  47.  62.  61.  47.  50.  62.  52.  67.\n",
      "  54.  57.  69.  57.  50.  62.  54.  50.  62.  66.  50.  62.  57.  54.  50.\n",
      "  50.  69.  62.  57.  59.  69.  62.  54.  59.  59.  62.  66.  54.  56.  57.\n",
      "  50.  59.  56.  50.  62.  67.  59.  62.  50.  59.  52.  45.  56.  52.  59.\n",
      "  54.  67.  59.  47.  50.  61.  45.  64.  50.  45.  52.  45.  45.  50.  47.\n",
      "  57.  64.  54.  62.  47.  62.  59.  52.  66.  50.  57.  59.  69.  50.  59.\n",
      "  62.  64.  62.  59.  54.  69.  56.  59.  57.  62.  69.  50.  67.  66.  64.\n",
      "  56.  45.  64.  56.  62.  54.  69.  57.  59.  62.  66.  45.  64.  54.  45.\n",
      "  62.  62.  64.  64.  52.  67.  62.  61.  52.  47.  54.  64.  54.  59.  61.\n",
      "  69.  50.  57.  56.  59.  64.  69.]\n",
      "Gibbs Done\n",
      "1 532\n",
      "[[ 1.]]\n",
      "10\n",
      "0.637998691726\n",
      "[ 59.  56.  64.  62.  61.  61.  64.  64.  61.  62.  54.  56.  62.  69.  61.\n",
      "  64.  56.  64.  62.  52.  50.  50.  52.  54.  54.  69.  64.  62.  67.  61.\n",
      "  69.  64.  67.  69.  47.  57.  52.  59.  66.  62.  54.  56.  62.  64.  64.\n",
      "  62.  59.  50.  64.  64.  62.  64.  47.  62.  59.  64.  64.  62.  67.  69.\n",
      "  59.  64.  57.  52.  50.  66.  56.  47.  61.  62.  61.  57.  62.  47.  64.\n",
      "  54.  47.  57.  67.  62.  50.  52.  67.  56.  50.  57.  62.  64.  62.  57.\n",
      "  62.  54.  59.  57.  61.  62.  62.  67.  61.  54.  57.  54.  67.  54.  52.\n",
      "  59.  62.  59.  59.  64.  59.  47.  64.  64.  64.  64.  56.  67.  50.  67.\n",
      "  57.  64.  54.  64.  62.  47.  59.  61.  62.  50.  59.  62.  59.  67.  56.\n",
      "  62.  67.  62.  59.  64.  54.  56.  59.  64.  64.  54.  64.  57.  64.  54.\n",
      "  52.  67.  64.  62.  64.  59.  61.  59.  62.  47.  61.  66.  62.  67.  61.\n",
      "  62.  64.  54.  52.  59.  62.  66.  57.  64.  62.  50.  62.  52.  61.  69.\n",
      "  62.  62.  64.  64.  66.  50.  59.  47.  67.  66.  64.  57.  47.  66.  64.\n",
      "  50.  66.  66.  64.  64.  69.  62.  62.  62.  64.  64.  64.  50.  62.  54.\n",
      "  50.  54.  66.  64.  56.  47.  61.  69.  66.  67.  62.  64.  59.  59.  61.\n",
      "  61.  66.  59.  64.  64.  66.  50.  66.  64.  62.  62.  59.  64.  64.  62.\n",
      "  62.  59.  56.  57.  56.  50.  59.  61.  62.  57.  59.  54.  54.  59.  67.\n",
      "  59.  54.  45.  64.  69.  57.  64.  64.  56.  64.  59.  62.  61.  62.  50.\n",
      "  47.  62.  64.  47.  47.  64.  62.  50.  56.  66.  57.  61.  54.  64.  54.\n",
      "  59.  59.  61.  64.  64.  57.  62.  62.  57.  52.  62.  52.  45.  62.  62.\n",
      "  61.  50.  47.  61.  67.  67.  59.  66.  64.  52.  67.  62.  56.  59.  59.\n",
      "  59.  64.  64.  66.  62.  59.  59.  56.  64.  62.  64.  59.  56.  64.  59.\n",
      "  62.  57.  62.  56.  57.  67.  62.  66.  67.  50.  62.  62.  59.  47.  56.\n",
      "  59.  59.  67.  64.  59.  50.  50.  64.  66.  57.  56.  54.  67.  67.  64.\n",
      "  62.  59.  67.  59.  69.  61.  59.  52.  62.  62.  64.  64.  62.  52.  54.\n",
      "  67.  57.  62.  59.  52.  62.  64.  59.  54.  56.  54.  67.  64.  59.  57.\n",
      "  61.  56.  59.  56.  61.  61.  62.  57.  62.  50.  64.  56.  62.  64.  54.\n",
      "  56.  59.  59.  64.  46.  56.  50.  52.  50.  62.  67.  54.  64.  66.  61.\n",
      "  64.  67.  64.  62.  62.  52.  59.  56.  59.  57.  52.  59.  57.  59.  66.\n",
      "  59.  61.  62.  64.  62.  57.  61.  64.  69.  62.  66.  57.  59.  57.  62.\n",
      "  57.  59.  62.  62.  64.  61.  66.  62.  64.  57.  67.  50.  59.  67.  62.\n",
      "  47.  64.  62.  67.  64.  59.  62.  59.  57.  64.  61.  64.  62.  59.  62.\n",
      "  69.  66.  54.  62.  59.  62.  59.  64.  61.  59.  62.  52.  62.  59.  54.\n",
      "  64.  64.  64.  54.  64.  56.  67.  56.  67.  62.  69.  64.  62.  64.  57.\n",
      "  57.  62.  52.  56.  56.  54.  67.  66.  64.  64.  57.  62.  61.  69.  59.\n",
      "  64.  59.  62.  69.  64.  66.  64.]\n",
      "Factorized Done\n",
      "1 532\n",
      "[[ 1.]]\n",
      "10\n",
      "0.892040127501\n",
      "20\n",
      "0.316868611665\n",
      "[ 64.  67.  52.  57.  56.  67.  57.  62.  56.  56.  62.  50.  52.  62.  56.\n",
      "  64.  59.  62.  47.  62.  66.  66.  69.  50.  46.  56.  62.  47.  67.  67.\n",
      "  54.  64.  54.  64.  54.  59.  47.  46.  61.  64.  64.  66.  47.  56.  62.\n",
      "  50.  62.  54.  64.  56.  64.  50.  62.  67.  47.  56.  61.  56.  57.  57.\n",
      "  64.  54.  64.  59.  59.  62.  54.  64.  56.  67.  52.  66.  56.  64.  57.\n",
      "  59.  52.  64.  64.  67.  57.  64.  57.  64.  57.  62.  62.  59.  67.  62.\n",
      "  67.  62.  64.  46.  62.  67.  61.  67.  47.  64.  69.  54.  64.  57.  62.\n",
      "  54.  64.  57.  61.  45.  56.  61.  54.  62.  54.  64.  47.  62.  66.  62.\n",
      "  61.  67.  66.  61.  66.  64.  69.  59.  69.  50.  62.  67.  47.  64.  67.\n",
      "  47.  46.  50.  50.  50.  56.  66.  66.  64.  52.  62.  64.  64.  69.  50.\n",
      "  57.  62.  50.  64.  66.  62.  62.  56.  62.  59.  54.  66.  62.  67.  54.\n",
      "  66.  54.  64.  47.  59.  61.  69.  67.  66.  47.  45.  54.  59.  59.  66.\n",
      "  64.  67.  47.  62.  67.  67.  67.  47.  62.  64.  61.  66.  62.  67.  46.\n",
      "  56.  66.  45.  52.  62.  50.  64.  67.  66.  67.  47.  54.  59.  50.  50.\n",
      "  46.  57.  50.  47.  62.  67.  62.  67.  47.  57.  66.  47.  50.  56.  59.\n",
      "  67.  64.  67.  59.  66.  57.  61.  57.  59.  57.  62.  64.  69.  64.  66.\n",
      "  57.  54.  66.  57.  64.  47.  54.  62.  57.  59.  64.  62.  62.  66.  45.\n",
      "  50.  62.  64.  45.  66.  66.  62.  67.  59.  66.  59.  69.  47.  54.  64.\n",
      "  56.  61.  56.  62.  50.  54.  46.  54.  66.  46.  62.  67.  62.  66.  54.\n",
      "  64.  59.  64.  46.  50.  62.  64.  66.  61.  67.  64.  67.  64.  62.  46.\n",
      "  52.  61.  62.  64.  47.  62.  64.  59.  67.  54.  62.  54.  64.  62.  67.\n",
      "  62.  66.  47.  50.  59.  67.  50.  54.  62.  56.  64.  52.  62.  54.  59.\n",
      "  54.  61.  54.  64.  46.  64.  67.  56.  62.  54.  62.  45.  62.  67.  47.\n",
      "  64.  69.  50.  59.  62.  64.  67.  50.  47.  59.  66.  62.  67.  61.  66.\n",
      "  64.  66.  47.  50.  62.  67.  59.  64.  61.  66.  46.  46.  47.  59.  69.\n",
      "  47.  52.  64.  59.  64.  54.  62.  54.  59.  57.  62.  59.  67.  45.  54.\n",
      "  61.  54.  62.  52.  59.  52.  64.  57.  64.  57.  62.  50.  67.  62.  69.\n",
      "  62.  69.  46.  45.  64.  67.  61.  64.  47.  47.  64.  64.  62.  66.  57.\n",
      "  64.  67.  67.  59.  62.  64.  64.  54.  52.  64.  46.  57.  61.  54.  61.\n",
      "  46.  61.  67.  50.  47.  62.  69.  45.  64.  64.  66.  69.  47.  50.  56.\n",
      "  62.  47.  64.  67.  62.  66.  57.  62.  57.  64.  47.  64.  64.  54.  62.\n",
      "  47.  50.  64.  62.  46.  46.  54.  66.  52.  57.  66.  56.  64.  59.  54.\n",
      "  61.  64.  62.  69.  59.  62.  62.  64.  62.  66.  52.  59.  62.  62.  64.\n",
      "  66.  56.  62.  59.  62.  67.  50.  47.  57.  64.  57.  59.  52.  62.  50.\n",
      "  64.  56.  62.  54.  62.  62.  67.  62.  62.  50.  54.  59.  47.  59.  67.\n",
      "  46.  45.  47.  50.  47.  54.  61.]\n",
      "Structural Done\n",
      "[ 57.  57.  54.  57.  62.  57.  57.  54.  59.  54.  59.  59.  56.  57.  54.\n",
      "  56.  59.  57.  57.  59.  59.  57.  62.  59.  54.  54.  61.  59.  57.  57.\n",
      "  57.  54.  59.  57.  57.  52.  62.  59.  54.  56.  56.  56.  59.  54.  52.\n",
      "  57.  54.  62.  59.  57.  52.  54.  61.  59.  54.  57.  59.  56.  57.  54.\n",
      "  57.  59.  56.  57.  62.  57.  57.  59.  57.  54.  56.  57.  57.  59.  59.\n",
      "  56.  57.  57.  59.  59.  59.  59.  56.  59.  50.  61.  57.  59.  57.  59.\n",
      "  54.  56.  56.  59.  56.  59.  57.  56.  59.  54.  59.  59.  54.  54.  57.\n",
      "  61.  57.  57.  57.  57.  59.  57.  56.  61.  57.  54.  61.  57.  61.  56.\n",
      "  57.  57.  59.  62.  57.  56.  57.  61.  57.  61.  56.  57.  62.  56.  56.\n",
      "  59.  57.  59.  57.  59.  57.  57.  59.  57.  57.  57.  57.  59.  57.  57.\n",
      "  59.  56.  56.  56.  57.  52.  61.  59.  61.  56.  54.  54.  59.  56.  57.\n",
      "  57.  54.  57.  59.  57.  56.  56.  61.  59.  54.  57.  59.  54.  59.  56.\n",
      "  54.  56.  57.  57.  57.  57.  57.  59.  57.  54.  57.  57.  59.  61.  62.\n",
      "  59.  59.  59.  54.  57.  59.  59.  59.  56.  57.  57.  57.  54.  57.  59.\n",
      "  57.  52.  57.  59.  57.  54.  59.  52.  57.  54.  59.  54.  56.  61.  61.\n",
      "  59.  62.  57.  57.  59.  59.  57.  57.  62.  57.  54.  57.  54.  52.  54.\n",
      "  59.  59.  57.  54.  57.  57.  59.  57.  56.  54.  59.  57.  59.  59.  56.\n",
      "  57.  61.  57.  56.  54.  64.  57.  62.  59.  62.  61.  62.  57.  62.  62.\n",
      "  59.  59.  57.  54.  57.  59.  56.  61.  56.  59.  57.  61.  57.  61.  57.\n",
      "  59.  59.  56.  52.  57.  59.  56.  56.  52.  56.  61.  54.  59.  56.  61.\n",
      "  59.  59.  59.  54.  56.  57.  57.  52.  57.  54.  57.  56.  61.  56.  57.\n",
      "  64.  59.  57.  57.  57.  57.  56.  54.  62.  59.  59.  61.  57.  57.  57.\n",
      "  54.  56.  57.  52.  59.  59.  57.  62.  54.  54.  54.  57.  54.  62.  54.\n",
      "  57.  59.  57.  64.  57.  57.  54.  57.  59.  59.  56.  57.  57.  54.  59.\n",
      "  61.  59.  57.  54.  57.  56.  59.  54.  57.  59.  59.  59.  56.  59.  57.\n",
      "  56.  57.  59.  62.  56.  62.  57.  52.  57.  59.  57.  59.  57.  62.  59.\n",
      "  56.  57.  64.  59.  59.  57.  57.  62.  54.  61.  56.  54.  54.  56.  57.\n",
      "  56.  54.  56.  59.  57.  52.  59.  56.  57.  57.  59.  54.  59.  59.  56.\n",
      "  62.  57.  54.  56.  59.  54.  59.  54.  61.  59.  56.  62.  56.  61.  57.\n",
      "  54.  56.  54.  52.  62.  59.  57.  54.  59.  57.  56.  56.  57.  57.  61.\n",
      "  54.  59.  59.  56.  62.  59.  56.  57.  57.  59.  57.  59.  57.  57.  52.\n",
      "  52.  57.  57.  59.  61.  57.  59.  61.  57.  59.  56.  59.  57.  57.  57.\n",
      "  64.  56.  52.  56.  59.  54.  52.  54.  56.  56.  62.  56.  59.  57.  59.\n",
      "  57.  57.  54.  61.  59.  57.  52.  57.  64.  61.  57.  59.  56.  57.  57.\n",
      "  57.  56.  62.  61.  57.  54.  57.  59.  57.  54.  59.  57.  56.  61.  59.\n",
      "  57.  59.  57.  61.  62.  57.  56.]\n",
      "GAM V Done\n",
      "NewCSV/ode-to-joy.csv\n",
      "1 1168\n",
      "[[ 1.]]\n",
      "10\n",
      "0.328987297645\n",
      "20\n",
      "2.37509483737\n",
      "30\n",
      "0.922332630299\n",
      "40\n",
      "1.1578570484\n",
      "50\n",
      "0.653923406089\n",
      "60\n",
      "0.375086860958\n",
      "70\n",
      "0.16011593322\n",
      "80\n",
      "3.52074086451\n",
      "90\n",
      "0.467288181853\n",
      "100\n",
      "1.7188096814\n",
      "110\n",
      "0.491325253979\n",
      "120\n",
      "0.549001060269\n",
      "130\n",
      "0.626982679536\n",
      "140\n",
      "0.921494577616\n",
      "150\n",
      "2.96772216334\n",
      "[ 53.  51.  46. ...,  75.  60.  56.]\n",
      "Gibbs Done\n",
      "1 1168\n",
      "[[ 1.]]\n",
      "10\n",
      "1.38868375108\n",
      "20\n",
      "0.206733374976\n",
      "30\n",
      "0.602630310328\n",
      "40\n",
      "0.0627554545582\n",
      "[ 65.  67.  63. ...,  72.  79.  65.]\n",
      "Factorized Done\n",
      "1 1168\n",
      "[[ 1.]]\n",
      "10\n",
      "0.0815747935033\n",
      "20\n",
      "0.620790545634\n",
      "30\n",
      "0.0288501646288\n",
      "[ 63.  70.  68. ...,  58.  41.  39.]\n",
      "Structural Done\n",
      "[ 63.  60.  60. ...,  60.  60.  60.]\n",
      "GAM V Done\n",
      "NewCSV/Jupiter.csv\n",
      "1 1050\n",
      "[[ 1.]]\n",
      "10\n",
      "0.0983031629746\n",
      "20\n",
      "0.634781561741\n",
      "30\n",
      "1.15573535631\n",
      "40\n",
      "1.86676893751\n",
      "50\n",
      "2.68504890773\n",
      "60\n",
      "0.488827818196\n",
      "70\n",
      "0.870598102859\n",
      "80\n",
      "0.00961676543649\n",
      "[ 57.  67.  67. ...,  83.  73.  61.]\n",
      "Gibbs Done\n",
      "1 1050\n",
      "[[ 1.]]\n",
      "10\n",
      "0.21028480869\n",
      "20\n",
      "2.44617199885\n",
      "30\n",
      "0.385515444568\n",
      "[ 54.  67.  57. ...,  62.  45.  57.]\n",
      "Factorized Done\n",
      "1 1050\n",
      "[[ 1.]]\n",
      "10\n",
      "0.0812837504675\n",
      "20\n",
      "1.4195354184\n",
      "30\n",
      "0.774956465224\n",
      "40\n",
      "0.727093290651\n",
      "50\n",
      "0.0486781286409\n",
      "60\n",
      "0.0396559415121\n",
      "70\n",
      "0.00953867383924\n",
      "[ 64.  45.  47. ...,  55.  61.  45.]\n",
      "Structural Done\n",
      "[ 59.  59.  61. ...,  62.  62.  62.]\n",
      "GAM V Done\n",
      "NewCSV/pachelbel.csv\n",
      "1 1164\n",
      "[[ 1.]]\n",
      "10\n",
      "3.78632061246\n",
      "20\n",
      "5.88921063406\n",
      "30\n",
      "4.98091014081\n",
      "40\n",
      "3.77219885706\n",
      "50\n",
      "1.33628649819\n",
      "60\n",
      "5.78607777975\n",
      "70\n",
      "2.71831356353\n",
      "80\n",
      "0.211578226682\n",
      "90\n",
      "0.202442646928\n",
      "100\n",
      "3.6202400788\n",
      "110\n",
      "0.170413542573\n",
      "120\n",
      "2.52399974898\n",
      "130\n",
      "1.82618834976\n",
      "140\n",
      "0.971733866669\n",
      "150\n",
      "4.06616306202\n",
      "160\n",
      "2.27958354374\n",
      "170\n",
      "7.15719173577\n",
      "180\n",
      "3.28513272151\n",
      "190\n",
      "2.32052489448\n",
      "200\n",
      "4.10084735088\n",
      "210\n",
      "4.44142952652\n",
      "220\n",
      "0.076887144946\n",
      "230\n",
      "1.39298961078\n",
      "240\n",
      "2.83827122611\n",
      "250\n",
      "0.585490191286\n",
      "260\n",
      "0.700035402366\n",
      "270\n",
      "2.68710443868\n",
      "280\n",
      "3.39439278441\n",
      "290\n",
      "3.3693609203\n",
      "300\n",
      "4.63589552733\n",
      "310\n",
      "2.03337253419\n",
      "320\n",
      "0.120934382372\n",
      "330\n",
      "2.13685862688\n",
      "340\n",
      "1.10289313735\n",
      "350\n",
      "5.66229704201\n",
      "360\n",
      "5.13315770437\n",
      "370\n",
      "0.465823241157\n",
      "380\n",
      "3.03826032357\n",
      "390\n",
      "4.01709868629\n",
      "400\n",
      "0.798976914482\n",
      "410\n",
      "5.02528031261\n",
      "420\n",
      "8.13135290073\n",
      "430\n",
      "0.147170443429\n",
      "440\n",
      "0.876244122877\n",
      "450\n",
      "1.75969426958\n",
      "460\n",
      "2.16628163432\n",
      "470\n",
      "4.63521730038\n",
      "480\n",
      "3.57538820729\n",
      "490\n",
      "0.345923270593\n",
      "500\n",
      "0.0218338372164\n",
      "[ 55.  53.  36. ...,  68.  74.  53.]\n",
      "Gibbs Done\n",
      "1 1164\n",
      "[[ 1.]]\n",
      "10\n",
      "0.722611273245\n",
      "20\n",
      "0.183910286213\n",
      "30\n",
      "0.226524930499\n",
      "[ 46.  48.  43. ...,  72.  62.  53.]\n",
      "Factorized Done\n",
      "1 1164\n",
      "[[ 1.]]\n",
      "10\n",
      "4.78203836984\n",
      "20\n",
      "0.0614363547988\n",
      "[ 43.  38.  41. ...,  93.  93.  93.]\n",
      "Structural Done\n",
      "10\n",
      "0.151818361713\n",
      "[ 53.  56.  52. ...,  55.  56.  58.]\n",
      "GAM V Done\n",
      "NewCSV/westworld.csv\n",
      "1 180\n",
      "[[ 1.]]\n",
      "10\n",
      "0.100791987202\n",
      "20\n",
      "0.0152305360378\n",
      "[ 55.  67.  62.  55.  55.  69.  52.  43.  52.  60.  41.  55.  55.  48.  55.\n",
      "  55.  69.  62.  48.  55.  43.  60.  57.  65.  52.  48.  60.  41.  52.  55.\n",
      "  52.  57.  41.  41.  55.  62.  55.  60.  52.  55.  60.  48.  52.  55.  52.\n",
      "  60.  41.  43.  55.  52.  55.  48.  48.  52.  55.  48.  60.  62.  48.  57.\n",
      "  52.  48.  60.  69.  41.  55.  62.  65.  48.  55.  55.  48.  60.  64.  69.\n",
      "  65.  60.  60.  67.  60.  69.  55.  57.  52.  60.  60.  67.  57.  55.  48.\n",
      "  48.  60.  48.  52.  55.  65.  55.  57.  65.  52.  41.  43.  55.  69.  48.\n",
      "  48.  55.  48.  48.  43.  48.  69.  57.  55.  43.  65.  52.  55.  52.  57.\n",
      "  52.  52.  64.  48.  60.  62.  60.  60.  55.  55.  41.  67.  57.  65.  60.\n",
      "  52.  62.  52.  57.  48.  60.  48.  43.  41.  60.  65.  52.  55.  55.  48.\n",
      "  57.  60.  67.  43.  43.  52.  52.  57.  69.  52.  43.  62.  52.  67.  43.\n",
      "  55.  67.  52.  55.  48.  41.  65.  60.  67.  62.  52.  60.  60.  62.  48.]\n",
      "Gibbs Done\n",
      "1 180\n",
      "[[ 1.]]\n",
      "10\n",
      "3.80835182565\n",
      "[ 67.  67.  62.  65.  67.  60.  60.  60.  48.  64.  60.  55.  65.  65.  65.\n",
      "  64.  57.  48.  48.  62.  48.  55.  67.  65.  65.  60.  60.  57.  60.  60.\n",
      "  55.  57.  67.  60.  62.  48.  64.  60.  62.  52.  64.  41.  62.  41.  62.\n",
      "  62.  69.  62.  52.  41.  43.  69.  57.  60.  60.  65.  67.  60.  55.  62.\n",
      "  57.  64.  52.  62.  55.  52.  60.  60.  48.  57.  67.  48.  60.  65.  69.\n",
      "  62.  55.  67.  69.  55.  57.  60.  65.  60.  60.  57.  48.  60.  52.  60.\n",
      "  62.  48.  62.  65.  67.  65.  60.  62.  48.  60.  62.  62.  62.  60.  65.\n",
      "  60.  57.  67.  69.  48.  48.  62.  52.  60.  62.  48.  60.  60.  60.  67.\n",
      "  60.  64.  62.  52.  60.  55.  60.  60.  69.  62.  64.  55.  69.  64.  60.\n",
      "  67.  48.  55.  60.  52.  60.  64.  60.  55.  55.  65.  64.  62.  60.  57.\n",
      "  62.  64.  69.  55.  48.  62.  41.  62.  52.  62.  65.  67.  69.  62.  62.\n",
      "  41.  60.  62.  62.  60.  52.  57.  43.  64.  60.  41.  60.  67.  62.  52.]\n",
      "Factorized Done\n",
      "1 180\n",
      "[[ 1.]]\n",
      "10\n",
      "0.536398395063\n",
      "20\n",
      "0.108693399335\n",
      "30\n",
      "5.01018660214\n",
      "40\n",
      "0.620217857415\n",
      "50\n",
      "0.0528019616964\n",
      "60\n",
      "0.04173234576\n",
      "70\n",
      "0.0212131687931\n",
      "[ 60.  55.  48.  67.  67.  55.  43.  67.  55.  43.  60.  55.  41.  62.  64.\n",
      "  55.  43.  64.  65.  57.  48.  62.  60.  43.  60.  52.  52.  64.  55.  48.\n",
      "  62.  52.  52.  65.  57.  48.  65.  62.  57.  43.  67.  67.  57.  41.  62.\n",
      "  57.  55.  43.  67.  62.  60.  41.  67.  67.  55.  43.  62.  64.  57.  48.\n",
      "  62.  65.  60.  60.  48.  64.  67.  57.  48.  62.  65.  60.  48.  64.  67.\n",
      "  55.  43.  65.  48.  48.  65.  55.  48.  60.  65.  57.  48.  69.  65.  60.\n",
      "  43.  67.  62.  48.  48.  62.  62.  55.  48.  67.  69.  55.  43.  65.  62.\n",
      "  57.  48.  64.  60.  55.  41.  60.  62.  43.  60.  52.  48.  62.  65.  48.\n",
      "  43.  69.  62.  57.  43.  64.  65.  48.  48.  60.  65.  60.  41.  60.  62.\n",
      "  65.  52.  48.  60.  57.  43.  62.  60.  41.  64.  65.  60.  52.  60.  64.\n",
      "  55.  43.  62.  55.  48.  64.  65.  57.  43.  65.  62.  55.  48.  62.  65.\n",
      "  55.  48.  65.  69.  57.  43.  67.  64.  55.  48.  64.  67.  55.  48.  65.]\n",
      "Structural Done\n",
      "10\n",
      "0.0119230738779\n",
      "[ 57.  60.  48.  60.  60.  52.  60.  57.  60.  64.  52.  55.  55.  43.  55.\n",
      "  52.  48.  48.  52.  48.  62.  55.  55.  48.  60.  67.  62.  55.  48.  69.\n",
      "  62.  57.  60.  57.  52.  57.  60.  60.  48.  55.  48.  62.  62.  60.  60.\n",
      "  60.  52.  48.  57.  52.  60.  67.  57.  41.  67.  69.  55.  48.  60.  48.\n",
      "  55.  62.  69.  57.  48.  52.  65.  48.  60.  64.  60.  55.  62.  57.  60.\n",
      "  48.  60.  55.  62.  48.  48.  60.  57.  57.  57.  57.  55.  60.  62.  65.\n",
      "  60.  62.  64.  62.  69.  57.  64.  55.  57.  52.  52.  62.  55.  64.  41.\n",
      "  64.  55.  55.  52.  57.  55.  52.  67.  62.  65.  57.  52.  43.  55.  64.\n",
      "  52.  55.  65.  55.  48.  52.  52.  48.  60.  55.  52.  69.  60.  48.  52.\n",
      "  52.  52.  67.  60.  57.  65.  52.  62.  69.  57.  57.  60.  57.  65.  65.\n",
      "  57.  64.  41.  57.  57.  41.  57.  69.  62.  67.  57.  55.  65.  64.  60.\n",
      "  57.  62.  60.  52.  67.  57.  52.  52.  55.  52.  52.  62.  57.  69.  43.]\n",
      "GAM V Done\n",
      "NewCSV/twinkle-twinkle-little-star.csv\n"
     ]
    }
   ],
   "source": [
    "# # 'book2-fugue07.csv', \n",
    "# # 'book2-fugue07.csv', \n",
    "# # 64, \n",
    "orig_list = ['beethoven-symphony9-4-ode-to-joy-piano-solo.csv', 'Jupiter.csv', \n",
    "             'pachelbel.csv', 'Ramin_Djawadi_-_Westworld_Theme.csv', 'twinkle-twinkle-little-star-orig.csv']\n",
    "new_list = ['ode-to-joy.csv', 'Jupiter.csv','pachelbel.csv', 'westworld.csv', \n",
    "            'twinkle-twinkle-little-star.csv']\n",
    "quarter_note = [128, 64, 64, 80, 256]\n",
    "M = 3\n",
    "K = np.array([5, 5, 5])\n",
    "\n",
    "# it_G = np.zeros(len(orig_list))\n",
    "# elapsed_G = np.zeros(len(orig_list))\n",
    "# it_F = np.zeros(len(orig_list))\n",
    "# elapsed_F = np.zeros(len(orig_list))\n",
    "# it_S = np.zeros(len(orig_list))\n",
    "# elapsed_S = np.zeros(len(orig_list))\n",
    "\n",
    "for i in range(len(orig_list)):\n",
    "    oldfile = 'OriginalCSV/' + orig_list[i]\n",
    "    newfile = 'NewCSV/' + new_list[i]\n",
    "    _, _, _, _, newNotes_G, params_G = FHMM_compose(oldfile, newfile, quarter_note[i], \"FHMM\", \"Gibbs\", None, \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = False)\n",
    "    print(\"Gibbs Done\")\n",
    "    _, _, _, _, newNotes_F, params_F = FHMM_compose(oldfile, newfile, quarter_note[i], \"FHMM\", \"FactorizedVI\", None, \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = False)\n",
    "    print(\"Factorized Done\")\n",
    "    _, _, _, _, newNotes_S, params_S = FHMM_compose(oldfile, newfile, quarter_note[i], \"FHMM\", \"StructuralVI\", None, \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = False)\n",
    "    print(\"Structural Done\")\n",
    "    _, _, _, _, newNotes_GAM, params_GAM = FHMM_compose(oldfile, newfile, quarter_note[i], \"GAM\", \"Gaussian\", \"V\", \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = False)\n",
    "    print(\"GAM V Done\")\n",
    "    print(newfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GAMs\n",
    "\n",
    "### a. M = 3, K = [5, 5, 5] (Gaussian, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54.  62.  62.  59.  57.  59.  57.  61.  57.  54.  59.  57.  57.  59.  57.\n",
      "  59.  59.  61.  59.  61.  57.  59.  54.  59.  59.  59.  57.  59.  57.  61.\n",
      "  64.  62.  56.  56.  59.  54.  57.  59.  56.  56.  57.  61.  57.  57.  61.\n",
      "  57.  57.  59.  59.  59.  59.  61.  59.  59.  59.  54.  62.  57.  59.  62.\n",
      "  59.  59.  56.  57.  59.  59.  59.  57.  59.  57.  57.  62.  59.  57.  54.\n",
      "  59.  57.  56.  59.  57.  56.  57.  57.  59.  59.  59.  59.  52.  52.  59.\n",
      "  59.  54.  54.  62.  59.  61.  61.  62.  57.  57.  56.  61.  61.  54.  54.\n",
      "  59.  61.  64.  59.  54.  57.  59.  57.  59.  54.  59.  57.  59.  59.  59.\n",
      "  62.  59.  57.  57.  59.  56.  57.  62.  57.  59.  59.  59.  54.  57.  59.\n",
      "  54.  61.  54.  54.  56.  62.  59.  56.  57.  57.  54.  56.  59.  54.  57.\n",
      "  59.  59.  54.  61.  62.  59.  59.  61.  57.  61.  59.  61.  57.  62.  62.\n",
      "  57.  59.  59.  57.  61.  57.  54.  56.  62.  59.  57.  57.  54.  59.  57.\n",
      "  56.  56.  61.  54.  62.  57.  62.  59.  56.  59.  54.  59.  57.  56.  56.\n",
      "  57.  59.  59.  61.  57.  57.  61.  57.  59.  57.  61.  59.  54.  59.  57.\n",
      "  54.  54.  59.  56.  59.  56.  54.  59.  61.  61.  59.  62.  56.  59.  61.\n",
      "  57.  56.  59.  56.  56.  61.  57.  57.  61.  61.  61.  57.  57.  59.  56.\n",
      "  57.  54.  59.  57.  59.  59.  59.  57.  61.  56.  54.  61.  62.  57.  59.\n",
      "  59.  64.  56.  59.  57.  59.  61.  61.  57.  59.  57.  62.  61.  59.  57.\n",
      "  62.  54.  59.  59.  56.  54.  59.  59.  59.  56.  59.  57.  57.  59.  62.\n",
      "  57.  54.  59.  56.  57.  62.  57.  57.  57.  59.  59.  57.  57.  59.  62.\n",
      "  54.  57.  57.  59.  59.  57.  57.  57.  59.  57.  56.  56.  61.  59.  59.\n",
      "  56.  59.  59.  57.  59.  59.  54.  61.  61.  57.  57.  54.  57.  59.  59.\n",
      "  59.  61.  57.  59.  56.  59.  62.  57.  57.  59.  59.  59.  57.  57.  62.\n",
      "  54.  59.  61.  59.  57.  57.  57.  54.  64.  57.  59.  59.  57.  57.  57.\n",
      "  62.  59.  59.  54.  62.  57.  54.  57.  54.  59.  57.  61.  56.  59.  57.\n",
      "  62.  66.  66.  59.  62.  62.  57.  56.  59.  57.  57.  62.  62.  54.  59.\n",
      "  59.  59.  62.  59.  59.  56.  59.  57.  54.  59.  59.  54.  59.  61.  57.\n",
      "  59.  56.  57.  59.  59.  61.  62.  61.  59.  59.  54.  57.  56.  57.  59.\n",
      "  59.  59.  57.  57.  57.  61.  57.  56.  54.  57.  61.  57.  61.  57.  59.\n",
      "  57.  57.  59.  56.  57.  59.  59.  54.  59.  57.  62.  59.  59.  57.  57.\n",
      "  59.  57.  62.  59.  61.  59.  59.  56.  57.  56.  56.  57.  62.  54.  54.\n",
      "  57.  64.  59.  56.  61.  57.  62.  57.  59.  57.  61.  57.  59.  56.  61.\n",
      "  57.  59.  59.  59.  61.  59.  57.  61.  57.  56.  59.  56.  59.  56.  61.\n",
      "  57.  54.  59.  52.  56.  54.  56.  54.  52.  61.  57.  62.  57.  61.  57.\n",
      "  57.  59.  54.  59.  56.  57.  57.  57.  62.  61.  54.  56.  61.  54.  62.\n",
      "  57.  62.  59.  59.  59.  62.  61.]\n",
      "metrics/ode-to-joy__GAMGaussian_3-tol0.01.csv\n",
      "GAM V Done\n",
      "NewCSV/ode-to-joy.csv\n",
      "[ 60.  60.  60. ...,  60.  60.  63.]\n",
      "metrics/Jupiter__GAMGaussian_3-tol0.01.csv\n",
      "GAM V Done\n",
      "NewCSV/Jupiter.csv\n",
      "[ 62.  64.  62. ...,  62.  62.  61.]\n",
      "metrics/pachelbel__GAMGaussian_3-tol0.01.csv\n",
      "GAM V Done\n",
      "NewCSV/pachelbel.csv\n",
      "10\n",
      "0.133463947698\n",
      "20\n",
      "0.0946644468177\n",
      "30\n",
      "0.223617546013\n",
      "[ 50.  56.  55. ...,  53.  55.  55.]\n",
      "metrics/westworld__GAMGaussian_3-tol0.01.csv\n",
      "GAM V Done\n",
      "NewCSV/westworld.csv\n",
      "[ 52.  67.  69.  52.  52.  62.  48.  60.  57.  57.  52.  65.  60.  55.  48.\n",
      "  60.  48.  55.  60.  52.  62.  65.  64.  57.  67.  57.  57.  67.  52.  57.\n",
      "  57.  52.  65.  69.  48.  60.  55.  48.  62.  55.  41.  48.  48.  55.  48.\n",
      "  62.  57.  69.  65.  48.  69.  43.  67.  57.  55.  60.  48.  48.  55.  55.\n",
      "  55.  60.  55.  48.  55.  57.  60.  52.  52.  69.  52.  65.  62.  60.  55.\n",
      "  60.  55.  60.  57.  62.  55.  60.  52.  52.  60.  55.  60.  55.  62.  64.\n",
      "  62.  60.  48.  57.  65.  65.  57.  60.  60.  65.  60.  62.  62.  67.  60.\n",
      "  60.  67.  69.  52.  52.  69.  55.  57.  62.  64.  62.  48.  60.  65.  52.\n",
      "  48.  67.  65.  60.  67.  55.  67.  69.  65.  48.  60.  64.  60.  60.  55.\n",
      "  67.  65.  60.  55.  62.  43.  60.  55.  52.  48.  67.  55.  62.  62.  55.\n",
      "  52.  64.  55.  69.  55.  48.  48.  57.  55.  48.  57.  67.  55.  57.  55.\n",
      "  48.  60.  55.  67.  62.  62.  55.  65.  48.  55.  64.  57.  55.  57.  48.]\n",
      "metrics/twinkle-twinkle-little-star__GAMGaussian_3-tol0.01.csv\n",
      "GAM V Done\n",
      "NewCSV/twinkle-twinkle-little-star.csv\n"
     ]
    }
   ],
   "source": [
    "# # 'book2-fugue07.csv', \n",
    "# # 'book2-fugue07.csv', \n",
    "# # 64, \n",
    "# orig_list = ['beethoven-symphony9-4-ode-to-joy-piano-solo.csv', 'Jupiter.csv', \n",
    "#              'pachelbel.csv', 'Ramin_Djawadi_-_Westworld_Theme.csv', 'twinkle-twinkle-little-star-orig.csv']\n",
    "# new_list = ['ode-to-joy.csv', 'Jupiter.csv','pachelbel.csv', 'westworld.csv', \n",
    "#             'twinkle-twinkle-little-star.csv']\n",
    "# quarter_note = [128, 64, 64, 80, 256]\n",
    "# M = 3\n",
    "# K = np.array([5, 5, 5])\n",
    "# it_GAM = np.zeros(len(orig_list))\n",
    "# elapsed_GAM = np.zeros(len(orig_list))\n",
    "# for i in range(len(orig_list)):\n",
    "#     oldfile = 'OriginalCSV/' + orig_list[i]\n",
    "#     newfile = 'NewCSV/' + new_list[i]\n",
    "#     it_GAM[i], elapsed_GAM[i], timeT, notes, newNotes_GAM, params_GAM = FHMM_compose(oldfile, newfile, \n",
    "#                                                                                quarter_note[i], \"GAM\", \"Gaussian\", \"V\", \n",
    "#                                                  M, K, 0.01, 1000, metrics_calc = True)\n",
    "#     print(\"GAM V Done\")\n",
    "#     print(newfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1408\n",
      "[[ 1.]]\n",
      "10\n",
      "0.286691530309\n",
      "20\n",
      "0.455551672153\n",
      "30\n",
      "1.11616375224\n",
      "40\n",
      "1.8822346074\n",
      "50\n",
      "0.886316497714\n",
      "60\n",
      "1.20391698025\n",
      "70\n",
      "0.518147961706\n",
      "80\n",
      "0.182248758324\n",
      "90\n",
      "0.653060336506\n",
      "100\n",
      "1.2017559324\n",
      "110\n",
      "0.852224303362\n",
      "120\n",
      "0.0180543708359\n",
      "130\n",
      "0.812838749956\n",
      "140\n",
      "0.0143266995223\n",
      "[ 71.  61.  58. ...,  66.  71.  57.]\n",
      "metrics/book2-fugue07__FHMMGibbs_3-tol0.01.csv\n",
      "Gibbs Done\n",
      "1 1408\n",
      "[[ 1.]]\n",
      "10\n",
      "0.0641910410587\n",
      "20\n",
      "0.629579483731\n",
      "30\n",
      "0.512692177315\n",
      "40\n",
      "0.111359617317\n",
      "50\n",
      "0.0331324708624\n",
      "[ 48.  67.  72. ...,  50.  55.  50.]\n",
      "metrics/book2-fugue07__FHMMFactorizedVI_3-tol0.01.csv\n",
      "Factorized Done\n",
      "1 1408\n",
      "[[ 1.]]\n",
      "10\n",
      "2.1627545713\n",
      "20\n",
      "4.42016744997\n",
      "30\n",
      "0.0433616403207\n",
      "40\n",
      "0.142584247091\n",
      "50\n",
      "0.511843257733\n",
      "60\n",
      "0.274375520704\n",
      "70\n",
      "0.092897613974\n",
      "80\n",
      "0.239004707958\n",
      "90\n",
      "0.172687021254\n",
      "100\n",
      "0.0837403792048\n",
      "110\n",
      "0.0395630197235\n",
      "120\n",
      "0.022478082001\n",
      "130\n",
      "0.0200883308315\n",
      "140\n",
      "0.022156494821\n",
      "150\n",
      "0.0239971205082\n",
      "160\n",
      "0.0200835076045\n",
      "170\n",
      "0.0151805247769\n",
      "180\n",
      "0.00939758148123\n",
      "[ 52.  74.  72. ...,  53.  62.  65.]\n",
      "metrics/book2-fugue07__FHMMStructuralVI_3-tol0.01.csv\n",
      "Structural Done\n",
      "[ 64.  64.  63. ...,  65.  63.  63.]\n",
      "metrics/book2-fugue07__GAMGaussian_3-tol0.01.csv\n",
      "GAM V Done\n",
      "NewCSV/book2-fugue07.csv\n"
     ]
    }
   ],
   "source": [
    "# 'book2-fugue07.csv', \n",
    "# 'book2-fugue07.csv', \n",
    "# 64, \n",
    "orig_list = ['book2-fugue07.csv']\n",
    "new_list = ['book2-fugue07.csv']\n",
    "quarter_note = [64]\n",
    "M = 3\n",
    "K = np.array([5, 5, 5])\n",
    "\n",
    "for i in range(len(orig_list)):\n",
    "    oldfile = 'OriginalCSV/' + orig_list[i]\n",
    "    newfile = 'NewCSV/' + new_list[i]\n",
    "    it_G_B, elapsed_G_B, timeT, notes, newNotes_G, params_G = FHMM_compose(oldfile, newfile, quarter_note[i], \n",
    "                                                                      \"FHMM\", \"Gibbs\", None, \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = True)\n",
    "    print(\"Gibbs Done\")\n",
    "    it_F_B, elapsed_F_B, timeT, notes, newNotes_F, params_F = FHMM_compose(oldfile, newfile, quarter_note[i], \n",
    "                                                                      \"FHMM\", \"FactorizedVI\", None, \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = True)\n",
    "    print(\"Factorized Done\")\n",
    "    it_S_B, elapsed_S_B, timeT, notes, newNotes_S, params_S = FHMM_compose(oldfile, newfile, quarter_note[i], \n",
    "                                                                          \"FHMM\", \"StructuralVI\", None, \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = True)\n",
    "    print(\"Structural Done\")\n",
    "    it_GAM_B, elapsed_GAM_B, timeT, notes, newNotes_GAM, params_GAM = FHMM_compose(oldfile, newfile, \n",
    "                                                                               quarter_note[i], \"GAM\", \"Gaussian\", \"V\", \n",
    "                                                 M, K, 0.01, 1000, metrics_calc = True)\n",
    "    print(\"GAM V Done\")\n",
    "    print(newfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.,   5.,   2.,  35.,   2.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_GAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency Metrics Summary\n",
    "\n",
    "#### Iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twinkle, Twinkle</th>\n",
       "      <th>Bach Book 2 Fugue 7</th>\n",
       "      <th>Ode to Joy</th>\n",
       "      <th>Jupiter Theme</th>\n",
       "      <th>Pachelbel's Canon</th>\n",
       "      <th>Westworld Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First Order</th>\n",
       "      <td>19.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layered</th>\n",
       "      <td>79.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Factorial</th>\n",
       "      <td>133.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Gibbs</th>\n",
       "      <td>16.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Factorized VI</th>\n",
       "      <td>34.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Structured VI</th>\n",
       "      <td>7.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-GAM</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Twinkle, Twinkle  Bach Book 2 Fugue 7  Ode to Joy  \\\n",
       "First Order                        19.0                 95.0        52.0   \n",
       "Random                              1.0                  1.0         1.0   \n",
       "Layered                            79.0                196.0        94.0   \n",
       "Independent Factorial             133.0                634.0       252.0   \n",
       "FHMM-Gibbs                         16.0                145.0         5.0   \n",
       "FHMM-Factorized VI                 34.0                 56.0        13.0   \n",
       "FHMM-Structured VI                  7.0                180.0        27.0   \n",
       "FHMM-GAM                            2.0                  5.0         4.0   \n",
       "\n",
       "                       Jupiter Theme  Pachelbel's Canon  Westworld Theme  \n",
       "First Order                     53.0              106.0             55.0  \n",
       "Random                           1.0                1.0              1.0  \n",
       "Layered                        174.0              268.0            227.0  \n",
       "Independent Factorial          298.0              287.0            189.0  \n",
       "FHMM-Gibbs                     346.0                7.0            420.0  \n",
       "FHMM-Factorized VI              22.0               39.0             46.0  \n",
       "FHMM-Structured VI              31.0              119.0             41.0  \n",
       "FHMM-GAM                         5.0                2.0             35.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it2_df = pd.DataFrame([it_1, it_r, it_lay, it_f, np.roll(np.append(it_G, it_G_B), 2), \n",
    "                          np.roll(np.append(it_F, it_F_B), 2), np.roll(np.append(it_S, it_S_B), 2), \n",
    "                          np.roll(np.append(it_GAM, it_GAM_B), 2)], \n",
    "                     index = [\"First Order\", \"Random\", \"Layered\", \"Independent Factorial\", \n",
    "                             \"FHMM-Gibbs\", \"FHMM-Factorized VI\", \"FHMM-Structured VI\", \"FHMM-GAM\"],\n",
    "                    columns = [\"Twinkle, Twinkle\", \"Bach Book 2 Fugue 7\", \"Ode to Joy\", \"Jupiter Theme\", \n",
    "                               \"Pachelbel's Canon\", \"Westworld Theme\"])\n",
    "it2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twinkle, Twinkle</th>\n",
       "      <th>Bach Book 2 Fugue 7</th>\n",
       "      <th>Ode to Joy</th>\n",
       "      <th>Jupiter Theme</th>\n",
       "      <th>Pachelbel's Canon</th>\n",
       "      <th>Westworld Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First Order</th>\n",
       "      <td>27.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>254.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layered</th>\n",
       "      <td>120.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Factorial</th>\n",
       "      <td>380.0</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1443.0</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Gibbs</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Factorized VI</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Structured VI</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-GAM</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Twinkle, Twinkle  Bach Book 2 Fugue 7  Ode to Joy  \\\n",
       "First Order                        27.0               1001.0        41.0   \n",
       "Random                              1.0                  1.0         1.0   \n",
       "Layered                           120.0               1300.0       554.0   \n",
       "Independent Factorial             380.0               2073.0       609.0   \n",
       "FHMM-Gibbs                         16.0                  0.0         5.0   \n",
       "FHMM-Factorized VI                 34.0                  0.0        13.0   \n",
       "FHMM-Structured VI                  7.0                  0.0        27.0   \n",
       "FHMM-GAM                            2.0                  0.0         4.0   \n",
       "\n",
       "                       Jupiter Theme  Pachelbel's Canon  Westworld Theme  \n",
       "First Order                    376.0              169.0            254.0  \n",
       "Random                           1.0                1.0              1.0  \n",
       "Layered                       1145.0              361.0            199.0  \n",
       "Independent Factorial          731.0             1443.0            704.0  \n",
       "FHMM-Gibbs                     346.0                7.0            420.0  \n",
       "FHMM-Factorized VI              22.0               39.0             46.0  \n",
       "FHMM-Structured VI              31.0              119.0             41.0  \n",
       "FHMM-GAM                         5.0                2.0             35.0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_df = pd.DataFrame([it_1, it_r, it_lay, it_f, np.roll(np.append(it_G, 0), 2), \n",
    "                          np.roll(np.append(it_F, 0), 2), np.roll(np.append(it_S, 0), 2), \n",
    "                          np.roll(np.append(it_GAM, 0), 2)], \n",
    "                     index = [\"First Order\", \"Random\", \"Layered\", \"Independent Factorial\", \n",
    "                             \"FHMM-Gibbs\", \"FHMM-Factorized VI\", \"FHMM-Structured VI\", \"FHMM-GAM\"],\n",
    "                    columns = [\"Twinkle, Twinkle\", \"Bach Book 2 Fugue 7\", \"Ode to Joy\", \"Jupiter Theme\", \n",
    "                               \"Pachelbel's Canon\", \"Westworld Theme\"])\n",
    "it_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  Twinkle, Twinkle &  Bach Book 2 Fugue 7 &  Ode to Joy &  Jupiter Theme &  Pachelbel's Canon &  Westworld Theme \\\\\n",
      "\\midrule\n",
      "First Order           &                19 &                   95 &          52 &             53 &                106 &               55 \\\\\n",
      "Random                &                 1 &                    1 &           1 &              1 &                  1 &                1 \\\\\n",
      "Layered               &                79 &                  196 &          94 &            174 &                268 &              227 \\\\\n",
      "Independent Factorial &               133 &                  634 &         252 &            298 &                287 &              189 \\\\\n",
      "FHMM-Gibbs            &                16 &                  145 &           5 &            346 &                  7 &              420 \\\\\n",
      "FHMM-Factorized VI    &                34 &                   56 &          13 &             22 &                 39 &               46 \\\\\n",
      "FHMM-Structured VI    &                 7 &                  180 &          27 &             31 &                119 &               41 \\\\\n",
      "FHMM-GAM              &                 2 &                    5 &           4 &              5 &                  2 &               35 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(it2_df.astype(int).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elapsed Time for iterations in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twinkle, Twinkle</th>\n",
       "      <th>Bach Book 2 Fugue 7</th>\n",
       "      <th>Ode to Joy</th>\n",
       "      <th>Jupiter Theme</th>\n",
       "      <th>Pachelbel's Canon</th>\n",
       "      <th>Westworld Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First Order</th>\n",
       "      <td>2.288773</td>\n",
       "      <td>44.256100</td>\n",
       "      <td>7.768446</td>\n",
       "      <td>18.956762</td>\n",
       "      <td>33.890511</td>\n",
       "      <td>22.049411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layered</th>\n",
       "      <td>3.901470</td>\n",
       "      <td>83.344170</td>\n",
       "      <td>13.244863</td>\n",
       "      <td>59.289448</td>\n",
       "      <td>79.300036</td>\n",
       "      <td>81.498019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Factorial</th>\n",
       "      <td>14.228130</td>\n",
       "      <td>613.362022</td>\n",
       "      <td>80.897396</td>\n",
       "      <td>283.062360</td>\n",
       "      <td>240.570831</td>\n",
       "      <td>169.747153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Gibbs</th>\n",
       "      <td>55.464956</td>\n",
       "      <td>3805.437366</td>\n",
       "      <td>51.041263</td>\n",
       "      <td>7520.183742</td>\n",
       "      <td>137.359845</td>\n",
       "      <td>9121.527179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Factorized VI</th>\n",
       "      <td>43.179979</td>\n",
       "      <td>545.208174</td>\n",
       "      <td>48.038469</td>\n",
       "      <td>179.543578</td>\n",
       "      <td>285.248236</td>\n",
       "      <td>379.849644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Structured VI</th>\n",
       "      <td>7.399632</td>\n",
       "      <td>679.824440</td>\n",
       "      <td>49.690906</td>\n",
       "      <td>132.664555</td>\n",
       "      <td>406.073802</td>\n",
       "      <td>211.511822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-GAM</th>\n",
       "      <td>0.786193</td>\n",
       "      <td>14.668302</td>\n",
       "      <td>4.454598</td>\n",
       "      <td>12.093389</td>\n",
       "      <td>4.403194</td>\n",
       "      <td>84.481035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Twinkle, Twinkle  Bach Book 2 Fugue 7  Ode to Joy  \\\n",
       "First Order                    2.288773            44.256100    7.768446   \n",
       "Random                         0.000043             0.000057    0.000045   \n",
       "Layered                        3.901470            83.344170   13.244863   \n",
       "Independent Factorial         14.228130           613.362022   80.897396   \n",
       "FHMM-Gibbs                    55.464956          3805.437366   51.041263   \n",
       "FHMM-Factorized VI            43.179979           545.208174   48.038469   \n",
       "FHMM-Structured VI             7.399632           679.824440   49.690906   \n",
       "FHMM-GAM                       0.786193            14.668302    4.454598   \n",
       "\n",
       "                       Jupiter Theme  Pachelbel's Canon  Westworld Theme  \n",
       "First Order                18.956762          33.890511        22.049411  \n",
       "Random                      0.000054           0.000092         0.000073  \n",
       "Layered                    59.289448          79.300036        81.498019  \n",
       "Independent Factorial     283.062360         240.570831       169.747153  \n",
       "FHMM-Gibbs               7520.183742         137.359845      9121.527179  \n",
       "FHMM-Factorized VI        179.543578         285.248236       379.849644  \n",
       "FHMM-Structured VI        132.664555         406.073802       211.511822  \n",
       "FHMM-GAM                   12.093389           4.403194        84.481035  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed2_df = pd.DataFrame([elapsed_1, elapsed_r, elapsed_lay, elapsed_f, np.roll(np.append(elapsed_G, elapsed_G_B), 2), \n",
    "                          np.roll(np.append(elapsed_F, elapsed_F_B), 2), np.roll(np.append(elapsed_S, elapsed_S_B), 2), \n",
    "                          np.roll(np.append(elapsed_GAM, elapsed_GAM_B), 2)], \n",
    "                     index = [\"First Order\", \"Random\", \"Layered\", \"Independent Factorial\", \n",
    "                             \"FHMM-Gibbs\", \"FHMM-Factorized VI\", \"FHMM-Structured VI\", \"FHMM-GAM\"],\n",
    "                    columns = [\"Twinkle, Twinkle\", \"Bach Book 2 Fugue 7\", \"Ode to Joy\", \"Jupiter Theme\", \n",
    "                               \"Pachelbel's Canon\", \"Westworld Theme\"])\n",
    "elapsed2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twinkle, Twinkle</th>\n",
       "      <th>Bach Book 2 Fugue 7</th>\n",
       "      <th>Ode to Joy</th>\n",
       "      <th>Jupiter Theme</th>\n",
       "      <th>Pachelbel's Canon</th>\n",
       "      <th>Westworld Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First Order</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layered</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Factorial</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Gibbs</th>\n",
       "      <td>55.464956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.041263</td>\n",
       "      <td>7520.183742</td>\n",
       "      <td>137.359845</td>\n",
       "      <td>9121.527179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Factorized VI</th>\n",
       "      <td>43.179979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.038469</td>\n",
       "      <td>179.543578</td>\n",
       "      <td>285.248236</td>\n",
       "      <td>379.849644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Structured VI</th>\n",
       "      <td>7.399632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.690906</td>\n",
       "      <td>132.664555</td>\n",
       "      <td>406.073802</td>\n",
       "      <td>211.511822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-GAM</th>\n",
       "      <td>0.786193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.454598</td>\n",
       "      <td>12.093389</td>\n",
       "      <td>4.403194</td>\n",
       "      <td>84.481035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Twinkle, Twinkle  Bach Book 2 Fugue 7  Ode to Joy  \\\n",
       "First Order                    0.000000                  0.0    0.000000   \n",
       "Random                         0.000000                  0.0    0.000000   \n",
       "Layered                        0.000000                  0.0    0.000000   \n",
       "Independent Factorial          0.000000                  0.0    0.000000   \n",
       "FHMM-Gibbs                    55.464956                  0.0   51.041263   \n",
       "FHMM-Factorized VI            43.179979                  0.0   48.038469   \n",
       "FHMM-Structured VI             7.399632                  0.0   49.690906   \n",
       "FHMM-GAM                       0.786193                  0.0    4.454598   \n",
       "\n",
       "                       Jupiter Theme  Pachelbel's Canon  Westworld Theme  \n",
       "First Order                 0.000000           0.000000         0.000000  \n",
       "Random                      0.000000           0.000000         0.000000  \n",
       "Layered                     0.000000           0.000000         0.000000  \n",
       "Independent Factorial       0.000000           0.000000         0.000000  \n",
       "FHMM-Gibbs               7520.183742         137.359845      9121.527179  \n",
       "FHMM-Factorized VI        179.543578         285.248236       379.849644  \n",
       "FHMM-Structured VI        132.664555         406.073802       211.511822  \n",
       "FHMM-GAM                   12.093389           4.403194        84.481035  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_df = pd.DataFrame([elapsed_1, elapsed_r, elapsed_lay, elapsed_f, np.roll(np.append(elapsed_G, 0), 2), \n",
    "                          np.roll(np.append(elapsed_F, 0), 2), np.roll(np.append(elapsed_S, 0), 2), \n",
    "                          np.roll(np.append(elapsed_GAM, 0), 2)], \n",
    "                     index = [\"First Order\", \"Random\", \"Layered\", \"Independent Factorial\", \n",
    "                             \"FHMM-Gibbs\", \"FHMM-Factorized VI\", \"FHMM-Structured VI\", \"FHMM-GAM\"],\n",
    "                    columns = [\"Twinkle, Twinkle\", \"Bach Book 2 Fugue 7\", \"Ode to Joy\", \"Jupiter Theme\", \n",
    "                               \"Pachelbel's Canon\", \"Westworld Theme\"])\n",
    "elapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  Twinkle, Twinkle &  Bach Book 2 Fugue 7 &  Ode to Joy &  Jupiter Theme &  Pachelbel's Canon &  Westworld Theme \\\\\n",
      "\\midrule\n",
      "First Order           &             2.289 &               44.256 &       7.768 &         18.957 &             33.891 &           22.049 \\\\\n",
      "Random                &             0.000 &                0.000 &       0.000 &          0.000 &              0.000 &            0.000 \\\\\n",
      "Layered               &             3.901 &               83.344 &      13.245 &         59.289 &             79.300 &           81.498 \\\\\n",
      "Independent Factorial &            14.228 &              613.362 &      80.897 &        283.062 &            240.571 &          169.747 \\\\\n",
      "FHMM-Gibbs            &            55.465 &             3805.437 &      51.041 &       7520.184 &            137.360 &         9121.527 \\\\\n",
      "FHMM-Factorized VI    &            43.180 &              545.208 &      48.038 &        179.544 &            285.248 &          379.850 \\\\\n",
      "FHMM-Structured VI    &             7.400 &              679.824 &      49.691 &        132.665 &            406.074 &          211.512 \\\\\n",
      "FHMM-GAM              &             0.786 &               14.668 &       4.455 &         12.093 &              4.403 &           84.481 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(elapsed2_df.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Time per Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Twinkle, Twinkle</th>\n",
       "      <th>Bach Book 2 Fugue 7</th>\n",
       "      <th>Ode to Joy</th>\n",
       "      <th>Jupiter Theme</th>\n",
       "      <th>Pachelbel's Canon</th>\n",
       "      <th>Westworld Theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First Order</th>\n",
       "      <td>0.120462</td>\n",
       "      <td>0.465854</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>0.357675</td>\n",
       "      <td>0.319722</td>\n",
       "      <td>0.400898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layered</th>\n",
       "      <td>0.049386</td>\n",
       "      <td>0.425225</td>\n",
       "      <td>0.140903</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.295896</td>\n",
       "      <td>0.359022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Factorial</th>\n",
       "      <td>0.106978</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>0.321021</td>\n",
       "      <td>0.949874</td>\n",
       "      <td>0.838226</td>\n",
       "      <td>0.898133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Gibbs</th>\n",
       "      <td>3.466560</td>\n",
       "      <td>26.244396</td>\n",
       "      <td>10.208253</td>\n",
       "      <td>21.734635</td>\n",
       "      <td>19.622835</td>\n",
       "      <td>21.717922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Factorized VI</th>\n",
       "      <td>1.269999</td>\n",
       "      <td>9.735860</td>\n",
       "      <td>3.695267</td>\n",
       "      <td>8.161072</td>\n",
       "      <td>7.314057</td>\n",
       "      <td>8.257601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-Structured VI</th>\n",
       "      <td>1.057090</td>\n",
       "      <td>3.776802</td>\n",
       "      <td>1.840404</td>\n",
       "      <td>4.279502</td>\n",
       "      <td>3.412385</td>\n",
       "      <td>5.158825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FHMM-GAM</th>\n",
       "      <td>0.393096</td>\n",
       "      <td>2.933660</td>\n",
       "      <td>1.113649</td>\n",
       "      <td>2.418678</td>\n",
       "      <td>2.201597</td>\n",
       "      <td>2.413744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Twinkle, Twinkle  Bach Book 2 Fugue 7  Ode to Joy  \\\n",
       "First Order                    0.120462             0.465854    0.149393   \n",
       "Random                         0.000043             0.000057    0.000045   \n",
       "Layered                        0.049386             0.425225    0.140903   \n",
       "Independent Factorial          0.106978             0.967448    0.321021   \n",
       "FHMM-Gibbs                     3.466560            26.244396   10.208253   \n",
       "FHMM-Factorized VI             1.269999             9.735860    3.695267   \n",
       "FHMM-Structured VI             1.057090             3.776802    1.840404   \n",
       "FHMM-GAM                       0.393096             2.933660    1.113649   \n",
       "\n",
       "                       Jupiter Theme  Pachelbel's Canon  Westworld Theme  \n",
       "First Order                 0.357675           0.319722         0.400898  \n",
       "Random                      0.000054           0.000092         0.000073  \n",
       "Layered                     0.340744           0.295896         0.359022  \n",
       "Independent Factorial       0.949874           0.838226         0.898133  \n",
       "FHMM-Gibbs                 21.734635          19.622835        21.717922  \n",
       "FHMM-Factorized VI          8.161072           7.314057         8.257601  \n",
       "FHMM-Structured VI          4.279502           3.412385         5.158825  \n",
       "FHMM-GAM                    2.418678           2.201597         2.413744  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed2_df/it2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "{} &  Twinkle, Twinkle &  Bach Book 2 Fugue 7 &  Ode to Joy &  Jupiter Theme &  Pachelbel's Canon &  Westworld Theme \\\\\n",
      "\\midrule\n",
      "First Order           &             0.120 &                0.466 &       0.149 &          0.358 &              0.320 &            0.401 \\\\\n",
      "Random                &             0.000 &                0.000 &       0.000 &          0.000 &              0.000 &            0.000 \\\\\n",
      "Layered               &             0.049 &                0.425 &       0.141 &          0.341 &              0.296 &            0.359 \\\\\n",
      "Independent Factorial &             0.107 &                0.967 &       0.321 &          0.950 &              0.838 &            0.898 \\\\\n",
      "FHMM-Gibbs            &             3.467 &               26.244 &      10.208 &         21.735 &             19.623 &           21.718 \\\\\n",
      "FHMM-Factorized VI    &             1.270 &                9.736 &       3.695 &          8.161 &              7.314 &            8.258 \\\\\n",
      "FHMM-Structured VI    &             1.057 &                3.777 &       1.840 &          4.280 &              3.412 &            5.159 \\\\\n",
      "FHMM-GAM              &             0.393 &                2.934 &       1.114 &          2.419 &              2.202 &            2.414 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print((elapsed2_df/it2_df).round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_metrics(filename):\n",
    "    metrics5 = pd.read_csv(filename, header = None)\n",
    "    rmse5 = np.sqrt(((metrics5 - metrics5.loc[0,:])**2).sum(axis = 0)/metrics5.shape[0])\n",
    "    print_metrics = pd.DataFrame(columns = ['entropy', 'mutual_info', 'edit', 'h_ints', 'm_ints',\n",
    "                                           'percent', 'note_counts', 'acf', 'pacf'])\n",
    "\n",
    "    hints = metrics5.loc[:, 3:15]\n",
    "    mints = metrics5.loc[:, 15:27]\n",
    "    perc = metrics5.loc[:, 27:33]\n",
    "    note_count = metrics5.loc[:, 33:metrics5.shape[1]-2*41]\n",
    "    acf = metrics5.loc[:, metrics5.shape[1]-2*41:]\n",
    "    pacf = metrics5.loc[:, metrics5.shape[1]-41:]\n",
    "    print_metrics.loc[0] = [np.mean(metrics5.iloc[1:, 0]), np.mean(metrics5.iloc[1:, 1]), np.mean(metrics5.iloc[1:, 2]), \n",
    "                            np.mean(rmse5[3:15]), np.mean(rmse5[15:27]),\n",
    "                              np.mean(rmse5[27:33]), np.mean(rmse5[33:metrics5.shape[1]-2*41]),\n",
    "                              np.mean(rmse5[metrics5.shape[1]-2*41:]), np.mean(rmse5[metrics5.shape[1]-41:])]\n",
    "\n",
    "    print(metrics5.shape)\n",
    "    return(metrics5, rmse5, hints, mints, perc, note_count, acf, pacf, print_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics/twinkle-twinkle-little-star2__GAMGaussian_3-tol0.001.csv\n",
      "metrics/twinkle-twinkle-little-star__factorial_5-tol1e-06.csv\n",
      "metrics/twinkle-twinkle-little-star__first_order_5-tol1e-06.csv\n",
      "metrics/twinkle-twinkle-little-star__GAMGaussian_3-tol0.001.csv\n",
      "metrics/twinkle-twinkle-little-star__layered_5-tol1e-06.csv\n",
      "metrics/twinkle-twinkle-little-star__random_5-tol1e-06.csv\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "root = \"metrics/\"\n",
    "for path, subdirs, files in os.walk(root):\n",
    "    for name in files:\n",
    "        print(os.path.join(path, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 127)\n",
      "First Order\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>edit</th>\n",
       "      <th>h_ints</th>\n",
       "      <th>m_ints</th>\n",
       "      <th>percent</th>\n",
       "      <th>note_counts</th>\n",
       "      <th>acf</th>\n",
       "      <th>pacf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.326605</td>\n",
       "      <td>0.396191</td>\n",
       "      <td>0.739406</td>\n",
       "      <td>11.524452</td>\n",
       "      <td>12.36942</td>\n",
       "      <td>0.095426</td>\n",
       "      <td>0.02999</td>\n",
       "      <td>0.241441</td>\n",
       "      <td>0.218721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entropy  mutual_info      edit     h_ints    m_ints   percent  \\\n",
       "0  2.326605     0.396191  0.739406  11.524452  12.36942  0.095426   \n",
       "\n",
       "   note_counts       acf      pacf  \n",
       "0      0.02999  0.241441  0.218721  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_1, rmse1_1, _, _, _, _, acf1_1, pacf1_1, \\\n",
    "    df1 = process_metrics('metrics/twinkle-twinkle-little-star__first_order_5-tol1e-06.csv')\n",
    "print('First Order')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 127)\n",
      "Random\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>edit</th>\n",
       "      <th>h_ints</th>\n",
       "      <th>m_ints</th>\n",
       "      <th>percent</th>\n",
       "      <th>note_counts</th>\n",
       "      <th>acf</th>\n",
       "      <th>pacf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.381391</td>\n",
       "      <td>0.37994</td>\n",
       "      <td>0.816383</td>\n",
       "      <td>12.675906</td>\n",
       "      <td>12.942803</td>\n",
       "      <td>0.098597</td>\n",
       "      <td>0.045808</td>\n",
       "      <td>0.245903</td>\n",
       "      <td>0.223558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entropy  mutual_info      edit     h_ints     m_ints   percent  \\\n",
       "0  2.381391      0.37994  0.816383  12.675906  12.942803  0.098597   \n",
       "\n",
       "   note_counts       acf      pacf  \n",
       "0     0.045808  0.245903  0.223558  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_r, rmse1_r, _, _, _, _, acf1_r, pacf1_r, \\\n",
    "    dfr = process_metrics('metrics/twinkle-twinkle-little-star__random_5-tol1e-06.csv')\n",
    "print('Random')\n",
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 127)\n",
      "Factorial\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>edit</th>\n",
       "      <th>h_ints</th>\n",
       "      <th>m_ints</th>\n",
       "      <th>percent</th>\n",
       "      <th>note_counts</th>\n",
       "      <th>acf</th>\n",
       "      <th>pacf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.227016</td>\n",
       "      <td>1.082493</td>\n",
       "      <td>0.621011</td>\n",
       "      <td>13.116825</td>\n",
       "      <td>13.210653</td>\n",
       "      <td>0.1065</td>\n",
       "      <td>0.051561</td>\n",
       "      <td>0.147701</td>\n",
       "      <td>0.191065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entropy  mutual_info      edit     h_ints     m_ints  percent  \\\n",
       "0  2.227016     1.082493  0.621011  13.116825  13.210653   0.1065   \n",
       "\n",
       "   note_counts       acf      pacf  \n",
       "0     0.051561  0.147701  0.191065  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_f, rmse1_f, _, _, _, _, acf1_f, pacf1_f, \\\n",
    "    df1_f = process_metrics('metrics/twinkle-twinkle-little-star__factorial_5-tol1e-06.csv')\n",
    "print('Factorial')\n",
    "df1_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 127)\n",
      "Layered\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>edit</th>\n",
       "      <th>h_ints</th>\n",
       "      <th>m_ints</th>\n",
       "      <th>percent</th>\n",
       "      <th>note_counts</th>\n",
       "      <th>acf</th>\n",
       "      <th>pacf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.380018</td>\n",
       "      <td>1.000038</td>\n",
       "      <td>0.711783</td>\n",
       "      <td>13.081477</td>\n",
       "      <td>14.036765</td>\n",
       "      <td>0.103099</td>\n",
       "      <td>0.01826</td>\n",
       "      <td>0.260044</td>\n",
       "      <td>0.443688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entropy  mutual_info      edit     h_ints     m_ints   percent  \\\n",
       "0  2.380018     1.000038  0.711783  13.081477  14.036765  0.103099   \n",
       "\n",
       "   note_counts       acf      pacf  \n",
       "0      0.01826  0.260044  0.443688  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_l, rmse1_l, _, _, _, _, acf1_l, pacf1_l, \\\n",
    "    df1_l = process_metrics('metrics/twinkle-twinkle-little-star__layered_5-tol1e-06.csv')\n",
    "print('Layered')\n",
    "df1_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 127)\n",
      "GAM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>edit</th>\n",
       "      <th>h_ints</th>\n",
       "      <th>m_ints</th>\n",
       "      <th>percent</th>\n",
       "      <th>note_counts</th>\n",
       "      <th>acf</th>\n",
       "      <th>pacf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.530559</td>\n",
       "      <td>0.177329</td>\n",
       "      <td>0.830861</td>\n",
       "      <td>12.200932</td>\n",
       "      <td>11.764131</td>\n",
       "      <td>0.130559</td>\n",
       "      <td>0.094307</td>\n",
       "      <td>0.245112</td>\n",
       "      <td>0.223017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    entropy  mutual_info      edit     h_ints     m_ints   percent  \\\n",
       "0  1.530559     0.177329  0.830861  12.200932  11.764131  0.130559   \n",
       "\n",
       "   note_counts       acf      pacf  \n",
       "0     0.094307  0.245112  0.223017  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_GAM, rmse1_GAM, _, _, _, _, acf1_GAM, pacf1_GAM, \\\n",
    "    df1_GAM = process_metrics('metrics/twinkle-twinkle-little-star2__GAMGaussian_3-tol0.001.csv')\n",
    "print('GAM')\n",
    "df1_GAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entropy</th>\n",
       "      <th>mutual_info</th>\n",
       "      <th>edit</th>\n",
       "      <th>h_ints</th>\n",
       "      <th>m_ints</th>\n",
       "      <th>percent</th>\n",
       "      <th>note_counts</th>\n",
       "      <th>acf</th>\n",
       "      <th>pacf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>First Order</th>\n",
       "      <td>2.327</td>\n",
       "      <td>0.396</td>\n",
       "      <td>0.739</td>\n",
       "      <td>11.524</td>\n",
       "      <td>12.369</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>2.381</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.816</td>\n",
       "      <td>12.676</td>\n",
       "      <td>12.943</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Independent Factorial</th>\n",
       "      <td>2.227</td>\n",
       "      <td>1.082</td>\n",
       "      <td>0.621</td>\n",
       "      <td>13.117</td>\n",
       "      <td>13.211</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layered</th>\n",
       "      <td>2.380</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.712</td>\n",
       "      <td>13.081</td>\n",
       "      <td>14.037</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAM-FHMM</th>\n",
       "      <td>1.531</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.831</td>\n",
       "      <td>12.201</td>\n",
       "      <td>11.764</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       entropy  mutual_info   edit  h_ints  m_ints  percent  \\\n",
       "First Order              2.327        0.396  0.739  11.524  12.369    0.095   \n",
       "Random                   2.381        0.380  0.816  12.676  12.943    0.099   \n",
       "Independent Factorial    2.227        1.082  0.621  13.117  13.211    0.107   \n",
       "Layered                  2.380        1.000  0.712  13.081  14.037    0.103   \n",
       "GAM-FHMM                 1.531        0.177  0.831  12.201  11.764    0.131   \n",
       "\n",
       "                       note_counts    acf   pacf  \n",
       "First Order                  0.030  0.241  0.219  \n",
       "Random                       0.046  0.246  0.224  \n",
       "Independent Factorial        0.052  0.148  0.191  \n",
       "Layered                      0.018  0.260  0.444  \n",
       "GAM-FHMM                     0.094  0.245  0.223  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df = pd.concat([df1, dfr, df1_f, df1_l, df1_GAM])\n",
    "metrics_df.index = ['First Order', 'Random', 'Independent Factorial', 'Layered', 'GAM-FHMM']\n",
    "metrics_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  entropy &  mutual\\_info &   edit &  h\\_ints &  m\\_ints &  percent &  note\\_counts &    acf &   pacf \\\\\n",
      "\\midrule\n",
      "First Order           &    2.327 &        0.396 &  0.739 &  11.524 &  12.369 &    0.095 &        0.030 &  0.241 &  0.219 \\\\\n",
      "Random                &    2.381 &        0.380 &  0.816 &  12.676 &  12.943 &    0.099 &        0.046 &  0.246 &  0.224 \\\\\n",
      "Independent Factorial &    2.227 &        1.082 &  0.621 &  13.117 &  13.211 &    0.107 &        0.052 &  0.148 &  0.191 \\\\\n",
      "Layered               &    2.380 &        1.000 &  0.712 &  13.081 &  14.037 &    0.103 &        0.018 &  0.260 &  0.444 \\\\\n",
      "GAM-FHMM              &    1.531 &        0.177 &  0.831 &  12.201 &  11.764 &    0.131 &        0.094 &  0.245 &  0.223 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics_df.round(3).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAH0CAYAAAAUghohAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+P8WJMVx03ayiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ee5668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(old_1, lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(old_1, lags=40, ax=ax2)\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('/Final_Report/original_twinkle_ACF.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAH0CAYAAAAUghohAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS5IkSRn8G5okd+coChoZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a343cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(newNotes_GAM, lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(newNotes_GAM, lags=40, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/Final_Report/GAM_twinkle_ACF.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAH0CAYAAAAUghohAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XmcXXV5+PHPnQmEBAIJMKwBg6iPqLS41CIFF7RuuFRb\nlSoUSqtdsKgVqlRqi0qLW6u2oD9bcMG1UlQUpVVWlyqoFavig1ICMSgJkCAhIcvc+/vjnJvc3MxM\n5sycO3eWz/v1mty537N978w3d57z3Od8T6PVaiFJkiRpfAb63QFJkiRpJjGAliRJkiowgJYkSZIq\nMICWJEmSKjCAliRJkiowgJYkSZIqmNfvDkjSdBARTwWuBu4BDszMLZPY1xDwQGaur6l700ZEXAsc\nmpkPncC2ewC7Zebd5fO/Bd4MHJaZd9TaUUnqITPQklR4BbAO2Bt4wUR3EhHPARLYt6Z+TTcTunlA\nRDwO+AnwqI7m/wBOBlbX0C9JmjJmoCXNeRGxK/C7wEcpAulTgcsmuLsnAnvV07NZ5UjgwM6GzPwh\n8MP+dEeSJs4MtCTBCRRB7zXAfwLPioj9JrivRm29ml38uUiaNcxAS1KRdW4B11O8L76UorTg3e0V\nImI58H+ZeXznhp3tEfEh4JRyX8sj4tr2+hHxGOBtwFOA+cBNwPmZ+fmu/QXwVuBpwC7A/wB/k5lf\n71hnp/uKiGuAB4HvAK8FHgCeDvzLSO2Z+aOIeBRwHvBUYNfy2G/JzP8a64cXES8BTgeOAhYAK4HP\nAOdk5uay1vlvy5/LtRGxPDMfGhF/R1EDvaxdAx0Re5ev7QUUZTDLgQ8B78zMZrnO3wFvoMhqvwd4\nMrAFuBz4y8y8d6z+StJkmYGWNKdFxCLgucB/Z+Zq4EvARopAuNNotb+d7R8APlt+/xqKYJSI+A3g\nW8BvAO8EzqYIjj8bEX/W0ZeHATdQBLDvK9dbAnwlIh5fZV+lYylOBs6kCEJ/PEL7h4EfR8SRwDeB\nR5b9/muKk4kvlQHyiCLij4FPA2uAvwJeTxH0nkVxIgBFrfMHy+/Powjc2z+7Vse+FgP/Dfwh8O/l\nej8G/gH4eMdhW8AgxScG95XHvBT4A+DC0foqSXUxAy1prvs9YDeKII/MvD8ivgo8NyIen5nfHe+O\nMvPbEfED4HeAz3fMLPHPwDDwhMz8BUBEvJ8iYH1nRHy6zJqeRxEY/mZm3lau92ngZxQB6YkV9gWw\nEHhFZn6n3cciwT1i+z8Dq4DHZuaDHW3XAO+NiM+OMjPJXwLfyMwXdezrQoog+tnAGzPzhxHx38Ar\nga9k5vWj/AjfCDwM+J3M/ELZ9oGI+BfgzyLiI5l5Zdk+D/hkZv5V+fxfI2Ip8KKI2K39GiSpF8xA\nS5rrXk6R0fxsR9tlFDW7fzjZnZe11E8EPtoOeAEycxNFBnkB8NsR0QCeA3ypHTyX691LkTE+Y7z7\n6jj8hs4gebT2smziyRTZ990jYp+I2Ici+/05YH+KjPdIjqSoIe90AEVGeo9RthnN84GbO4LntrdS\n/D5e2NHWoigT6fR9isB6n4rHlaRKDKAlzVkRcQBFrfEt5fOHRMRDgB9QBGgnRsQukzzMsvLxlhGW\n3UwRGD6EIujbA/hp90qZ+ePMXFVhX233jNKn7vbDy8e/oJhSrvOrXQd+6Eg7ysxh4IkR8W8R8fWI\n+CXwc4rAuurfmMMopgDsPsZdwFq2f22w4/R3G8vHwYrHlaRKLOGQNJf9PkWQ9wjgtq5lLYoM7Asp\n6mtHs7NgbazZJ9oB5qaO/Yw1z/J499U2PMq63e3tY19AkXEeyY9GaizLPE4HvkdRv/xRinKSC4BD\nxujvSHb2+jZ1tTUr7l+SamEALWkuezlFEPYHFDdR6fTrwLkUc0JfShF0zu9cISIGKWaK+NkYx1he\nPj5yhGXttjuAu4ENbMsGdx7n9RRzKL9znPuqqt3HLZl5ddexj6DIDO9wV8WIOJQieP5IZv5h17ID\nJtiPGOE4+wN7MrHXJkm1s4RD0pwUEQ8HHg9ck5mfyMzLO78oZn74JfDMiDiw/D4iojOIfiHFBYid\n2tndAdhafvAd4KSIOKjj+LtQXID3IPDVshTivyguXjy4Y70lFBcQLhvvvqr+LDLzl+V+Ty1fa3u/\n8yhm7/gMIydc9i4fb+5sjIjnAg/v2ma7n8sovgAcERHdd4I8myIz/8WxX4kkTQ0z0JLmqvbczxeN\ntDAzt0TExRTTuZ0MfIJiDuX/jIiPUQSIr2Rb9rZtNUUpwl9FxJfLC+LOAK4CvlPOUHF/uc/HAn+R\nmb8qtz2bYoq6G8uZJ35VHmN34JxynfHuq6r2fr9b7vceigz9b1DMpLFmhG1+TJEV/uuIWEBR+/yb\nFFMAbgAWjfBz+fOIODAzPznC/v6B4o6Qn46ID1DUej8DeBFw6c7mo5akqWIGWtJc9fsUF6Z9dox1\nPkiROf2DzLyQ8qYfFHM0P5liurruW1F/CvgKRenH+QCZ+S3gtyiyvK+nmFViPfDCcr+U6/0EeBLw\nbYqs87kUNyX5rXLZuPdVGs/c1e1jt/d7I0U2+x0Us3qckpnv7Fq9VW6ziWLmkP+mCMDfSRnIU9zo\nZM+IeGy5zVUU80U/F/jn8vbp3X1YAxxNUUf9MooLGKN8nS8b5bVI0pRrtFpjXa8iSZIkqZMZaEmS\nJKkCA2hJkiSpAgNoSZIkqYIZNwvH6tX396Voe8mShaxZs8M0qFItHF/qNceYesnxpV7q1/gaGlo0\n6s2dzECP07x53hlWveP4Uq85xtRLji/10nQcXwbQkiRJUgU9KeEoJ8AfyMxXjbHOE4D3UMwZ+nPg\nbZl5SS/6I0mSJNWl9gx0RLwFGDVwLtfZF7iS4kYAjwX+GbgoIp5Rd38kSZKkOtWWgY6Iwyhuifto\n4PadrP5KYG1mvrZ8fktEPA44E/hqXX2SJEmS6lZnBvoY4A7gSGD5TtY9Fri+q+1aitvISpIkSdNW\nbQF0Zn48M0/NzFXjWH0psLKr7U5gYUTsXVefJEmSpLr1ax7ohcCDXW0by8fdprgvY1q1dgMXX3Ez\nt668j8MP3ovTTjiC/RYv6He3JEmS1Cf9msZuAzC/q639/IEp7suYLr7iZm5ZsZbhZotbVqzl4itu\n7neXJEmS1Ef9ykCvAA7sajsIWJeZ94214ZIlC6d0Qu1bV963w/OhoUVTdnzNHY4r9ZpjTL3k+FIv\nTbfx1a8A+uvAqV1txwPf2NmGU30rx8MP3otbVqzd7vnq1fdPaR80+w0NLXJcqaccY+olx5d6qV/j\na6ygfUpKOCJil4jYPyJ2KZsuAoYi4v0R8ciI+AvgRODtU9GfKk474QjWrf4ZreYwjzhkMaedcES/\nuyRJkqQ+6lUGutX1/BjgauBpwPWZuSoing28D/gexbzRJ2fmdT3qz4Ttt3gBt177PgYGGnzoxv/t\nd3ckSZLUZz0JoDPz+K7n1wGDXW03AEf34viSJElSr/RrFg5JkiRpRjKAliRJkiowgJYkSZIqMICW\nJEmSKjCAliRJkiowgJYkSZIqMICWJEmSKjCAliRJkiowgJYkSZIqMICWJEmSKjCAliRJkiowgJYk\nSZIqMICWJEmSKjCAliRJkiowgJYkSZIqMICWJEmSKjCAliRJkiowgJYkSZIqMICWJEmSKphX144i\nYgA4DzgFWARcCZyematGWf944B+ARwO/AD6Yme+sqz+SJElSL9SZgT4XOBk4CTgOWApcOtKKEXE4\n8AXgcuAxwBuAv42IP6uxP5IkSVLtagmgI2IX4Azg7My8OjO/D5wIHBsRR4+wybOB9Zl5XmYuz8zL\ngCuAZ9XRH0mSJKlX6spAHwXsAVzXbsjM24HlFNnobquBvSPixIhoRMRjgCcDN9bUH0mSJKkn6gqg\nl5aPK7va7wQOGWH9/wAuBj4ObAJ+AFybmefV1B9JkiSpJ+oKoBcCzcwc7mrfCOw2wvqLgWXA+cAT\ngD8AnhkRf1dTfyRJkqSeqCuA3gAMlDNxdJoPPDDC+u8ANmfmmzLzpsz8GHAm8MaIWFJTnyRJkqTa\n1TWN3Yry8UC2L+M4iB3LOgB+E7isq+3bwK7AocCa0Q60ZMlC5s0bnHhPJ2BgoAHA0NCiKT2u5hbH\nl3rNMaZecnypl6bb+KorgL4JWAc8BfgEQEQsoyjTuH6E9X8O/FpX25HAMHDrWAdas2b95Ho6Ac1m\ni4GBBqtX3z/lx9bcMDS0yPGlnnKMqZccX+qlfo2vsYL2WgLozNwUERcC74qIeyhm2bgAuCYzbyin\nudsbuDczNwPvBb4QEW+iCLgfDbwbuCAz19XRJ0mSJKkX6ryRyjkUs2pcAlwF3Aa8pFx2DMWMHE8C\nyMwvAy8GXkiRvf5H4APA62vsjyRJklS72m7lXc7AcVb51b3sOmCwq+1yijsRSpIkSTNGnRloSZIk\nadYzgJYkSZIqMICWJEmSKjCAliRJkiowgJYkSZIqMICWJEmSKjCAliRJkiowgJYkSZIqMICWJEmS\nKjCAliRJkiowgJYkSZIqMICWJEmSKjCAliRJkiowgJYkSZIqMICWJEmSKjCAliRJkiowgJYkSZIq\nMICWJEmSKjCAliRJkiowgJYkSZIqmFfXjiJiADgPOAVYBFwJnJ6Zq0ZZ/2DgvcAzgQ3ApcDrM/PB\nuvokSZIk1a3ODPS5wMnAScBxwFKKoHgHEbEr8FVgMfAk4KXA84B31NgfSZIkqXa1BNARsQtwBnB2\nZl6dmd8HTgSOjYijR9jkFcD+wIsz80eZeR3wZuCJdfRHkiRJ6pW6MtBHAXsA17UbMvN2YDlFNrrb\nM4GvZOavOtb/SGaOFGxLkiRJ00ZdNdBLy8eVXe13AoeMsP4jgKsi4i0UJR8t4DLgnMzcWFOfJEmS\npNrVFUAvBJqZOdzVvhHYbYT19wT+GPgS8HvAwcAFwBBwak19kiRJkmpXVwC9ARiIiIHMbHa0zwce\nGGH9zcA9wMmZ2QK+V15Y+O8R8brMXDPagZYsWci8eYM1dXt8BgYaAAwNLZrS42pucXyp1xxj6iXH\nl3ppuo2vugLoFeXjgWxfxnEQO5Z1ULZtKIPnth8DDWAZMGoAvWbN+kl1dCKazRYDAw1Wr75/yo+t\nuWFoaJHjSz3lGFMvOb7US/0aX2MF7XVdRHgTsA54SrshIpZRBMPXj7D+14CjIqIzlXwksIXiwkNJ\nkiRpWqolA52ZmyLiQuBdEXEPsJqipvmazLyhnOZub+DezNwMfAB4NfDR8kLCQyjmgP7IWOUbkiRJ\nUr/VeSOVc4CPA5cAVwG3AS8plx1DMSPHkwDKuxM+mSKo/i7wMeAzwJ/X2B9JkiSpdrXdyrucgeOs\n8qt72XXAYFfbT4Dn1HV8SZIkaSrUmYGWJEmSZj0DaEmSJKkCA2hJkiSpAgNoSZIkqQIDaEmSJKkC\nA2hJkiSpAgNoSZIkqQIDaEmSJKkCA2hJkiSpAgNoSZIkqQIDaEmSJKkCA2hJkiSpAgNoSZIkqQID\naEmSJKkCA2hJkiSpAgNoSZIkqQIDaEmSJKkCA2hJkiSpAgNoSZIkqYJ5de0oIgaA84BTgEXAlcDp\nmblqHNt+EViYmcfX1R9JkiSpF+rMQJ8LnAycBBwHLAUu3dlGEfEnwHNr7IckSZLUM7UE0BGxC3AG\ncHZmXp2Z3wdOBI6NiKPH2O5hFFnrb9bRD0mSJKnX6spAHwXsAVzXbsjM24HlFNnoHZQlHx8Bzgdu\nrqkfkiRJUk/VFUAvLR9XdrXfCRwyyjZ/DTQz81019UGSJEnqubouIlxIEQwPd7VvBHbrXjkiHg+8\nDnhCTceXJEmSpkRdAfQGYCAiBjKz2dE+H3igc8WImA98FDgnM2+reqAlSxYyb97gpDpb1cBAA4Ch\noUVTelzNLY4v9ZpjTL3k+FIvTbfxVVcAvaJ8PJDtyzgOYseyjt8EHgm8PSLeUbbNpwjAfwU8KjN/\nPtqB1qxZX0+PK2g2WwwMNFi9+v4pP7bmhqGhRY4v9ZRjTL3k+FIv9Wt8jRW011UDfROwDnhKuyEi\nlgHLgOu71v028HCKCw9/vfz6LHBj+f2dNfVJkiRJql0tGejM3BQRFwLvioh7gNXABcA1mXlDOc3d\n3sC9mbkR+L/O7cvM84aJlHRIkiRJU6nOG6mcA3wcuAS4CrgNeEm57BiKzPKTajyeJEmSNOVqu5V3\nOQPHWeVX97LrgFGv/MvMV9bVD0mSJKmX6sxAS5IkSbOeAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQk\nSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJ\nklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklTBvLp2FBEDwHnAKcAi\n4Erg9MxcNcr6LwPeCDwcuBO4CHhnZjbr6pMkSZJUtzoz0OcCJwMnAccBS4FLR1oxIp4DfAz4IHAk\nRSD9BuDsGvsjSZIk1a6WDHRE7AKcAbw6M68u204EbouIozPzW12b/Anwmcx8f/n8toh4FPCHFFls\nSdIctWrtBi6+4mZuXXkfhx+8F6edcAT7LV7Q725J0lZ1ZaCPAvYArms3ZObtwHKKbHS3twJv6Wpr\nAUtq6o8kaYa6+IqbuWXFWoabLW5ZsZaLr7i5312SpO3UVQO9tHxc2dV+J3BI98qZ+d3O5xGxJ/Cn\nwJdr6o8kaYa6deV9Yz6XpH6rKwO9EGhm5nBX+0Zgt7E2jIgFwOfK9ayBlqQ57vCD9xrzuST1W10Z\n6A3AQEQMdM2iMR94YLSNImIf4AvAI4FnZOaKnR1oyZKFzJs3ONn+VjIw0ABgaGjRlB5Xc4vjS702\nU8bYWSc/gd9/3QfYfZ/DeMzD9uO1Jz6WoX1273e3tBMzZXxpZppu46uuALod+B7I9mUcB7FjWQcA\nEbEM+C9gd+C4zPzReA60Zs36ifdygprNFgMDDVavvn/Kj625YWhokeNLPTWTxtggcOu17wPgQ9/9\nITSbM6bvc9VMGl+aefo1vsYK2usKoG8C1gFPAT4BWwPkZcD13StHxBBwDbAJeFJm3lFTPyRJkuac\nVqu13Vez2Ry5jdYoO9i2n5EXt/dRLG82W7Ra0Go1aTVbNGnRoLF1/62t+yu3brWg0aj4mspvBrZQ\n461LalFLbzJzU0RcCLwrIu4BVgMXANdk5g3lNHd7A/dm5mbgwvL58cDGiNi/3FVrtBuvSJKkwliB\nUuc63d93rtP5L60dA6dtgVBX+wiBVmNgC3ff86ttAVZrW5hWBF6d2xbLuvezdW8tup5vv3yU+G5C\nRn5t23egNUZfaHX2q/vn1/E4ymsc5emoQWzHrtiuqy1oNYoAlkajbG/QaDRoAY1Go3hOA0aIYRs7\nCWw7l2/dV9nWaDRoNAZ2uo/JuGfNOvbZa3HP9j8RdYbz55T7uwTYhWJGjVeXy44BrgaeFhE3AC+i\n+BXe0LF9A9gC7FpjnyRJs1Sz2WTLli0MDw+zefNmNm4qvh9utmi2iq+JarXa2TS2RizNVhEINhqN\nruC0yMKVkcq2TFtn0NQZjHVuy/bBWbPjuNuCXnZ4bNEqApYRgiXYMeBpb9toR08dsU534DNaIDR6\ngNRgfXMj993XnJJgqqcao3xfcdMJbK4ZprYAupyB46zyq3vZdRRlbbUfV9LctmMGaezn7bbujNxI\nGbr2x52t9keWrebWjy8n0rduzWZ3S2uE/rMtctpuze222hYYjWLT5vXce++o13RXNurHwJ3rlFnN\nzgBupOxjO8BsB6stYPOWYlKnny2/c2tWc7j9WH503Gy1aDQGGRgcZGCg+BocnII/L90vvUGlaGms\nGG1qL5Gvz7x58xgcnKm9l6ozkNWc1f7Ys/Pjzx1qxsrgqUWrrPdqrwftYKdYXgZLje5s0bYM1FgB\nw30P/Ip77nlg6/Lttm91ZKm6tt320WeLzj/FO4Q2XRmv7ZeN/nRnAeBoi1ujPhnf9uO1syCuMyPX\n2dZubAd2O2buGttl6oqsWqNj+Q5HqtTvsTN8k80GjmL9IGsfnElv+cXr29JYUHw7UMy7OoB/uCT1\nn+9D01Sr1dr60eSWLVto0WJ4eLjIvgx3BHq0i/jp+L4jwzNW4LTd8XrzGsY+VsfyEb7t/FhztNq4\n7o9CocxK0f6ZtDOK2x+7/dFuo9GeCr34KHSs4GlbwNL5vJ6PKzdsmc+mVtc06o2uxxGMYxVJklQz\nA+gpsGnTJlbdfS8tGkVtXnPblazN9iPFFa3N7T6aHIDGAAONQRoDje1qywYGZkmN2VhtFXfV/r6u\nuwNJkiSNxAB6CvzfHb+AXfbccUEZ6TUGi7o3q8cmZ+26jXzpW3dw593rOGjfPXju0YeyeI/5/e6W\nJEmaZQyge+yXd61mS2M3f9BT4EvfuoOfr14HwM9Xr+NL37qDlz/j4X3ulSTtnAkAaWbx0+4e2vDg\ng9y1dgPz5jkz31S48+51Yz6XpOmqnQBotrYlACRNXyZGe2j5z+9i/m4jlG6oJw7ad4+tGej2c0ma\nCWZqAmBr5vyeBzhon93NnGvOMAPdI7/45WqaAwv63Y055blHH8r9q35KsznM0qHiI9CpsHbdRj7x\n1Z/yrk/9D5/46k9Zu27jlBxX0uzRfcI/UxIAWzPnzZaZ81nMv3M7MoDugQ0PPsiq+zYwOLhLv7sy\npyzeYz551Xv53qdfw8uf8fApy4L40aukyepXAmCyZmrmXNX4d25HlnD0wG2Wbswp/gGZObxQS9NV\nOwEA8MbLv9Hn3oyfpXNzg3/ndmQGuma/+OVqWpZuzCkz9aPXucgsilSvdua8NcMy55MxF8sZ/Du3\nIwPoGm148EFWrX3Q0o05ZqZ+9DoXmUWR6tXOnP/PZ147paVz/TQXT8T9O7cjSzhqdNuKu5i/wNKN\nuWamfvQ6F/lxs6TJmosn4v6d25EZ6Jrc+ctVtAYt3ZiLH21p5jCLImmyLGcQmIGuxfoNG1i9diPz\nF/ifyLsBTq3JXBQ3Fy+oM4siabKee/ShvPuiz7P7vg/l0P33qnQiPhffd2crM9A1WP7zVQbPpbn4\n0VY/TaYWby7W8fWLn8xIs8dkpkz1fXf2MICepJW/WEVrcGG/uzFt+NHW1JrMCYsnO1PHP5qSwPfd\n2cQAehLWr9/A3b/ayODg9KuE6VfGyxrTqTWZExZPdqaOfzQlge+7s4kB9AS1Wi1uW7mK+btNz8Hf\nr4xXv+4GOFdN5oTFk52p4x9NSeD77mxSW+o0IgaA84BTgEXAlcDpmblqlPWfALwHeCzwc+BtmXlJ\nXf3ptTt/uYrWwPQt3ZhMxsuLHGaOyVwU5wV1U2cyFx1Jmj1835096sxAnwucDJwEHAcsBS4dacWI\n2JciwP4ORQD9z8BFEfGMGvvTMw88sJ67f7WJefOmX+lG22QyXtZrqpfm4gV1fjIjSbNLLQF0ROwC\nnAGcnZlXZ+b3gROBYyPi6BE2eSWwNjNfm5m3ZOa/AB8DzqyjP73UarVYvnL1tC3daJvMx0TWa6qX\nPEGTJM10dWWgjwL2AK5rN2Tm7cByimx0t2OB67vargV+q6b+9MzKX9w1I2bdmEzGy3pN9ZInaJKk\nma6uAHpp+biyq/1O4JBR1h9p3YURsXdNfardAw+s555fbZ7WpRt18CIH9ZInaJKkma7RarUmvZOI\neAXw4czcpav9KuDWzHxVV/tPy/XP62g7jiILfUhm3jnasQ49tDn5Dld0550rgQb7Du1HozFzJi5Z\nteoXAOy334EzZtvJ6texJ3vcgYEGzQkO7Zn2u9p19/Uc/LgbWXLgOh64Z29u+9avs+mBqftUZ6aO\nkYnadff1HHb0Teyx7xrW3b1kyn/eE9XP95F+mamvedWqX9AAhqb4feSwo29i933X8EAfxvVMe9+t\nQz/7PTAAgwNTH3/dccdAY7RldQXQLwY+A+ySmc2O9q8DN2bm67rW/wHwucx8c0fbM4D/BPbOzPtG\nO9ayZa0WjPp6eqbZHGbLcItGo9qx7/plcS6w/wEHTei4k91+JurXa55rx52sfvZ7rv2uJnPchz/t\nmyza796tz+9ftTc/veaYKTn2TPx5TXb7ufiaJ2Oix+3nuO6nmTg2J3vs9rZLl45U0NBby5ePHnDW\nVYuwonw8kO1LMw5ix1KN9vrdpzAHAevGCp4BbryxP/WSQ0OLuO6bP2Rg1z0rbffSFxRl3Z/63MSm\nq5ns9jNRv15zP487MNDgU5/7+pQed7L6OTbn4hiZ6HHf9al76fxwY6/97+VTnxvpbbn+Y/fj57V2\n3cYdpgysOuvJTHvNdRx3stsvXryQtWvXT9lx+zmu+2kmjs3JHrv4Gwk33vjjurs1DotGXVJXPvwm\nYB3wlHZDRCwDlrHjxYIAXwee3NV2PDCtR/KypfuxcYMXPElz0dp1G4mnv4bHvey9M2r6vblWc/6l\nb93Bov0ezsDAoLO8zGJzbVxr+qklgM7MTcCFwLsi4lkR8Tjgk8A1mXlDROwSEfuX090BXAQMRcT7\nI+KREfEXFNPevb2O/vTKwgULGFo8n+Hhzf3uiqQpNlMDs+cefShLh/ZgYKAxJy4KdpaXuWHruG4w\nJ8a1pp86p5M4p9zfJcAuwJeBV5fLjgGuBp4GXJ+ZqyLi2cD7gO8BtwMnZ+Z1O+x1mjnogP1Y+9Pb\nYXCXna8sadboV2DWznzvvu9D+cRXf1q5JGHxHvOLqSwn8BH7ZI/dDwftuwc/X71uu+eafdrjWuPT\nz//LM/F9ZDxqC6Azcxg4q/zqXnYdMNjVdgMw0k1Wpr3DDtmfW5avZv4C35iluaJfgVk78w3bbjwz\nVYFDP489Uc89+lC+9K07uPPudRy0r5nJ8ZitAY628X2kfrN7QuMeWbDbbgwtns+a9ZsZNBMtTal+\n/bHvV2DWz5KEmVgOYWayutka4Ggb30fqN3MmNZ5mDjpgPxrNDf3uhjTn9KsWuR2YnXniYyvf3XMy\n+nmxlBdqzQ2zNcDRNr6P1M8AehIOW7o/Gx+8v9/dkKZcP2ekmGt/7Pt5sZQXas0Mk/3/OFsDHG3j\n+0j9LOHgtf8MAAAgAElEQVSYhAW77cZ+ey3gXks5NMf08yPfuXaRWD9LEiyHmBkm+//RuvHZz/eR\n+hlAT9KBBwyx9mfOylEXL2aZGfqZBfaPvbS9yf5/7FeA4/u9dqY9RvbY96Gc//HvcdoJR7Df4gX9\n7hZgCUctllnKUZuZOtfuXNPPj3z7VYssTVcztQSjX+/3M/WmSHNRe4w0Bga5ZcVaLr7i5n53aSsD\n6Bos2G039l+8gC1bNvW7KzNev+fa9Q11fGZrTZs0Gf16H5mp/x/79X5vombm6B4Tt668r0892ZEl\nHDU5YP8h1t5/O7Brv7syo83FuXZnotla0yZNRr/eR2bq/8d+vd/PtQuRZ7LuMXL4wXv1sTfbMwNd\no8MOOcBSjknqVybFN1SpXjP1U53J9Nv3kWr69X4/U0te5qKtY2QAHnHIYk474Yh+d2krM9A1mj9/\nPvsvWcjd929i3jwz0RPRr0xKvzIhnRdIeBGNZpOZ+qnOZPo912aImax+vd97IfLM0R4jQ4sb7LPX\n4n53ZztmoGt2wH77Mq/1YL+7oYr6lQnpvEDCWjzNJjM1GzuZfs/UWuS5xguRVQcz0D1w2CEH8JPl\nv2T+bnv2uysap35lQmZqkCHtzEzNxk6m3zO1Flkzg9P+TS9moHtg/vz5HLBkDzZvnlzN30ytIdT4\nWYun2WqmZmNnar81+zl7yPRiBrpH9t9vH9bcf/uk9jFTawg1fltr8e55gIP22d0/1po1Zmo2dqb2\nW7Ofn1hOLwbQPfTQQw6k1WrSaEws0e9/ltmv/cd68eKFrF27vt/dkSRNUzO1LGq2soSjh3bddVcG\nBxq0Wq0Jbe/H+5IkCSwvmm7MQPfY4OAgzeaWCW3rVDuSJAksL5puDKCnwLx5g+w5fxOtFjRb0Gy2\n2DLchFarbGsx3GzRBFrNFsPDLZqtFrs24EXHHFCUgDQaNGixceODDAwM0Gg0aDSKx4EBP0iQJEma\nKgbQU6DRaHDQAftX3q7VajE8PMzw8DDNZrP4ahWPw8NNms1W2V5kuJtlQA4tmmXVyHCzSaPRGOUA\nYxy7cm+3dnrMfY1UzTJSicu2ptbWh9b2LVtX6ly1BbTKb1rlslareNJsr9/eV3kyQ4PyBKVBo9Gg\n1Sp+Zy3o+NkVy2lsaytOYhoUO9j2fFu7JEmajWoJoCNiCLgA+G1gE/Ah4K8zsznK+vOANwEnAwcA\nPwHekpmX19Gf2aLRaDBv3jzmzfM8p5darRatVnEy0v6+/bXD8jJcbzVb5cnMtnWaTWi1mrSazY5g\nv7X1ZKB9ctOCjrbi+cJ5gzw4uLH4VILtTzRaHYE/XScH7fU7zjN2eG2jvu6dPO/sxI7LRn862jEn\ncilApU12snL38du/S9onRB0nQmOeRBXfVjLWCdVIy0Zef+cHHes47ZPxiRrPSeFo63hCKWm2qSsy\nuwwYBo4DlgIfATYDfzPK+ucBJwGvpAieXwpcFhFPzcyv19QnaVzaGeN+lsIMDS1iz93v79vx56KR\nTpLG87x90jPGnndy4G3H39bU2uHEo9Ua62RkjBOj1sjf77v3ILs26xjjO/a1c9nW445wAjbaCWVn\nX1sdJ4XtT9WazaKsrdVssaXZ/vStXA40GoM0BgYZHBxkoHyUpF6adAAdEU8CjgEOy8w7gB9GxFnA\n+yLiLZm5uWv9BvDHwNmZ+aWy+fyIeAZwKjBrAuhVazdw+FPPYPd9DuP8j3+P0044gv0WL+h3tyTB\nnCu1GRpaRIPZd9eyZrPJli1b2LJlC5u3bGbTpmG2bNnMcLNFi9aEf8fN5rZtO4P6zhKy7k+TOhYx\navlZZ+lZxydHra4Tjq2fMLW2X779CUi7JK3sa6Mxwvnbttff+bNojdDWvf72raP8HMvmjRsH2LRp\n43albZa1aTarIwN9LHB7GTy3XQvsCRwF3Ni1/gDwEuB/u9qbwJIa+jNtXHzFzewx9DAAblmxlouv\nuJk3vuJxfe6VJM0eAwMD7Lrrruy666797krfjFZ61rm8yvdjPd+hvXzcd589WL1bY2tpW6sd/HeU\nxxXrb/8pRKtVVnpuPVnZ8bV1HmeHcrUJThM70msYqXRux8O0duhD90nVSP3sPkEa6fvuToxWOtcq\nasy2O6na7oSste2zncbAAI3WtnK07cvSRtcY5ffRWca2/cnR3LsWqI4AeimwsqvtzvLxELoC6Mwc\nBq7ubIuI3wCOB/60hv5MG7euvG/M55IkTdZ0CFb23HMRGzf2tQvqsEPZWdeJTPe6O9tXp/b1QO1r\ngYq29jF2vBYIioC+81OdqvbbZx+GJzYjcM/sNICOiIcAt1Gc23S/8geBj5WPW2XmlohoAbuNY/8P\no6ih/hbFxYezxuEH78UtK9Zu91ySJKmXpsNJVZ32XrKI1aun13VC48lArwQeOcqyJnAGbF9YV86y\n0QAeGGvHEfF44IvAL4Hnl9npMS1ZspB58/pzgcjQ0KJK65918hN4z6f+h58sv5dHLtub1574WIb2\n2b1HvdNMV3V8SVU5xtRLji/10nQbXzsNoDNzC3DLaMsjYgXwnK7mg8rH7tKOzu2eCVwK/A/wgswc\nV33DmjXrx7Na7YaGqp/9DAKvf+mvb2toNqfdGZSmh4mML6kKx5h6yfGlXurX+BoraK9jTqOvAw+N\niIM72o4HfgV8f6QNIuI44PMUtdDPHG/wLEmSJPXbpC8izMz/johvAZ+OiL+guDHK24F3l9lrImJ3\nYI/MvCsidgU+ASRwOrA4Itq725iZa3c4iCRJkjRN1HXniBcBdwHXAxcBH8zMt3YsP5NtM3M8haLE\n40jgjrK9/fXvNfVHkiRJ6onGzqYvmW5Wr76/Lx22vku95PhSrznG1EuOL/VSH2ugR53KpH/3LpYk\nSZJmoBmXgZYkSZL6yQy0JEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0\nJEmSVMG8fndguouIAeA84BRgEXAlcHpmruprxzTjRcQHgIHMfFVH2zOBtwMB3AK8MTOv7FMXNcNE\nxH7AO4HfBhYA3wZen5k/Kpc7vjRhEXEw8B7geIoE3JXAX2bmL8rlji/VIiKOBr4GPD0zry/bptX4\nMgO9c+cCJwMnAccBS4FL+9ojzXgR8RbgVV1tjwI+D3waOAq4HPhcRBwx9T3UTBMRDeBzwMOA5wNP\nAu4DroqIJY4v1eAKYC/gKcCTgQMpxpHvX6pNRCwELqEjRp2O48sM9BgiYhfgDODVmXl12XYicFtE\nHJ2Z3+prBzXjRMRhwEXAo4HbuxafAfx3Zp5fPn9zRBwLvAb406nrpWaoXwd+EzgiM28BiIiTgXuB\nE4BjcXxpgiJif+DHFFm/O8q2fwQ+GxF7UYwjx5fq8E/AHcBDO9qm3fgyAz22o4A9gOvaDZl5O7Cc\nIhstVXUMxRvDkRTjqNNxwLVdbdfiWNP43AE8rx08l5rl4xIcX5qEzLwrM1/eETwvpQhcbsjM+yhO\n0K7t2uxaHF+qICKeCzyHIqHU6Fg07caXGeixLS0fV3a13wkcMsV90SyQmR8HPg4QEd2Ll+JY0wRl\n5r3Al7uaXwPsBvwX8DYcX6pBRHwWeCHFpxtPK5t9/9KkRMS+wL9RXHO2tmvxtBtfZqDHthBoZuZw\nV/tGij9KUp0WAg92tTnWNCER8QLg74F3Z2bi+FJ9zgGeCHwD+EpEHITjS5P3AeBzmfmVjrZW+Tjt\nxpcB9Ng2AAPlTByd5gMP9KE/mt02UIytTo41VRYRp1Jc7PzJzHxD2ez4Ui0y80eZ+R3gRGCQImO4\nHseXJigiTqEomz2zbGp0PU679y8D6LGtKB8P7Go/iB0/SpAmawWONU1SRLwJuBi4MDNP7Vjk+NKE\nRcR+EfGyzrbM3AD8H8U4cnxpMk6hKNO4KyLuB35Stn85It5PcY3HtBpfBtBjuwlYRzFlDwARsQxY\nBlzfny5pFvs6HWOt9DQcaxqniPgr4C3AOZn52q7Fji9NxkOAT0bE49oN5ewbQTE7xzdwfGniXgE8\nimI2oV8HnlW2/xHwN0zD8dVotVo7X2sOi4h/oDgz+kNgNXABsD4zn97XjmnGi4hrgJ+2b6QSEY8B\nvgOcD3yS4g3l9cDjyhpWaVQR8WvAd4EPU9SodrqfYkoox5cmpJxn/BpgT+BPgC0UY2kZ8FgcX6pR\nedOeFcBTM/P66fj30Qz0zp1DMWvCJcBVwG3AS/raI80W2529ZuYPgRcBvwv8D/A8imnJ/OOj8XgZ\nxXv6aRRXp3d+vdbxpcnIzBbwYuD7wBcoguk1FAHOeseXemDr38jpOL7MQEuSJEkVmIGWJEmSKjCA\nliRJkiowgJYkSZIq8FbekqaFiPgQxYw3nZoUE+XfTDGv8UdrPuYQ8EBmru/owx9k5mDF/Xy43G5c\nSYmIWASsorgRwFGZ+YNKHd9xf7sC+2bmnZPZz3QUEW8D/hpYWvX1lTNHHJqZt5fPnw58BTgpMz9R\ne2clzRlmoCVNJy3gNcBJ5dcpwNkUgfSHI+J1dR0oIp4DJLBvR/MHgJMnsLsWXbOq7MSLgV0o7q51\n6gSOt1VEHAb8EHjqZPYzjVX92QJb5yi+gWK6q7YfUoyrb9TTNUlzlRloSdPN5zPzjs6GiLiY4mYN\nb46If8nMzTUc54nAXp0Nmflt4Ns17HtnXkFxo6ZfAi+PiLMyc3iC+3oo8LDaejZ77As8HvhsuyEz\n7wLMPEuaNDPQkqa9zHyQYu7ZPYFH17TbRk37qSQi9mfbHbS+DOwHnDCJXfbldcwA/lwk9YwZaEkz\nRbN83Pq+FRF/SnGX0CMoSiKWAx/KzHd0rHMbRd3rAPBy4B6Km0GcQFEasDwirs3M40eqZY6I44Ez\nKTLWe1LULn8ReENm3jeB1/H7ZV+uAb4HvK98DZd3rhQRHwNelpm7jNYeEX8E/Gv5Oj4WER/OzF3L\n9fYBzgOeD+xDcROoi4F3Z2azY397Am8Ffocia/sz4J8y88Md6+x0X2Wt8msoSlIuABYAfwE8HHht\nR/tC4NWZ+dGIWAK8rTz2PsCtwPsz81/G+gFGxOOBNwG/BSwB7gW+CvxVZt7ZUevcAt4WEW8FDqEY\nJ9vVQEfEIHBW+Tt4CHA38DngzZl5b7lOe39Pp7hhzYuB3SlKQf6yvMmDpDnEDLSkaa+8GOxpwEaK\nUo52wHYhRV3r6yhqpTcA55eBdaffB46kCPA+SBG0tT/afw1FcAhd9bYR8UzgvyiCvr+hCAi/DbwK\n+H8TfDkvL/v5X5n5c4rb0z6nDFI7jVb729l+DcWtbRsUP4uTy37vXfbzFIrb3r6Oot777cDWCzHL\niw+/AfwpRdD4WoqTkIsj4s+q7Kvs024UQfK7gHcDXy+Xdba/C/h6ROxRHvtE4CKK38OPgfdFxD+N\n9sOLiKOAr1EEu+cBpwNXUvyO/71c7YcUt/ltAJ+hqHu+t6OfnT4D/D3F3c1eC1xG8fv9WtnHTh+i\n+ATk74B3UATwXyzHp6Q5xAy0pOlm74h4oPx+HnAYRdB2JPCPmbk+IuYBrwY+kZl/1N4wIi6iyBA/\nm+KCwLbdgBeUNbDtdX9Akfncoea6w2uB24Gnd9Qo/7+I+GZ5jEoi4mHAE4DLyrIUgP+gqNU9CXhv\nlf1l5v9FxFXAG4FvZuany0V/TfFze15mfrlse39EfAB4ZZmp/irwJ8CjgJdm5n+Uffw3isD3bOD9\nFfYFRVLm/Mx8T8drHq39bcAy4HGZ+ZOy+f9FxNuBMyPiXzPzxyO87D8HNlHcQvr+su1fI2Ih8LsR\nsSgz74qIyymC+Jsy85Mdfdka7EbE8yjGwDsz8w0d7d+kqJV+I3BOx7FXZOZxHettpsjePxm4boS+\nSpqlzEBLmk4aFGUNq8uvX1BkKZ9PUepwNkBmbqGoHf6Tru2HgF8B3ZnDn3UGzxWcADyh8wK/MlM8\n0jHG4xUUGdDLOtouo3jdp05gf6N5PvC/HQFv21vLY72wfH4C8Mt28AyQmS2KbO5TKu6r7Wuj9Km7\n/cUUF1Kujoh92l8UmfAGo9SFZ+argId2BM/tMpT2Ccnuoxx/JC+g+H2c33WMT1GUsnS/tsu6nn+/\n7OsBFY4paRYwAy1pOmlRBJmryufDwFrg5szc1LXuZuD5EfECIChqbZeU++hODqxiAjKzFREPi4hT\nKT66Pxw4uKOvVb2Copb7RxHxkLJtM/B/wK9FxFGZ+f2J9LXLMopAdDuZuTIi1lGUP7TX+9kI63Vm\n5Me7r7bRftbd7YdT/A1aPcK6LeDQUfYDsH9E/A3FpxKHl+s2GPl3P5ZlwN2ZuWaEZT9hx6kBu/u6\nsXysNG+4pJnPAFrSdPPNMUoqOn0eeB5FZvMbFOUGX6OoC+42oSniIuJMilrXn5T7vpSiHvgMilrm\nKvt6AsV0cy2KettO7WD8VIqykbGMJ1gbqyZ3gKIEor2vnZ0IjHdfbaP9rLvbByjKHtqZ7G4rR9pJ\nRLycovZ6BXA1cAVwI0Wm/Mwx+jqSqq+tOdKKkuYeA2hJM05EHEcRPJ+bmed2tA+ybTaHyR5jPsXF\nYlcBzyxLG9rL9p/ALtvlG+dRXDjYaQHwMYo5oc8sS1SGgcGIaHQem/GVC9wOPLK7MSIOprggsn2C\ncgfwiBHWOwH4PYrZKca7r6puB/bIzO1OeMqLFp8K3DLKdudTXGz4G5m5sWO70ybQh+XA8RGxZIQs\n9CMognRJ2oE10JJmovaMFTd3tb+KIqgbT3KgnREd7X1wQbmvn3YFz0dRXDRGRIz31t0NiunP7gPO\ny8zLu74+TZFJ3YcikwrFTVYAjurYz0OAo8fxOr4APCYintu17tkUQfwXy+dfAg4qA+ZOrweenZl3\nV9hXVZcDjy9nOun0txSZ/iNG2W5vYHlX8PwQttUrt3/3O/v9QvHaGpS19R37+z2KTwu+sJPXIGmO\nMgMtaSb6JsWFfO+JiGXAGopp7l5GMUXconHsYzVF8PRXEfHlzNwuWMrMtRHxbeC0iLifYuq2I4E/\nogjOdimPM565oJ9OkTm+sDPw6/IBiovaTqWYYu9TFBngz0TEeygujjudInN7eNfrADglInbNzIsp\nstwvAi4tZ8v4KfDMcv+fzsyry23eXx7vMxFxYbne8ykuIGzf0ny8+6qqvd/Plfu9uTzuyylmRvnK\nKNt9GXhxRFwAfJci0H0lxUwrsO13fzdFgP87EXEnRVC+ncy8PCKuAF5fBuHXUATuf0rx+35H9zaS\nBGagJU0v47owLzNXAc+huADuTRTB2KEUAfT7gUdHxNBO9vspiptjnMr2szB0rvt7FLXWfwj8E0Ug\n/PcU5RgAx4+z7y8vl39ojHX+k+IGJc+KiKHyYsITgQeAdwKnUdQLf7hzo8z8EcUcy08E/ikiDsnM\neygy1R+jmFHj3RSB5l9m5ss7tl1PkU3/cNnHd1PMbvK77RuNjHdfVXXs9xKK39t7Kab4+9vydY/m\nlRQ/xxeV2/wO8G/Ab5fLjy/3v45iCrpl5XqPKZd3/55eVB7zsRS/4xdS/DyPLvfBKNvtrF3SLNZo\ntfy/L0mSJI2XGWhJkiSpAgNoSZIkqQIDaEmSJKmCGTcLx+rV9/elaHvJkoWsWbO+H4fWHOD4Uq85\nxtRLji/1Ur/G19DQolFvtmQGepzmzfNOreodx5d6zTGmXnJ8qZem4/gygJYkSZIq6EkJRzkp/kBm\nvmqMdZ4AvIdi7s2fA2/LzEt60R9JkiSpLrVnoCPiLRS30x1rnX2BK4HvUATQ/wxcFBHPqLs/kiRJ\nUp1qy0BHxGHARcCjKW41O5ZXAmsz87Xl81si4nHAmcBX6+qTJEmSVLc6M9DHAHcARwLLd7LuscD1\nXW3XAr9VY38kSZKk2tWWgc7MjwMfB4iIna2+FPheV9udwMKI2Dsz762rX5O1au0GLr7iZm5deR+H\nH7wXp51wBPstXtDvbkmSJKlP+jULx0Lgwa62jeXjblPclzFdfMXN3LJiLcPNFresWMvFV9zc7y5J\nkiSpj/p1I5UNwPyutvbzB8bacMmShVM6H+CtK+/b4fnQ0KIpO77mDseVes0xpl5yfKmXptv46lcA\nvQI4sKvtIGBdZt43wvpbTfWdaA4/eC9uWbF2u+erV98/pX3Q7Dc0tMhxpZ5yjKmXHF/qpX6Nr7GC\n9n6VcHwdeHJX2/HAN/rQlzGddsIRrFv9M1rNYR5xyGJOO+GIfndJkiRJfTQlGeiI2AXYG7g3MzdT\nTHd3VkS8H3gv8NvAicCzpqI/Vey3eAG3Xvs+BgYafOjG/+13dyRJktRnvcpAt7qeH0Mxy8aTADJz\nFfBsipuofA/4c+DkzLyuR/2RJEmSatGTDHRmHt/1/DpgsKvtBuDoXhxfkiRJ6pV+1UBLkiRJM5IB\ntCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0\nJEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQkSZJUgQG0JEmSVIEBtCRJklSBAbQk\nSZJUgQG0JEmSVMG8unYUEQPAecApwCLgSuD0zFw1yvrHA/8APBr4BfDBzHxnXf2RJEmSeqHODPS5\nwMnAScBxwFLg0pFWjIjDgS8AlwOPAd4A/G1E/FmN/ZEkSZJqV0sAHRG7AGcAZ2fm1Zn5feBE4NiI\nOHqETZ4NrM/M8zJzeWZeBlwBPKuO/kiSJEm9UlcG+ihgD+C6dkNm3g4sp8hGd1sN7B0RJ0ZEIyIe\nAzwZuLGm/kiSJEk9UVcAvbR8XNnVfidwyAjr/wdwMfBxYBPwA+DazDyvpv5IkiRJPVFXAL0QaGbm\ncFf7RmC3EdZfDCwDzgeeAPwB8MyI+Lua+iNJkiT1RF2zcGwABiJiIDObHe3zgQdGWP8dwObMfFP5\n/Kayjvr9EfHezFwz2oGWLFnIvHmDNXV7fAYGGgAMDS2a0uNqbnF8qdccY+olx5d6abqNr7oC6BXl\n44FsX8ZxEDuWdQD8JnBZV9u3gV2BQ4FRA+g1a9ZPvJcT1Gy2GBhosHr1/VN+bM0NQ0OLHF/qKceY\nesnxpV7q1/gaK2ivq4TjJmAd8JR2Q0QsoyjTuH6E9X8O/FpX25HAMHBrTX2SJEmSaldLBjozN0XE\nhcC7IuIeilk2LgCuycwbyvKMvYF7M3Mz8F7gCxHxJuATFDdTeTdwQWauq6NPkiRJUi/UeSOVcyhm\n1bgEuAq4DXhJuewYihk5ngSQmV8GXgy8kCJ7/Y/AB4DX19gfSZIkqXa13cq7nIHjrPKre9l1wGBX\n2+UUdyKUJEmSZow6M9CSJEnSrGcALUmSJFVgAC1JkiRVYAAtSZIkVWAALUmSJFVgAC1JkiRVYAAt\nSZIkVWAALUmSJFVgAC1JkiRVYAAtSZIkVWAALUmSJFVgAC1JkiRVYAAtSZIkVWAALUmSJFVgAC1J\nkiRVYAAtSZIkVWAALUmSJFVgAC1JkiRVYAAtSZIkVTCvrh1FxABwHnAKsAi4Ejg9M1eNsv7BwHuB\nZwIbgEuB12fmg3X1SZIkSapbnRnoc4GTgZOA44ClFEHxDiJiV+CrwGLgScBLgecB76ixP5IkSVLt\nagmgI2IX4Azg7My8OjO/D5wIHBsRR4+wySuA/YEXZ+aPMvM64M3AE+vojyRJktQrdWWgjwL2AK5r\nN2Tm7cByimx0t2cCX8nMX3Ws/5HMHCnYliRJkqaNumqgl5aPK7va7wQOGWH9RwBXRcRbKEo+WsBl\nwDmZubGmPkmSJEm1qyuAXgg0M3O4q30jsNsI6+8J/DHwJeD3gIOBC4Ah4NSa+iRJkiTVrq4AegMw\nEBEDmdnsaJ8PPDDC+puBe4CTM7MFfK+8sPDfI+J1mblmtAMtWbKQefMGa+r2+AwMNAAYGlo0pcfV\n3OL4Uq85xtRLji/10nQbX3UF0CvKxwPZvozjIHYs66Bs21AGz20/BhrAMmDUAHrNmvWT6uhENJst\nBgYarF59/5QfW3PD0NAix5d6yjGmXnJ8qZf6Nb7GCtrruojwJmAd8JR2Q0QsowiGrx9h/a8BR0VE\nZyr5SGALxYWHkiRJ0rRUSwY6MzdFxIXAuyLiHmA1RU3zNZl5QznN3d7AvZm5GfgA8Grgo+WFhIdQ\nzAH9kbHKNyRJkqR+q/NGKucAHwcuAa4CbgNeUi47hmJGjicBlHcnfDJFUP1d4GPAZ4A/r7E/kiRJ\nUu1qu5V3OQPHWeVX97LrgMGutp8Az6nr+JIkSdJUqDMDLUmSJM16BtCSJElSBQbQkiRJUgUG0JIk\nSVIFBtCSJElSBQbQkiRJUgUG0JIkSVIFBtCSJElSBQbQkiRJUgUG0JIkSVIFBtCSJElSBQbQkiRJ\nUgUG0JIkSVIFBtCSJElSBQbQkiRJUgUG0JIkSVIFBtCSJElSBQbQkiRJUgUG0JIkSVIF8+raUUQM\nAOcBpwCLgCuB0zNz1Ti2/SKwMDOPr6s/kiRJUi/UmYE+FzgZOAn4/+3de5Bc1X3g8W/3SBpJI6GR\n0IwejGSJhw84scE46wgWBb/iJBB7y5vyQtlmwewGp8oYvBuzdhJ2q3BCFm/wxtmUcSoVSHYJGK+p\nmDjLY22eWhwrwoZQFQcfqbBeSEIzegxIo9Fzev/oHjHq0Yym597u27f7+6maavXpvn1/mv5N31+f\ne865a4E+4OEzbRRC+AxwVYpxSJIkSXWTSgEdQpgJ3AL8Tozx6RjjPwLXAleEENZMst35lHut/z6N\nOCRJkqR6S6sH+hJgHvDcaEOMcSuwhXJv9DiVIR//E7gLeCWlOCRJkqS6SquA7qvc7qhq3wmsmGCb\n3wVGYox3pxSDJEmSVHdpTSKcS7kYPlHVfgSYXf3kEMJ7gP8A/EJK+5ckSZIaIq0CehgohhCKMcaR\nMe2dwNDYJ4YQOoH/BdweY9xc644WLpzLjBkdiYKtVbFYAKCnZ35D96v2Yn6p3swx1ZP5pXpqtvxK\nq41Jv6EAABaHSURBVIDeXrldxqnDOJYzfljHLwIXAl8JIfy3Slsn5QL8TeAdMcbXJtrR/v2H0om4\nBiMjJYrFAgMDBxq+b7WHnp755pfqyhxTPZlfqqes8muyoj2tMdAvAweBK0cbQgirgFXAuqrn/gNw\nAeWJhxdXfr4DvFD5986UYpIkSZJSl0oPdIzxaAjhHuDuEMJeYAD4OvBMjHFDZZm7RcC+GOMR4Gdj\nt6/0PA9PZ0iHJEmS1EhpXkjlduAB4H7gKWAz8PHKY5dT7lm+LMX9SZIkSQ2X2qW8Kytw3Fb5qX7s\nOWDCmX8xxt9MKw5JkiSpntLsgZYkSZJangW0JEmSVAMLaEmSJKkGFtCSJElSDSygJUmSpBpYQEuS\nJEk1sICWJEmSamABLUmSJNXAAlqSJEmqgQW0JEmSVAMLaEmSJKkGFtCSJElSDSygJUmSpBpYQEuS\nJEk1sICWJEmSamABLUmSJNXAAlqSJEmqgQW0JEmSVAMLaEmSJKkGM9J6oRBCEbgTuB6YDzwBfDbG\n2D/B868BvgRcAOwE7gX+KMY4klZMkiRJUtrS7IG+A7gO+BSwFugDHj7dE0MIvwb8NfDnwDspF9Jf\nBH4nxXgkSZKk1KXSAx1CmAncAtwcY3y60nYtsDmEsCbGuL5qk88A344xfqNyf3MI4R3Apyn3YkuS\nJElNKa0e6EuAecBzow0xxq3AFsq90dV+H/hyVVsJWJhSPJIkSVJdpDUGuq9yu6OqfSewovrJMcYf\nj70fQjgL+C3g8ZTikSRJkuoirR7oucBIjPFEVfsRYPZkG4YQ5gCPVJ7nGGhJkiQ1tbR6oIeBYgih\nWLWKRicwNNFGIYSzgb8DLgQ+FGPcfqYdLVw4lxkzOpLGW5NisQBAT8/8hu5X7cX8Ur2ZY6on80v1\n1Gz5lVYBPVr4LuPUYRzLGT+sA4AQwirge0AXsDbG+JOp7Gj//kPTj3KaRkZKFIsFBgYONHzfag89\nPfPNL9WVOaZ6Mr9UT1nl12RFe1pDOF4GDgJXjjZUCuRVwLrqJ4cQeoBnKE8cvGyqxbMkSZKUtVR6\noGOMR0MI9wB3hxD2AgPA14FnYowbKsvcLQL2xRiPAfdU7n8AOBJCWFJ5qdJEF16RJEmSmkFqVyIE\nbq+83v3ATMoratxceexy4Gng/SGEDcDHgAKwYcz2BeA4MCvFmCRJkqRUpVZAV1bguK3yU/3Yc8DY\nmX9pFu6SJElSw6R5KW9JkiSp5VlAS5IkSTVwKIUkqan0Dw5z36Ov8OqONzjvnAXcePVF9HbPyTos\nSTrJAroBXu/fQ/++ofI0SdXNG0PH+N6P+9m17zDLFs3mw+/pZUHXzKzDmpKFu7vYPzjhNYekxPKU\nY99et4Mdew8DsHH7IH/67Zf4+C+dk3FUmkye8kv50/fmfBadtSjrME5hAV1nw4cPs3v/ITrnnJV1\nKC3v+89vOnnQ3bH3MN9/aR+f+NAFGUc1NTNnz2XW7MZeYVPtJU85tmvfq1X3DzNrtp+hzSxP+aX8\nKZWarwfSArrOtry2m04/+Bti556Dk96vl8GDR3hs/TZ27jnI8sXzuGrNSrrndTZk31IrWr54Hq8N\nHDzlviQ1EycR1tGu1wcYKTpur1GqD7KNOug+tn4brw0cZKQErw0c5LH12xqyX6lVXbVmJQf6NzEy\ncoK+nvKXUklqJvZA18nw4cP0vzFM5+yJr6OudF21ZiVfvfdv6Vp8LiuXLGjYQTernm+pVXXP6yQ+\n9ScAfOm7P8g4GkmeaR3PHug62fzabovnBhs96L74rVv5xIcuaNgfd1Y935IkNYJnWsezgK6DXa8P\nUHLoRtvwdLMkqZV5pnU8h3CkbPjwYfoHD9M5x17IduHpZklSK3Ni73j2QKds8/bdbV08Dx48woNP\nbuLuh17iwSc3MXjwSNYhSZKkBDzTOp490Cna+Xo/pY72HroxOk4K3honlZe1mCVJqqe8TsbzTOt4\n9kCn5NDwMAODR+joyMeV7+rFcVKNZY+/JOWHk/FahwV0Sra81t/WQzdGuSJFY/lhLLUGvwy3BzuZ\nWocFdAp27Oqn1DE36zCaguOkGssPY6k1+GW4PdjJ1DocA53QoUPD7HnzCJ2z/SMAx0k1mjOj8yGv\n4x7VOHn9Mnwyt/cOsfzsLnP7DLK64JfSZw90AqVSic07+i2elRl7/PPB3sXGyetQiLz2TJ7M7ZGS\nuT0FWV3wS+mzgE5g5+v9lIoO3VB2/DDOh7z2LuZRXr+s5PXLsLmtdpXaEI4QQhG4E7gemA88AXw2\nxtg/wfN/Afga8G7gNeAPYoz3pxVPvQ0NHWLPm0ftfZZyJMlQiiTbOtSmcfJa0OV1+Ju5rXaVZg/0\nHcB1wKeAtUAf8PDpnhhCWEy5wP4R5QL6T4F7QwgfSjGeuimVSmzZMWDxLOVMkt7JJNvmtXcxj/I6\nFCKvRnO71Ea5nddhQkpXKj3QIYSZwC3AzTHGpytt1wKbQwhrYozrqzb5TWAwxvj5yv2NIYRLgS8A\nT6YRUz3t2LXbVTeUe+04sS1J72SSbfPau5hHTtJqrNHcLhYLfPGR57MOpyG8YJggvR7oS4B5wHOj\nDTHGrcAWyr3R1a4A1lW1PQv8y5TiqZuhoUPsffMYM2a07gImfrtuD3kdK5pEkt5JezbzwXkBqre8\nDhNSutIqoPsqtzuq2ncCKyZ4/umeOzeEsCilmFJ3cuhGi18wpR0Lq3aU5CCQ1y9ZSYZSOAxDEvhl\nWmWFUqmU+EVCCJ8E/irGOLOq/Sng1RjjTVXtmyrPv3NM21rKvdArYow7J9rXypUjyQOu0c6dO4AC\nvb1LGClBoVBodAgNdek1j1EsvvVrHhkp8OK3rpry9v39uwDo7V2WemzNuu+k+y0WC4xMM7Wnu+/w\nwR8yv3ffyfsH+hcRn7qs7ttmLcl7ldW2SczqOsTqNS8zb/F+Du5ZyOb1F3N0qPmHoOXxd51U1jnS\ntXg/Q9PIkf7+XRSAnpz9vqdrVtchzrn0BRYuO8jQ3kXT+n2B+VmLYhE6io1fOG7btuKEBV9a4xCG\ngWIIoRhjHBnT3gkMTfD86vNqo/dP9/yTisUC0NgCtq9vBaXSCMeOj9Ax8e/ytHa/Xv4usGTp8mnt\nO8n20912aM/CU4qjoT0LK7/3qVk6zf/rqCT/5yT7zuN+k+x764aLedt73yqstm64eMrv87zF+8fd\nryVHsvy7SPJeZbHtrK4hll/yAt2Vg/XWDRdzdKhrytuvXvPyyb/n+b37WL3mZTY9c/mUt8/iMwiy\ne58gn//nJPtNmiNZ5XZW79Px4S62/uB9bB3TVkttl9X7nNWxJum+R7ft6zvdgIbspFVAb6/cLuPU\noRnLGT9UY/T51V9hlgMHY4xvTLajF17IZqxRV9cM/v7Hm2sevvFvPloe1v3QI9ObOJRk++luO3hw\nKY+tP/rW5LKPLKX71tO9jfWR9HeWx/0WiwUeymQCztsqPwCDlZ8ze/DJrlOWrlqxpIsvPjL1HMny\n7yJvHnxy08nf9fzeffzqp1+oacLS3Q/tY+zJjQVL9vFQg96rvL5Pefw/J9lv0hwB6O6ey+DgoZq2\nSZrbeXyfksrr/zlp3MUivPDCP6cd1hTMn/CRtArol4GDwJXAgwAhhFXAKsZPFgR4Hrihqu0DQNNm\n8ty5c+jp7mT/oWN0dMw88wYZGzx4hPDBW+lafC4PPrmpphUWuud1OqNYk7pqzcpxK3hMVZLcTGP7\nvEk6Ycl1enUmWeWIk/GUZ6kMKIkxHgXuAe4OIfxKZUm6bwLPxBg3hBBmhhCWVJa7A7gX6AkhfCOE\ncGEI4XPAtcBX0oinXpYv7aVwYjjrMKbksfXbmN97AcVihxMBlbrRL1lfuPbdNa90kDQ32y23k05Y\numrNSvp65lEsFpz8qNM6mSMFGpojTsZTnqW5Ftvtlde7H5gJPA7cXHnscuBp4P3AuhhjfwjhV4H/\nAbwIbAWuizE+N+5Vm8zqFUvYuKX5V+Lwm72aVdLcbLfcTtLbD2992ZnOKXa1h6zOOibNbU1du525\na4TUCugY4wngtspP9WPPAR1VbRuANWntv1HmzJ6di6EceT1t6x9560uam3nN7elySJValbndOKNn\n7iBfF38ZrQnmLT6Xux54kRuvvoje7jlZhwWkeynvtrF8aS+FkeYeypHVKbmk2u30fDtKmpt5zW1J\nykpez9yN1gSFYgcbtw9y36OvZB3SSa17Ob06W923hI1b++mcPfEMzSzl9Zt9Xv/INXVJczOvuS0p\nPUnOVrbjmc68nrmrrgFe3THpQm0NZQ/0NM2ZPZveBXM4ceJY1qG0FCeVSMrSaHF16TV/kqurbLab\nJGcr2/FMZ17P3FXXAOedsyCjSMazgE5g2dIeik0+lCNvsvoj96ApCdqzuMqjJGcr2/FMZ5KVk5JK\ncnx9axUhePuKbm68+qI6Rlobh3AktKrJh3LkTVan5/M6wUKqp3Y81d2OxVUeJRmSkNfhDHmV5Pg6\nWhP0dBc4e0F3PcOsmT3QCc2ZPZsl3XM4fvxo1qEoAQ+a0njt2BvrMLJ8SHK2Mq/DGfKqVY+v9kCn\nYOmSHgYPbAVmZR2KpskeCWm8Vj3wTca1ifMhydlKJyI3VqseXy2gU7J6xVJ+umW3QzlyyoOmNF6r\nHvgmY3ElpatVj68W0Cnp7OxkycK57DlwlBkz7InOGw+a0niteuBrNe04Vr0d5fV9btXjqwV0ipb2\nLmbwTYdyaOrGXmUpTx+Iag+teuBrNU6Cbg++z83FSYQpW71iKUcOv5l1GMqJsVdZapdJWlKrymo5\nzHYcq96OfJ+biwV0yjo7O1m6cB7HjrmOsM7MD0S1qnZcWz2rVUtcOaQ9+D43FwvoOljSezYzC61/\nsFByfiCqVbXjEnhZfSF2Wbb24PvcXBwDXSfnrljGK5t3ZR2GmtzJSVp7h1h+dpcfiGoZ7Xh2JatV\nSxyr3h58n5uLBXSdzJo1i6UL51EqlSgUClmHoyY1+oHY3T2XwcFDWYcjpaYdl8Bz1RKpfVhA19GS\n3rMpUAIsoCW1l3YsJu0hlNqHBXSdzZjRwbHjJ7IOQ5IaymJSUiuzgK6zQqFAR7HA8aMHpjWUo1Qa\nAeDEsdYfP9jORo6OcOKYQzhUP+aY6sn8Uj3N7Dgr6xDGsYBugI6ODn7+gumdvpw1s/wW/dz5K9IM\nSU2mp2c+AwMHsg5DLcwcUz2ZX6qnZsyvVAroEEIP8HXgl4GjwF8CvxtjHJng+TOA3wOuA5YCPwW+\nHGP8bhrxtIr+wWHOe98tdJ29mrseeJEbr76I3u45WYclSZLU1tJaB/pvgF5gLXA98Gngjkmefydw\nE3AL8C7gYeBvQghXpBRPS7jv0VeY13M+hWIHG7cPct+jr2QdkiRJUttLXECHEC4DLgf+bYzxn2KM\nTwC3AZ8LIcw8zfMLwL8H7ogxPhZj/FmM8S7gWeCGpPG0kld3vDHpfUmSJDVeGj3QVwBbY4xjLzP1\nLHAWcMkE+/w48J2q9hFgYQrxNI3RIRjv+o0/5q4HXqR/cLim7c87Z8Gk9yVJktR4aRTQfcCOqrad\nldtxM99ijCdijE/HGAdG20II/wL4APB4CvE0jaRDMG68+iLevqKbjmKBt6/o5sarL6pTpJIkSZqq\nM04iDCG8DdgMp70iyGHgryu3J8UYj4cQSsDsKbz++ZTHUK+nPPmwZSQdgtHbPYcvffLSNEOSJElS\nQlNZhWMHcOEEj41QngjYObaxsspGARia7IVDCO8B/g/wOvCRGGNLXXHkvHMWsHH74Cn3JUmSlG+F\nUqmU6AVCCLcBN8UYLxjTthLYArw3xvijCbb7MOXVN14CPhpjnFL37PHjJ0ozZnQkirlRXt87xNce\neomfbtnHhasW8flr383Ss7uyDkuSJElnNuEV8NIooC8DngdWxhh3VNpuAL4GLI4xHj/NNmuB7wH/\nF7gmxnhkqvsbGDiQLOBpasZFvNU6zC/VmzmmejK/VE9Z5VdPz/wJC+jEF1KJMf4whLAe+FYI4XOU\nL4zyFeCro8VzCKELmBdj3B1CmAU8CETgs0B3CGH05Y7EGAfH7USSJElqEmldSOVjwG5gHXAv8Ocx\nxt8f8/gXeGtljiuB5cA7gW2V9tGf/51SPJIkSVJdJB7C0WgO4VArMr9Ub+aY6sn8Uj014xCOtHqg\nJUmSpLZgAS1JkiTVIHdDOCRJkqQs2QMtSZIk1cACWpIkSaqBBbQkSZJUAwtoSZIkqQYW0JIkSVIN\nLKAlSZKkGlhAS5IkSTWYkXUAzS6EUATuBK4H5gNPAJ+NMfZnGphyL4TwZ0AxxnjTmLYPA18BArAR\n+FKM8YmMQlTOhBB6gT8CfhmYA/wD8Nsxxp9UHje/NG0hhHOArwEfoNwB9wTwH2OMuyqPm19KRQhh\nDfD/gA/GGNdV2poqv+yBPrM7gOuATwFrgT7g4UwjUu6FEL4M3FTV9g7gb4FvAZcA3wUeCSFc1PgI\nlTchhALwCHA+8BHgMuAN4KkQwkLzSyl4FFgAXAn8ErCMch75+aXUhBDmAvczpkZtxvyyB3oSIYSZ\nwC3AzTHGpytt1wKbQwhrYozrMw1QuRNCWA3cC/wcsLXq4VuAH8YY76rc/y8hhCuAW4HfalyUyqmL\ngV8ELooxbgQIIVwH7AOuBq7A/NI0hRCWAP9MuddvW6XtvwPfCSEsoJxH5pfS8MfANuDcMW1Nl1/2\nQE/uEmAe8NxoQ4xxK7CFcm+0VKvLKX8wvJNyHo21Fni2qu1ZzDVNzTbg10eL54qRyu1CzC8lEGPc\nHWP8xJjiuY9y4bIhxvgG5S9oz1Zt9izml2oQQrgK+DXKHUqFMQ81XX7ZAz25vsrtjqr2ncCKBsei\nFhBjfAB4ACCEUP1wH+aapinGuA94vKr5VmA28D3gDzC/lIIQwneAf0X57Mb7K81+fimREMJi4C8o\nzzkbrHq46fLLHujJzQVGYownqtqPUD4oSWmaCxyuajPXNC0hhI8Cfwh8NcYYMb+UntuB9wI/AL4f\nQliO+aXk/gx4JMb4/TFtpcpt0+WXBfTkhoFiZSWOsTqBoQziUWsbppxbY5lrqlkI4QbKk52/GWP8\nYqXZ/FIqYow/iTH+CLgW6KDcY3gI80vTFEK4nvKw2S9UmgpVt033+WUBPbntldtlVe3LGX8qQUpq\nO+aaEgoh/B5wH3BPjPGGMQ+ZX5q2EEJvCOGasW0xxmHgZ5TzyPxSEtdTHqaxO4RwAPhppf3xEMI3\nKM/xaKr8soCe3MvAQcpL9gAQQlgFrALWZROSWtjzjMm1ivdjrmmKQgj/CfgycHuM8fNVD5tfSuJt\nwDdDCJeONlRW3wiUV+f4AeaXpu+TwDsoryZ0MfArlfZ/B/xnmjC/CqVS6czPamMhhP9K+ZvRp4EB\n4OvAoRjjBzMNTLkXQngG2DR6IZUQws8DPwLuAr5J+QPlt4FLK2NYpQmFEN4F/Bj4K8pjVMc6QHlJ\nKPNL01JZZ/wZ4CzgM8Bxyrm0Cng35pdSVLloz3bgfTHGdc14fLQH+sxup7xqwv3AU8Bm4OOZRqRW\nccq31xjjPwEfA34DeAn4dcrLknnw0VRcQ/kz/UbKs9PH/nze/FISMcYS8K+BfwT+jnIxvZ9ygXPI\n/FIdnDxGNmN+2QMtSZIk1cAeaEmSJKkGFtCSJElSDSygJUmSpBpYQEuSJEk1sICWJEmSamABLUmS\nJNXAAlqSJEmqgQW0JEmSVIP/Dzc//mXiMsjPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a1227f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(new_1, lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(new_1, lags=40, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
