{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STA 863 Final Project - FHMM\n",
    "*Factorial Hidden Markov Models* - Gharamani and Jordan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from numpy import linspace,exp\n",
    "from numpy.random import randn\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.stats import multivariate_normal\n",
    "import seaborn as sns\n",
    "from music_comp import * ## pre-processing and metrics code\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate log likelihood\n",
    "# n is number of observations\n",
    "# W is a M long list of D x K[m] matrices\n",
    "# pi is a M long list of K[m] vectors for the initial distributions\n",
    "# Tmat is a M long list of K[m] x K[m] transition matrices\n",
    "# C is a D x D covariance matrix for the Gaussian observations \n",
    "# mu is a D x n mean matrix\n",
    "def log_like(n, pi, Tmat, mu, C, Y, zstates):\n",
    "    y_prob = np.zeros(n) # emission probabilities\n",
    "    t_prob = 0 # transition matrix probabilities\n",
    "    pi_prob = 0 # initial probability\n",
    "    for i in range(0, M):\n",
    "            pi_prob += np.log(pi[i][zstates[i][0]])\n",
    "    \n",
    "    for t in range(0, n):\n",
    "        y_prob[t] = np.log(multivariate_normal.pdf(Y[:, t], mean = mu[:, t], cov = C))  \n",
    "        \n",
    "        for i in range(0, M):\n",
    "            t_prob += Tmat[i][zstates[i][t-1], zstates[i][t]]\n",
    "    ll = pi_prob + t_prob + np.sum(y_prob)        \n",
    "    return(ll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Toy Data and Parameters\n",
    "\n",
    "$$P({S_t, Y_t}) = P(S_1)P(Y_1 | S_1)\\prod_{t=2}^T P(S_t | S_{t-1})P(Y_t | S_t)$$\n",
    "\n",
    "- Assume three different chains, each with 5 hidden states each\n",
    "- M = 3, K = (5, 5, 5)\n",
    "- n = 10 observations, D = 3 (dimension of Gaussian)\n",
    "- Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3 ## Number of independent hidden state chains\n",
    "K = np.array([5, 5, 5]) ## number of hidden states for each chain\n",
    "D = 3 ## Dimension of Gaussian\n",
    "n = 10 ## number of observations\n",
    "\n",
    "\n",
    "## Generate distribtions\n",
    "pi = [] ## initial distribution\n",
    "Tmat = []  ## transition distribution\n",
    "W = [] ## contribution to means matrices D x K\n",
    "for i in range(0, M):\n",
    "    vals = np.random.rand(K[i])\n",
    "    pi.append(vals/np.sum(vals))\n",
    "    vals1 = np.random.rand(K[i], K[i])\n",
    "    Tmat.append(vals1/np.sum(vals1, axis=1)[:,None])\n",
    "    W.append(10*np.random.rand(D, K[i]))\n",
    "    \n",
    "## Generate state variables\n",
    "S = []\n",
    "for i in range(0, M):\n",
    "    zstates = np.arange(0, K[i], dtype = int)\n",
    "    z = np.zeros(n, dtype = int)\n",
    "    zmat = np.zeros((K[i], n), dtype = int)\n",
    "    z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "    zmat[z[0], 0] = 1\n",
    "    for j in range(1, n):\n",
    "        z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "        zmat[z[j], j] = 1\n",
    "    S.append(zmat)\n",
    "#x = np.random.normal(size=D)\n",
    "#y = np.random.normal(size=D)\n",
    "#z = np.vstack((x, y))\n",
    "#C = np.cov(z.T) ## covariance matrix\n",
    "C = np.identity(D)\n",
    "mu = np.zeros((D, n))\n",
    "Y = np.zeros((D, n))\n",
    "for t in range(0, n):\n",
    "    for i in range(0, M):\n",
    "        mu[:, t] += np.dot(W[i], S[i][:, t])\n",
    "    Y[:, t] = np.random.multivariate_normal(mu[:, t], C, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C_new = np.dot((np.array([1, 2, 1] ) - np.array([0, 0.7, 0]))[np.newaxis].transpose(), \n",
    "#               (np.array([1, 2, 1] ) - np.array([0, 0.7, 0]))[np.newaxis])\n",
    "#print(np.all(np.linalg.eigvals(C_new) > 0))\n",
    "#C_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi\n",
      "[[0.157 0.283 0.102 0.036 0.42 ]\n",
      " [0.22  0.263 0.04  0.23  0.248]\n",
      " [0.151 0.167 0.29  0.245 0.146]]\n",
      "Tmat\n",
      "[[[0.29  0.281 0.254 0.017 0.158]\n",
      "  [0.338 0.021 0.309 0.314 0.018]\n",
      "  [0.254 0.215 0.233 0.188 0.11 ]\n",
      "  [0.121 0.228 0.161 0.32  0.17 ]\n",
      "  [0.106 0.111 0.041 0.528 0.215]]\n",
      "\n",
      " [[0.376 0.013 0.177 0.198 0.236]\n",
      "  [0.219 0.058 0.437 0.029 0.257]\n",
      "  [0.215 0.353 0.073 0.031 0.327]\n",
      "  [0.005 0.236 0.228 0.259 0.272]\n",
      "  [0.169 0.146 0.192 0.442 0.051]]\n",
      "\n",
      " [[0.025 0.271 0.221 0.227 0.256]\n",
      "  [0.221 0.122 0.152 0.251 0.254]\n",
      "  [0.135 0.052 0.227 0.195 0.391]\n",
      "  [0.159 0.163 0.118 0.253 0.306]\n",
      "  [0.058 0.296 0.073 0.139 0.433]]]\n",
      "W\n",
      "[[[1.988 8.314 5.68  0.823 5.45 ]\n",
      "  [1.59  6.768 1.185 4.45  8.88 ]\n",
      "  [7.973 0.68  9.608 6.592 7.188]]\n",
      "\n",
      " [[6.755 8.585 6.929 7.851 3.533]\n",
      "  [2.202 2.454 7.274 0.641 4.537]\n",
      "  [4.877 6.409 1.062 5.736 9.603]]\n",
      "\n",
      " [[4.829 5.407 7.112 6.874 0.37 ]\n",
      "  [8.882 1.886 7.82  6.439 4.854]\n",
      "  [9.29  2.699 8.142 6.95  2.355]]]\n",
      "C\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "Z states\n",
      "[4, 3, 3, 1, 2, 0, 2, 1, 0, 1]\n",
      "[0, 4, 3, 1, 4, 0, 0, 3, 3, 3]\n",
      "[2, 2, 4, 3, 4, 4, 4, 3, 3, 1]\n",
      "Log-Likelihood\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-36.794003412324884"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Pi\")\n",
    "print(np.round(pi, 3))\n",
    "print(\"Tmat\")\n",
    "print(np.round(Tmat, 3))\n",
    "print(\"W\")\n",
    "print(np.round(W, 3))\n",
    "print(\"C\")\n",
    "print(np.round(C, 3))\n",
    "print(\"Z states\")\n",
    "print([np.where(S[0][:, t] == 1)[0][0] for t in range(n)])\n",
    "print([np.where(S[1][:, t] == 1)[0][0] for t in range(n)])\n",
    "print([np.where(S[2][:, t] == 1)[0][0] for t in range(n)])\n",
    "print('Log-Likelihood')\n",
    "zstore = [[np.where(S[0][:, t] == 1)[0][0] for t in range(n)], [np.where(S[1][:, t] == 1)[0][0] for t in range(n)],\n",
    "         [np.where(S[2][:, t] == 1)[0][0] for t in range(n)]]\n",
    "log_like(n, pi, Tmat, mu, C, Y, zstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(Y)\n",
    "plt.title(\"Toy Data Y Values\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E - Step\n",
    "\n",
    "## 2. Gibbs Sampling \n",
    "\n",
    "$$S_t^{(m)} \\propto P(S_t^{(m)} | S_{t-1}^{(m)})P(S_{t+1}|S_t^{(m)})P(Y_t | S_t^{(1)}, \\ldots, S_t^{(M)})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate transition matrix from a vector\n",
    "# q is a vector from 0 to m different states\n",
    "# return m x m transition matrix b\n",
    "from collections import Counter\n",
    "def trans_mat(q, m):\n",
    "    b = np.zeros((m,m))\n",
    "    for (x,y), c in Counter(zip(q, q[1:])).items():\n",
    "        b[x, y] = c\n",
    "    return(b)\n",
    "\n",
    "\n",
    "# t is the time step to be updated\n",
    "# y is the observed value at that time step\n",
    "# M is the number of hidden Markov chains\n",
    "# K is a vector of number of hidden states for each chain\n",
    "# C is covariance matrix for emission distribution\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable \n",
    "# S is a M long list of current states, each element of list is K[i] x n long (n number of observations)\n",
    "# update is which of M chains to calculate emission probabilities for, for every K[i] possible values\n",
    "# output is a K[update] vector of density of y for each possible value of S[update]\n",
    "def y_density(t, y, M, K, S, C, W, update):\n",
    "    ydense = np.zeros(K[update]) ## output density for each possible value of S[update]\n",
    "    Stemp = S\n",
    "    for i in range(0, K[update]):\n",
    "        mu = 0\n",
    "        Stemp[update][:, t] = 0\n",
    "        Stemp[update][i, t] = 1 # state variable value to calculate probability for\n",
    "        for j in range(0, M):\n",
    "            mu += np.dot(W[j], Stemp[j][:, t])\n",
    "        ydense[i] = multivariate_normal.pdf(y, mean = mu, cov = C)\n",
    "    return(ydense)\n",
    "\n",
    "\n",
    "\n",
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# it is the number of iterations to run for the Gibbs Sampler\n",
    "# output is:\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "def gibbs_sampler(n, M, K, Y, Tmat, W, C, it = 10):\n",
    "    # Randomly initialize state vectors\n",
    "    small = 10E-5\n",
    "    S = []\n",
    "    zstates = []\n",
    "    for i in range(0, M):\n",
    "        s = np.zeros((K[i], n), dtype = int)\n",
    "        ind = np.random.choice(range(0, K[i]), n)\n",
    "        s[ind, range(0, n)] = 1\n",
    "        zz = np.zeros((it, n), dtype = int)\n",
    "        zz[0, :] = ind\n",
    "        zstates.append(zz)\n",
    "        S.append(s)\n",
    "        \n",
    "    for l in range(1, it):\n",
    "        ## update one  chain at a time\n",
    "        for i in range(0, M):\n",
    "            ## step through each time point\n",
    "            for t in range(0, n):\n",
    "                ## select P(S_t | S_t-1)\n",
    "                if t == 0:\n",
    "                    tback = np.ones(K[i])\n",
    "                else:\n",
    "                    prev = zstates[i][l-1, t-1]\n",
    "                    tback = Tmat[i][prev, :]\n",
    "                ## select P(S_t+1 | S_t)\n",
    "                if t == (n-1):\n",
    "                    tfore = np.ones(K[i])\n",
    "                else:\n",
    "                    fore = zstates[i][l-1, t]\n",
    "                    tfore = Tmat[i][fore, :]\n",
    "                ## calculate P(Y_t | S_t^1, S_t^2, ..., S_t^M)\n",
    "                ydense = y_density(t, Y[:, t], M, K, S, C, W, i)\n",
    "                \n",
    "                ## Calculate probability for each state for S_t^i\n",
    "                probvec = np.multiply(np.multiply(tback, tfore) , ydense)\n",
    "                if np.sum(probvec) == 0: # check if all states have 0 probability\n",
    "                    probvec = np.ones(len(probvec)) # reset to equal probs if so\n",
    "                probvec = probvec/sum(probvec)\n",
    "                ## sample state and update vector\n",
    "                zstates[i][l, t] = np.random.choice(range(0, K[i]), 1, p = probvec)\n",
    "                S[i][zstates[i][l, t], t] = 1\n",
    "    \n",
    "    ## Calculate expectations\n",
    "    # <S_t^(m)>\n",
    "    St = []\n",
    "    Smm = []\n",
    "    for i in range(0, M):\n",
    "        uprobs = [np.unique(zstates[i][:, t], return_counts = True)[1]/it for t in range(0,n)] # calculate probs\n",
    "        zmat = np.zeros((K[i], n))\n",
    "        inds = [np.unique(zstates[i][:, t], return_counts = True)[0] for t in range(0,n)]\n",
    "        for t in range(n):\n",
    "            zmat[inds[t], t] += uprobs[t] + small\n",
    "        #zmat = zmat/np.sum(zmat)\n",
    "        St.append(zmat)\n",
    "        # calculate trans mat\n",
    "        Smm.append(np.stack([trans_mat(zstates[i][:, t], K[i])/(it-1) for t in range(0, n)], axis = 2))  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # <S_t^(m)S_t^(n)>\n",
    "    Snm = np.zeros((sum(K), sum(K), n))\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0) # indices for Snm matrix\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            for j in range(0, M):\n",
    "                if i == j:\n",
    "                    s1 = np.zeros((K[i], K[i]))\n",
    "                    mm = np.unique(zstates[i][:, t], return_counts = True)\n",
    "                    s1[mm[0], mm[0]] = mm[1]/it\n",
    "                    Snm[ind1[i]:ind2[i], ind1[i]:ind2[i], t] = s1\n",
    "                s2 = np.zeros((K[i], K[j]))\n",
    "                for l in range(0, it):\n",
    "                    s2[zstates[i][l, t], zstates[j][l, t]] += 1\n",
    "                Snm[ind1[i]:ind2[i], ind1[j]:ind2[j], t] = s2/it\n",
    "    \n",
    "    return(St, Smm, Snm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Completely Factorized VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KL divergence (to monitor convergence of approximation) - equation C.9\n",
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# pi is M long list of initial distributions\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# Return KL divergence\n",
    "def KL_factorized(n, M, K, Y, theta, pi, Tmat, W, C):\n",
    "    term1 = 0\n",
    "    term2 = 0\n",
    "    term3 = 0\n",
    "    term4 = 0\n",
    "    term5 = 0\n",
    "    term6 = 0\n",
    "    term7 = 0\n",
    "    small = 10E-10\n",
    "    for t in range(n):\n",
    "        term2 += np.dot(Y[:, t].transpose() , np.dot(np.linalg.inv(C), Y[:, t]))\n",
    "        for i in range(M):\n",
    "            term1 += np.dot(theta[i][:, t].transpose(), np.log(theta[i][:, t] + small))\n",
    "            term3 += np.dot(np.dot(Y[:, t].transpose(), np.linalg.inv(C)), np.dot(W[i], theta[i][:, t]))\n",
    "            for j in range(M):\n",
    "                if i != j:\n",
    "                    targ1 = np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), W[j])\n",
    "                    targ2 = np.dot(theta[j][:, t], theta[i][:, t].transpose())\n",
    "                    term4 += np.trace(np.dot(targ1, targ2))\n",
    "            \n",
    "            term5 += np.trace(np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), \n",
    "                                     np.dot(W[i], np.diag(theta[i][:, t]))))\n",
    "            if t > 0:\n",
    "                term7 += np.trace(np.outer(theta[i][:, t-1], \n",
    "                                           np.dot(theta[i][:, t].transpose(), np.log(Tmat[i] + small))))\n",
    "                \n",
    "    for i in range(M):\n",
    "        term6 += np.dot(theta[i][:, 0].transpose(), np.log(pi[i] + small))\n",
    "        \n",
    "    # Find normalizing constants\n",
    "    \n",
    "    KL = term1 + 0.5*(term2 - 2*term3 + term4 + term5) + term6 + term7\n",
    "    return(KL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax operator on input vector x\n",
    "def softmax(x):\n",
    "    y = x - np.max(x)\n",
    "    return(np.exp(y)/np.sum(np.exp(y)))\n",
    "\n",
    "\n",
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# theta is a M long list of K[m] x n matrices from completely factorized VI approx\n",
    "# pi is M long list of initial distributions\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# tol is the tolerance for convergence of the KL divergence to stop the iterations\n",
    "# output is:\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "def factorized_VI(n, M, K, Y, pi, Tmat, W, C, tol):\n",
    "    D = Y.shape[0]\n",
    "    thetaOld = []\n",
    "    thetaNew = []\n",
    "    for i in range(M):\n",
    "        vals1 = np.random.rand(K[i], n)\n",
    "        thetaOld.append(vals1/np.sum(vals1, axis=0)[None, :])\n",
    "        thetaNew.append(np.zeros((K[i], n)))\n",
    "\n",
    "    KLOld = 10E10\n",
    "    small = 10E-10\n",
    "    convergence = 0\n",
    "    iterations = 0\n",
    "    criteria = 10E10\n",
    "    maxit = 20 ## max number of iterations\n",
    "    while(convergence == 0):\n",
    "        for i in range(M):\n",
    "            for t in range(n):\n",
    "                ## Calculate Y tilde\n",
    "                s1 = np.zeros((D, 1))\n",
    "                for j in np.delete(np.arange(M), i):\n",
    "                    s1 += np.dot(W[j], thetaOld[j][:, t])[np.newaxis].transpose()\n",
    "                Ytilde = Y[:, t][np.newaxis].transpose() - s1\n",
    "                ## Calculate delta term\n",
    "                delta = np.dot(W[i].transpose(), np.dot(np.linalg.inv(C), W[i])).diagonal()\n",
    "                ## Calculate first term\n",
    "                term1 = np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), Ytilde)\n",
    "                term2 = delta[np.newaxis].transpose()/2\n",
    "                if t > 0:\n",
    "                    term3 = np.dot(np.log(Tmat[i] + small), thetaOld[i][:, t-1])[:, np.newaxis]\n",
    "                else:\n",
    "                    term3 = np.log(pi[i] + small)[np.newaxis].transpose()\n",
    "                if t < n-1:\n",
    "                    term4 = np.dot(np.log(Tmat[i] + small).transpose(), thetaOld[i][:, t+1])[np.newaxis].transpose()\n",
    "                else:\n",
    "                    term4 = np.zeros(K[i])[np.newaxis].transpose()\n",
    "                ## Find sum\n",
    "                sumterm = term1 - term2 + term3 + term4\n",
    "                thetaNew[i][:, t] = softmax(sumterm).transpose()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## Check KL divergence\n",
    "\n",
    "\n",
    "\n",
    "        #KLNew = KL_factorized(n, M, K, Y, thetaNew, pi, Tmat, W, C)\n",
    "        #print(KLNew)\n",
    "        #criteria = abs(KLOld - KLNew)\n",
    "        if criteria < tol or iterations > maxit:\n",
    "            convergence = 1\n",
    "        #else:\n",
    "        #    convergence = 0\n",
    "        #    KLOld = KLNew\n",
    "        #    thetaOld = thetaNew\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    ## Find expectations\n",
    "    # St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "    # Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "    # Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "    St = [np.zeros((K[i], n)) for i in range(M)]\n",
    "    Smm = [np.zeros((K[i], K[i], n)) for i in range(M)]\n",
    "    Snm = np.zeros((np.sum(K), np.sum(K), n))\n",
    "    for i in range(M):\n",
    "        for t in range(n):\n",
    "            St[i][:, t] = thetaNew[i][:, t]\n",
    "            if t == 0:\n",
    "                Smm[i][:, :, t] = np.outer(pi[i], thetaNew[i][:, t])\n",
    "            else:\n",
    "                Smm[i][:, :, t] = np.outer(thetaNew[i][:, t-1], thetaNew[i][:, t])\n",
    "\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0) # indices for Snm matrix\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            for j in range(0, M):\n",
    "                if i == j:\n",
    "                    Snm[ind1[i]:ind2[i], ind1[i]:ind2[i], t] = np.diag(thetaNew[i][:, t])\n",
    "                else:\n",
    "                    Snm[ind1[i]:ind2[i], ind1[j]:ind2[j], t] = np.outer(thetaNew[i][:, t], thetaNew[j][:, t])\n",
    "                    \n",
    "    return(St, Smm, Snm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Structural VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forward- Backward Algorithm\n",
    "#Function using the log-sum-exp trick#\n",
    "def logSumExp(a):\n",
    "    if np.all(np.isinf(a)):\n",
    "        return np.log(0)\n",
    "    else:\n",
    "        b = np.max(a)\n",
    "        return(b + np.log(np.sum(np.exp(a-b))))\n",
    "\n",
    "\n",
    "def pForwardFHMM(g):\n",
    "    n, m = g.shape\n",
    "    pXf = logSumExp(g[n-1,:])\n",
    "    return(pXf)\n",
    "\n",
    "    \n",
    "def forwardAlgFHMM(n, m, pi, Tmat, phi):\n",
    "    g = np.zeros((n,m))\n",
    "    for i in range(0,m):\n",
    "        g[0,i] = (pi[i]) + (phi[i, 0])\n",
    "    \n",
    "    \n",
    "    for j in range(1, n):\n",
    "        for l in range(0, m):\n",
    "            g[j,l] = logSumExp(np.asarray(g[j-1, :]) + np.asarray(Tmat[:,l]) + (phi[l, j]))\n",
    "    return(g)\n",
    "\n",
    "def backwardAlgFHMM(n, m, pi, Tmat, phi):\n",
    "    r = np.zeros((n,m))\n",
    "    for j in range(n-2, -1, -1):\n",
    "        for l in range(0, m):\n",
    "            r[j, l] = logSumExp(np.asarray(r[j+1,: ]) + np.asarray(Tmat[l,:]) + phi[:, j+1])\n",
    "    \n",
    "    return(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n is the number of observations\n",
    "# M is number of Markov hidden chains\n",
    "# K is number of hidden states for each chain (1 x M vector)\n",
    "# Y is the matrix of observations (D x n)\n",
    "# theta is a M long list of K[m] x n matrices from completely factorized VI approx\n",
    "# pi is M long list of initial distributions\n",
    "# Tmat is a list of M KxK transition matrices\n",
    "# W is a list of M D x K matrix, columns contribution to mean of each state variable\n",
    "# C is the covariance matrix for the observations\n",
    "# tol is the tolerance for convergence of the KL divergence to stop the iterations\n",
    "# output is:\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "def structural_VI(n, M, K, Y, pi, Tmat, W, C, tol):\n",
    "    D = Y.shape[0]\n",
    "    small = 10E-10\n",
    "    ## Work with log of parameters\n",
    "    piL = [np.log(pi[i] + small) for i in range(M)]\n",
    "    TmatL = [np.log(Tmat[i] + small) for i in range(M)]\n",
    "    # St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "    St = [np.zeros((K[i], n)) for i in range(M)]\n",
    "    ## h matrices which serve as emission distributions for forward-backward\n",
    "    phi = [np.zeros(shape = (K[i], n)) for i in range(M)]\n",
    "    ## Randomly initialize St\n",
    "    for i in range(M):   \n",
    "        vals = np.random.rand(K[0], n)\n",
    "        St[i] = vals/np.sum(vals, axis=0)[None, :]\n",
    "    \n",
    "    \n",
    "    pOld = 10E10#*np.ones(M)\n",
    "    pNew = np.zeros(M)\n",
    "    convergence = 0\n",
    "    iterations = 0\n",
    "    criteria = 10E10\n",
    "    maxit = 20 ## max number of iterations\n",
    "    while(convergence == 0):\n",
    "        for i in range(M):\n",
    "            ## 1. Find ht = phi ##\n",
    "\n",
    "            ## Calculate delta term\n",
    "            delta = np.dot(W[i].transpose(), np.dot(np.linalg.inv(C), W[i])).diagonal()\n",
    "\n",
    "            for t in range(n):\n",
    "                ## Calculate Y tilde\n",
    "                s1 = np.zeros((D, 1))\n",
    "                for j in np.delete(np.arange(M), i):\n",
    "                    s1 += np.dot(W[j], St[j][:, t])[np.newaxis].transpose()\n",
    "                Ytilde = Y[:, t][np.newaxis].transpose() - s1\n",
    "                term1 = np.dot(np.dot(W[i].transpose(), np.linalg.inv(C)), Ytilde)\n",
    "                term2 = delta[np.newaxis].transpose()/2\n",
    "                #phi[i][:, t] = np.exp(term1 - term2).transpose()\n",
    "                phi[i][:, t] = (term1 - term2).transpose()\n",
    "\n",
    "\n",
    "            ## 2. Run Forwards-Backwards Algorithm\n",
    "\n",
    "            g = forwardAlgFHMM(n, K[i], piL[i], TmatL[i], phi[i])\n",
    "            h = backwardAlgFHMM(n, K[i], piL[i], TmatL[i], phi[i])\n",
    "            pNew[i] = pForwardFHMM(g)\n",
    "            #print(g)\n",
    "            #print(pForward(g))\n",
    "\n",
    "            ## 3. Update expectations\n",
    "            for t in range(0, n):\n",
    "                for j in range(0, K[i]):\n",
    "                    St[i][j, t] = np.exp(g[t, j] + h[t, j] - pNew[i])\n",
    "                    \n",
    "            #print(np.sum(St[i]))\n",
    "        ## Check log-likelihood\n",
    "        #print(KLNew)\n",
    "        #print(pOld)\n",
    "        #print(pNew)\n",
    "        criteria = abs(pOld - np.max(pNew))\n",
    "        if criteria < tol or iterations > maxit:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            pOld = np.max(pNew)\n",
    "            #thetaOld = thetaNew\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    ## Find expectations\n",
    "    # St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "    # Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "    # Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "    \n",
    "    ## St already found above\n",
    "    Smm = [np.zeros((K[i], K[i], n)) for i in range(M)]\n",
    "    for i in range(M):\n",
    "        for t in range(n):\n",
    "            if t == 0:\n",
    "                Smm[i][:, :, t] = np.outer(pi[i], St[i][:, t])\n",
    "            else:\n",
    "                Smm[i][:, :, t] = np.outer(St[i][:, t-1], St[i][:, t])\n",
    "    \n",
    "    #intermed = Smm[m][:, :, t]/np.sum(Smm[m][:, :, t])\n",
    "    #Smm[m][:, :, t] = np.exp(intermed)/np.sum(np.exp(intermed)) ## renormalize\n",
    "    \n",
    "#     for m in range(M):\n",
    "#         for t in range(0, n):\n",
    "#             for i in range(0, K[m]):\n",
    "#                 for j in range(0, K[m]):\n",
    "#                     if t == 0:\n",
    "#                         #Smm[m][i, j, t] = np.exp(TmatL[m][i,j] + phi[m][j, t] + piL[m][i] + h[t, j] - pNew[m])\n",
    "#                         Smm[m][i, j, t] = TmatL[m][i,j] + phi[m][j, t] + piL[m][i] + h[t, j] - pNew[m]\n",
    "#                     else:\n",
    "#                         #Smm[m][i, j, t] = np.exp(TmatL[m][i,j] + phi[m][j, t] + g[t-1, i] + h[t, j] - pNew[m])\n",
    "#                         Smm[m][i, j, t] = TmatL[m][i,j] + phi[m][j, t] + g[t-1, i] + h[t, j] - pNew[m]\n",
    "            \n",
    "#             #print(np.sum(Smm[m][:, :, t]))\n",
    "#             if np.sum(Smm[m][:, :, t]) < small:\n",
    "#                 Smm[m][:, :, t] += small\n",
    "            \n",
    "#             intermed = Smm[m][:, :, t]/np.sum(Smm[m][:, :, t])\n",
    "#             Smm[m][:, :, t] = np.exp(intermed)/np.sum(np.exp(intermed)) ## renormalize\n",
    "    \n",
    "    \n",
    "    Snm = np.zeros((np.sum(K), np.sum(K), n))\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0) # indices for Snm matrix\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            for j in range(0, M):\n",
    "                if i == j:\n",
    "                    Snm[ind1[i]:ind2[i], ind1[i]:ind2[i], t] = np.diag(St[i][:, t])\n",
    "                else: ## Assume independence\n",
    "                    Snm[ind1[i]:ind2[i], ind1[j]:ind2[j], t] = np.outer(St[i][:, t], St[j][:, t])\n",
    "                    \n",
    "    return(St, Smm, Snm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "\n",
    "# # warnings.simplefilter(\"always\")\n",
    "# # for i in range(10):\n",
    "# #     print i\n",
    "# #     warnings.warn('this is a warning message')\n",
    "# warnings.simplefilter('error')\n",
    "# for i in range(100):\n",
    "#     print(i)\n",
    "#     St, Smm, Snm = structural_VI(n, M, K, Y, pi, Tmat, W, C_new, tol = 1E-5)\n",
    "#     W, pi, Tmat, C_new = Mstep(M, K,  Y, St, Smm, Snm)\n",
    "#     if not np.all(np.linalg.eigvals(C_new) > 0):\n",
    "#         print(C_new)\n",
    "#         break\n",
    "#     #print(np.all(np.linalg.eigvals(C_new) > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(M):\n",
    "#    print(np.sum(St[i], axis = 0))\n",
    "#    for t in range(n):\n",
    "#        print(np.sum(Smm[i][:,:,  t]))\n",
    "#        print(np.sum(St[i][:, t]))\n",
    "#for t in range(n):\n",
    "#    print(np.sum(Snm[0:5, 0:5, t]), np.sum(Snm[0:5, 5:10, t]), np.sum(Snm[0:5, 10:15, t]))\n",
    "#    print(np.sum(Snm[5:10, 0:5, t]), np.sum(Snm[5:10, 5:10, t]), np.sum(Snm[5:10, 10:15, t]))\n",
    "#    print(np.sum(Snm[10:15, 10:15, t]), np.sum(Snm[10:15, 10:15, t]), np.sum(Snm[10:15, 10:15, t]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M-Step\n",
    "\n",
    "## 5. M-Step\n",
    "\n",
    "$$ n = T$$\n",
    "$$W^{new} = \\left(\\sum_{t=1}^T Y_t<S_t'>\\right)\\left(\\sum_{t=1}^T<S_tS_t'>\\right)^{\\dagger}$$\n",
    "\n",
    "** Add other update equations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M is number of hidden state Markov chains\n",
    "# K is vector of number of hidden states for each Markov chain\n",
    "# Y is the D x n matrix of observations\n",
    "# St is a M long list of  K[i] x n matrices of the <S_t^(m)> expectations\n",
    "# Smm is a M long list of K[m] x K[m] x n matrices of <S_t-1^(m)S_t^(m)'> expectations\n",
    "# Snm is a sum(K) x sum(K) x n=T matrix of <S_t^(q)S_t^(m)'> expectations\n",
    "# output is a tuple of updated values from the M step\n",
    "# W is a M long list of D x K[m] matrices\n",
    "# pi is a M long list of K[m] vectors for the initial distributions\n",
    "# Tmat is a M long list of K[m] x K[m] transition matrices\n",
    "# C is a D x D covariance matrix for the Gaussian observations\n",
    "\n",
    "def Mstep(M, K,  Y, St, Smm, Snm):\n",
    "    ### Update W ###\n",
    "    # Concatenate St to be sum(K) x 1 x t\n",
    "    cSt = np.vstack([np.vstack(St[i]) for i in range(0, len(St))])\n",
    "    s1 = np.dot(Y, cSt.transpose()) # first sum for Wnew\n",
    "    s2 = np.linalg.pinv(np.sum(Snm, axis = 2)) # second sum for Wnew\n",
    "    Wnew = np.dot(s1, s2)\n",
    "    # make Wnew back into list of matrices\n",
    "    W = []\n",
    "    pi = []\n",
    "    ind1 = np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    ind2 = K + np.insert(np.cumsum(K[1:]), 0, 0)\n",
    "    for i in range(0, M):\n",
    "        W.append(Wnew[:, ind1[i]:ind2[i]])\n",
    "        ### Update pi ###\n",
    "        pi.append(cSt[ind1[i]:ind2[i], 0])\n",
    "\n",
    "    ### Update Transition matrices ###\n",
    "    Tmat = []\n",
    "    #St = [np.vstack(St[i]) for i in range(0, M)] ## stack St matrices for easier indexing\n",
    "    for i in range(0, M):\n",
    "        Tnew = np.zeros((K[i], K[i]))\n",
    "        for j in range(0, K[i]):\n",
    "            for l in range(0, K[i]):\n",
    "                Tnew[j,l] =  np.sum(Smm[i][j, l, :])/np.max([np.sum(St[i][l, 0:(n-1)]), 10E-5])\n",
    "        #print(np.sum(Tnew, axis=1)[:,None])\n",
    "        if np.any(np.sum(Tnew, axis=1)[:,None]):\n",
    "            #print(\"Yes\")\n",
    "            Tnew = Tnew + 10E-5\n",
    "        #print(np.sum(Tnew, axis=1)[:,None])\n",
    "        Tnew = Tnew/np.sum(Tnew, axis=1)[:,None]\n",
    "        Tmat.append(Tnew)\n",
    "\n",
    "    ### Update C covariance ###\n",
    "    #s1 = np.dot(Y, Y.transpose())/n\n",
    "    #s2 = np.zeros((D, D))\n",
    "    #for t in range(0, n):\n",
    "    #    for i in range(0, M):\n",
    "    #        mult1 = np.dot(W[i], St[i][t, :])\n",
    "    #        s2 += np.outer(mult1, Y[:, t].transpose())\n",
    "    #C = s1 - s2/n\n",
    "    \n",
    "    #mutemp = np.zeros((D, n))\n",
    "    #for i in range(0, M):\n",
    "    #    mutemp += np.dot(W[i], np.vstack(St[i]))\n",
    "    #C = np.dot(Y - mutemp, (Y - mutemp).transpose())/n\n",
    "    \n",
    "    term2 = np.zeros((D, D))\n",
    "    for i in range(M):\n",
    "        for t in range(n):\n",
    "            term2 += np.dot(np.dot(W[i], St[i][:, t][:, np.newaxis]), Y[:, t][np.newaxis])\n",
    "\n",
    "\n",
    "    C = np.dot(Y, Y.transpose())/n - term2/n\n",
    "    \n",
    "    return(W, pi, Tmat, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Inference: Run E-M Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is D x n observation matrix\n",
    "# M is number of hidden markov chains\n",
    "# K is an 1 x M vector of the number of hidden states for each chain\n",
    "# tol = tolerance for convergence\n",
    "# inference is inference method to use, choices = Gibbs, FactorizedVI, StructuralVI\n",
    "def FHMM(Y, M, K, tol, inference):\n",
    "    D, n = Y.shape\n",
    "    ## Initialize params\n",
    "    pi = [] ## initial distribution\n",
    "    Tmat = []  ## transition distribution\n",
    "    W = [] ## contribution to means matrices D x K\n",
    "    for i in range(0, M):\n",
    "        vals = np.random.rand(K[i])\n",
    "        pi.append(vals/np.sum(vals))\n",
    "        vals1 = np.random.rand(K[i], K[i])\n",
    "        Tmat.append(vals1/np.sum(vals1, axis=1)[:,None])\n",
    "        W.append(10*np.random.rand(D, K[i]))\n",
    "    C_old = np.identity(D)\n",
    "    \n",
    "    convergence = 0\n",
    "    pOld = 10E10\n",
    "    iterations = 0\n",
    "    while(convergence == 0):\n",
    "        \n",
    "        ## E - Step\n",
    "        if inference == \"Gibbs\":\n",
    "            St, Smm, Snm = gibbs_sampler(n, M, K, Y, Tmat, W, C_old, it = 10)\n",
    "            \n",
    "        if inference == \"FactorizedVI\":\n",
    "            St, Smm, Snm = factorized_VI(n, M, K, Y, pi, Tmat, W, C_old, tol = 1E-5)\n",
    "            \n",
    "        if inference == \"StructuralVI\":\n",
    "            St, Smm, Snm = structural_VI(n, M, K, Y, pi, Tmat, W, C_old, tol = 1E-5)\n",
    "        \n",
    "        ## M - Step\n",
    "        W, pi, Tmat, C_new = Mstep(M, K,  Y, St, Smm, Snm)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ## Check tolerance\n",
    "        # sample S with new params\n",
    "        ## Generate state variables\n",
    "        #S = []\n",
    "        #mu = np.zeros((D, n))\n",
    "        #zstore = []\n",
    "        #for i in range(0, M):\n",
    "        #    zstates = np.arange(0, K[i], dtype = int)\n",
    "        #    z = np.zeros(n, dtype = int)\n",
    "        #    zmat = np.zeros((K[i], n), dtype = int)\n",
    "        #    z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "        #    zmat[z[0], 0] = 1\n",
    "        #    for j in range(1, n):\n",
    "        #        z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "        #        zmat[z[j], j] = 1\n",
    "        #    S.append(zmat)\n",
    "        #    zstore.append(z)\n",
    "        #for i in range(0, M):\n",
    "        #    for j in range(1, n):\n",
    "        #        mu[:, j] += np.dot(W[i], S[i][:, j])\n",
    "        \n",
    "        #pNew = log_like(n, pi, Tmat, mu, C, Y, zstore) \n",
    "        \n",
    "        \n",
    "        ## Monitor convergence of C since does not have label switching issues like other params\n",
    "        criteria = np.linalg.norm(C_old - C_new)\n",
    "        #criteria = abs(pOld - pNew)\n",
    "        if criteria < tol or iterations > 500:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            #pOld = pNew\n",
    "            C_old = C_new\n",
    "    \n",
    "        iterations += 1\n",
    "        if iterations%10 == 0:\n",
    "            print(iterations)\n",
    "            print(criteria)\n",
    "            \n",
    "    if not np.all(np.linalg.eigvals(C_new) > 0):\n",
    "           C_new = np.dot(C_new.transpose(), C_new)\n",
    "    return(pi, Tmat, mu, C_new, W)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "6.467832683124013\n",
      "20\n",
      "4.403414820318734\n",
      "30\n",
      "11.56125857930364\n",
      "40\n",
      "17.59258594518104\n",
      "50\n",
      "1.2156465908229521\n",
      "60\n",
      "2.6800360296176713\n",
      "70\n",
      "0.5801671537951137\n",
      "80\n",
      "2.9533522744481844\n",
      "90\n",
      "1.9485324821977155\n",
      "[[19.76463853  3.86406901 -2.31018184]\n",
      " [ 3.86406901  1.5704837  -0.35730166]\n",
      " [-2.31018184 -0.35730166  0.62564909]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_new, Tmat_new, mu_new, C_new, W_new = FHMM(Y, M, K, 0.1, \"FactorizedVI\")\n",
    "print(C_new)\n",
    "np.all(np.linalg.eigvals(C_new) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "4.490965249737926\n",
      "20\n",
      "5.506070557434812\n",
      "30\n",
      "1.082176822226427\n",
      "[[29.28927295 11.07334164 -7.39604979]\n",
      " [11.07334164 13.9858158   3.87480983]\n",
      " [-7.39604979  3.87480983 11.77714872]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_new, Tmat_new, mu_new, C_new, W_new = FHMM(Y, M, K, 2, \"Gibbs\")\n",
    "print(C_new)\n",
    "np.all(np.linalg.eigvals(C_new) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "7.8772270450914235\n",
      "20\n",
      "9.396238278997338\n",
      "30\n",
      "12.38067320911451\n",
      "40\n",
      "10.585347712173\n",
      "50\n",
      "5.602576293529085\n",
      "60\n",
      "7.529250048671103\n",
      "70\n",
      "5.179583557339078\n",
      "[[13.98888929 10.42145607  5.5700366 ]\n",
      " [10.42145607 33.8482872  21.79498203]\n",
      " [ 5.5700366  21.79498203 14.15585699]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_new, Tmat_new, mu_new, C_new, W_new = FHMM(Y, M, np.array([3, 3, 3]), 1, \"StructuralVI\")\n",
    "print(C_new)\n",
    "np.all(np.linalg.eigvals(C_new) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.linalg.eigvals(C_new) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.22952395,  0.26194639,  0.11809421])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvals(C_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C_new[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annayanchenko/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.88356932,  0.91333524, -0.66946396]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.multivariate_normal(np.zeros(3), C_new, 1, tol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_sequence(n, D, M, K, pi, Tmat, C, W):\n",
    "    ## Generate state variables\n",
    "    S = []\n",
    "    for i in range(0, M):\n",
    "        zstates = np.arange(0, K[i], dtype = int)\n",
    "        z = np.zeros(n, dtype = int)\n",
    "        zmat = np.zeros((K[i], n), dtype = int)\n",
    "        z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "        zmat[z[0], 0] = 1\n",
    "        for j in range(1, n):\n",
    "            z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "            zmat[z[j], j] = 1\n",
    "        S.append(zmat)\n",
    "    mu = np.zeros((D, n))\n",
    "    Y = np.zeros((D, n))\n",
    "    for t in range(0, n):\n",
    "        for i in range(0, M):\n",
    "            mu[:, t] += np.dot(W[i], S[i][:, t])\n",
    "        Y[:, t] = np.random.multivariate_normal(mu[:, t], C, 1)\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annayanchenko/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: covariance is not positive-semidefinite.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16.47279006, 21.27830851, 17.16516976, 22.58819907, 14.67235784,\n",
       "        19.89475411, 15.56563507, 19.59145992, 14.14347911, 21.32416265],\n",
       "       [17.32953341, 16.72907076, 15.46957202, 10.00396505,  8.56552976,\n",
       "         8.08849012,  7.78869003,  7.14888238,  6.55771533, 10.0044372 ],\n",
       "       [20.27255282, 18.06996353, 24.05224757, 12.09445613, 20.38632903,\n",
       "        12.73914654, 20.64608648, 12.64422652, 20.97920438, 12.96817573]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sequence(n, D, M, K, pi_new, Tmat_new, C_new, W_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Models\n",
    "\n",
    "Assumes univariate distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 5., 5.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from scipy.stats import norm\n",
    "# norm.logpdf(Y, loc = np.zeros(3), scale = np.ones(3))\n",
    "np.ones(3)*(5*np.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "\n",
    "# mu, Sigma vectors of params for each possible value of hidden states each is 1 x K[i]\n",
    "# make emission distribution matrix for normal case\n",
    "# X is D x n\n",
    "def make_phi(n, m, mu, Sigma, X):\n",
    "    phi = np.zeros((m, n))\n",
    "    for i in range(m):\n",
    "        #phi[i, :] = multivariate_normal.logpdf(X.transpose(), mean = mu[i], cov = Sigma[i])\n",
    "        phi[i, :] = norm.logpdf(X, loc = mu[i], scale = Sigma[i]) ## need standard dev\n",
    "    return(phi)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def forwardAlgGAM(n, m, pi, Tmat, phi):\n",
    "    g = np.zeros((n,m))\n",
    "    for i in range(0,m):\n",
    "        g[0,i] = (pi[i]) + (phi[i, 0])\n",
    "    \n",
    "    for j in range(1, n):\n",
    "        for l in range(0, m):\n",
    "            g[j,l] = logSumExp(np.asarray(g[j-1, :]) + np.asarray(Tmat[:,l]) + (phi[l, j]))\n",
    "    return(g)\n",
    "\n",
    "def backwardAlgGAM(n, m, pi, Tmat, phi):\n",
    "    r = np.zeros((n,m))\n",
    "    for j in range(n-2, -1, -1):\n",
    "        for l in range(0, m):\n",
    "            r[j, l] = logSumExp(np.asarray(r[j+1,: ]) + np.asarray(Tmat[l,:]) + phi[:, j+1])\n",
    "    return(r)\n",
    "\n",
    "def ViterbiGAM(n, m, pi, Tmat, phi, x):\n",
    "    f = np.zeros(shape = (n,m))\n",
    "    alpha = np.zeros(shape = (n,m))\n",
    "    zStar = np.zeros(n)\n",
    "    \n",
    "    for t in range(0, n):\n",
    "        for i in range(0,m):\n",
    "            if t == 0:\n",
    "                f[0, i] = pi[i] + phi[i, 0]\n",
    "            else:\n",
    "                u = np.asarray(f[t-1, :]) + np.asarray(Tmat[:, i]) + phi[i, t]\n",
    "                f[t,i] = np.max(u)\n",
    "                alpha[t,i] = np.argmax(u)\n",
    "    zStar[n-1] = np.argmax(np.asarray(f[n-1, :]))\n",
    "    for i in range(n-2, -1, -1):\n",
    "        zStar[i] = alpha[i+1, int(zStar[i+1])]\n",
    "    return zStar\n",
    "\n",
    "## method = type of expectation to find, choices are \"gamma\" and \"V\", see paper pg. 2428\n",
    "def first_orderGAM(n, m, x, w, tol, method):\n",
    "    #randomly initialize pi, phi and T#\n",
    "    vals = np.random.rand(m)\n",
    "    pi = np.log(vals/np.sum(vals))\n",
    "    Tmat = np.zeros(shape = (m, m))\n",
    "    mu = np.zeros(m)\n",
    "    Sigma = np.ones(m)\n",
    "    phi = make_phi(n, m, mu, Sigma, x)\n",
    "    gamma = np.zeros(shape = (n, m))\n",
    "    beta = np.zeros(shape = (n,m,m))\n",
    "    iterations = 0\n",
    "    convergence = 0\n",
    "    count = 0\n",
    "    pOld = 1E10\n",
    "    pNew = 0\n",
    "    criteria = 0\n",
    "    \n",
    "    vals1 = np.random.rand(m,m)\n",
    "    Tmat = np.log(vals1/np.sum(vals1, axis=1)[:,None])\n",
    "    \n",
    "    \n",
    "    #Stop iterations when log(p(x_1:n)) differs by tol between iterations#\n",
    "    while convergence == 0:\n",
    "        #Perform forward and backward algorithms# \n",
    "        g = forwardAlgGAM(n, m, pi, Tmat, phi)\n",
    "        h = backwardAlgGAM(n, m, pi, Tmat, phi)\n",
    "        pNew = pForwardFHMM(g)\n",
    "        \n",
    "        ##E-Step##\n",
    "    \n",
    "        #Calculate gamma and beta#\n",
    "        for t in range(0, n):\n",
    "            for i in range(0,m):\n",
    "                gamma[t,i] = g[t,i] + h[t,i] - pNew\n",
    "        #p = np.full((n,m), pNew)\n",
    "        #gamma = g+h-p\n",
    "        for t in range(1, n):\n",
    "            for i in range(0, m):\n",
    "                for j in range(0, m):\n",
    "                    beta[t,i,j] = Tmat[i,j] + phi[j, t] + g[t-1, i] + h[t, j] - pNew\n",
    "        ##M-Step##\n",
    "    \n",
    "        #Update pi, phi and Tmat#\n",
    "        pi = gamma[0,:] - logSumExp(gamma[0,:])\n",
    "        for i in range(0, m):\n",
    "            for j in range(0, m):\n",
    "                Tmat[i,j] = logSumExp(beta[1::, i, j]) - logSumExp(beta[1::, i,:])\n",
    "        \n",
    "        \n",
    "        ## Update mu, Sigma\n",
    "        for i in range(0, m):\n",
    "            mu[i] = np.sum(np.exp(gamma[:, i])*w*x)/np.sum(np.exp(gamma[:, i])*w)\n",
    "            Sigma[i] = np.sum(np.exp(gamma[:, i])*w*(x - mu[i])**2)/np.sum(np.exp(gamma[:, i])*w)\n",
    "            \n",
    "        # Update phi\n",
    "#         Sigma = np.sqrt(Sigma)\n",
    "#         for i in range(m):\n",
    "#             if Sigma[i] == 0 or iterations == 1:\n",
    "#                 print(np.exp(phi))\n",
    "#                 print(g)\n",
    "#                 print(h)\n",
    "#                 print(pNew)\n",
    "#                 print(Sigma)\n",
    "#                 print(gamma[:, i])\n",
    "#                 print(np.sum(np.exp(gamma[:, i])*w*(x - mu[i])**2))\n",
    "#                 print(np.sum((x - mu[i])**2))\n",
    "#                 print(np.sum(np.exp(gamma[:, i])*w))\n",
    "#                 print(mu[i])\n",
    "#                 print(\"\\n\")\n",
    "        phi = make_phi(n, m, mu, Sigma, x)\n",
    "        \n",
    "        \n",
    "        criteria = abs(pOld - pNew)\n",
    "        if criteria < tol:\n",
    "            convergence = 1\n",
    "        \n",
    "        elif iterations > 10:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            pOld = pNew\n",
    "            iterations +=1\n",
    "            #print(iterations)\n",
    "            \n",
    "    if method == \"gamma\":\n",
    "        expect = gamma.transpose()\n",
    "    if method == \"V\":\n",
    "        most_likely = ViterbiGAM(n, m, np.exp(pi), np.exp(Tmat), np.exp(phi), x) ## Viterbi\n",
    "        # Use one-hot encoding\n",
    "        expect = np.zeros((m, n))\n",
    "        for t in range(n):\n",
    "            expect[int(most_likely[t]), t] = 1\n",
    "    return (iterations, pNew, np.exp(pi), np.exp(phi), np.exp(Tmat), mu, Sigma, expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.ones(n)\n",
    "tol = 1E-3\n",
    "iterations, pNew, pi, phi, Tmat, mu, Sigma, expect = first_order(n, K[0], Y[0, :], w, tol, \"V\")\n",
    "#Viterbi(n, K[0], pi, Tmat, phi, Y[0, :])\n",
    "expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "a[np.arange(len(a))!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y is D x n observation matrix\n",
    "# M is number of hidden markov chains\n",
    "# K is an 1 x M vector of the number of hidden states for each chain\n",
    "# tol = tolerance for convergence\n",
    "# method is type of expectation to find, choices are \"gamma\" and \"V\"\n",
    "# inference is type of observed data, choices = Gaussian\n",
    "def GAM_FHMM(x, M, K, tol, inference, method):\n",
    "    n = len(x)\n",
    "    ## Initialize params\n",
    "    pi = [np.zeros(K[i]) for i in range(M)] ## initial distribution\n",
    "    Tmat = [np.ones((K[i], K[i])) for i in range(M)]  ## transition distribution\n",
    "    mu = [np.zeros(K[i]) for i in range(M)] ## contribution to means, initially 0 for all chains\n",
    "    Sigma = [np.ones(K[i]) for i in range(M)] ## variance for emission distributions, initially one for all chains\n",
    "    W = [np.random.rand(n) for i in range(M)] ## weights for GAM\n",
    "    expect = [np.ones((K[i], n)) for i in range(M)] ## expected values for f updates\n",
    "    phi = [make_phi(n, K[i], mu[i], Sigma[i], x) for i in range(M)]\n",
    "    convergence = 0\n",
    "    pOld = 10E10\n",
    "    iterations = 0\n",
    "    while(convergence == 0):\n",
    "        \n",
    "        ## E - Step\n",
    "        for i in range(M):\n",
    "            if inference == \"Gaussian\":\n",
    "                W = [np.ones(n) for i in range(M)]\n",
    "                err = np.zeros(n)\n",
    "                for t in range(n):\n",
    "                    sterm = 0\n",
    "                    for j in np.delete(np.arange(M), i):\n",
    "                        sterm += np.dot(mu[j], expect[j][:, t])\n",
    "\n",
    "                    err[t] = x[t] - sterm\n",
    "                    \n",
    "                _, pNew, pi[i], phi[i], Tmat[i], mu[i], Sigma[i], expect[i] = first_orderGAM(n, K[i], \n",
    "                                                                                          err, W[i], tol, method)\n",
    "                Sigma[i] = np.sqrt(Sigma[i])\n",
    "            \n",
    "        ## Check tolerance\n",
    "        \n",
    "        \n",
    "        ## Monitor convergence of C since does not have label switching issues like other params\n",
    "        criteria = abs(pOld - pNew)\n",
    "        if criteria < tol or iterations > 500:\n",
    "            convergence = 1\n",
    "        else:\n",
    "            convergence = 0\n",
    "            pOld = pNew\n",
    "    \n",
    "        iterations += 1\n",
    "        if iterations%10 == 0:\n",
    "            print(iterations)\n",
    "            print(criteria)\n",
    "            \n",
    "    return(pi, Tmat, phi, mu, Sigma)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0.9260770234219109\n",
      "20\n",
      "0.43845149414941176\n"
     ]
    }
   ],
   "source": [
    "pi, Tmat, phi, mu, Sigma = GAM_FHMM(Y[0, :], M, K, 1E-2, \"Gaussian\", \"V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.46307807, 10.91478596,  9.06284829, 24.33646301,  9.30090597,\n",
       "        9.39570944, 12.84926431, 22.56246619, 15.74604623, 21.96205872])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.29518965, 15.40713287, 15.68502338, 13.37025373, 16.73312722,\n",
       "       17.31487785, 13.13230919, 18.23849938, 15.03339718, 14.03975806])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_GAM(n, M, K, pi, Tmat, mu, Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_GAM(n, M, K, pi, Tmat, mu, Sigma):\n",
    "    ## Generate state variables\n",
    "    S = []\n",
    "    for i in range(0, M):\n",
    "        zstates = np.arange(0, K[i], dtype = int)\n",
    "        z = np.zeros(n, dtype = int)\n",
    "        zmat = np.zeros((K[i], n), dtype = int)\n",
    "        z[0] = np.random.choice(zstates, size = 1, p = pi[i])\n",
    "        zmat[z[0], 0] = 1\n",
    "        for j in range(1, n):\n",
    "            z[j] = np.random.choice(zstates, size = 1, p = Tmat[i][z[j-1], :])\n",
    "            zmat[z[j], j] = 1\n",
    "        S.append(zmat)\n",
    "    Y = np.zeros(n)\n",
    "    for t in range(0, n):\n",
    "        mean = 0\n",
    "        sig = 0\n",
    "        for i in range(0, M):\n",
    "            mean += np.dot(mu[i], S[i][:, t])\n",
    "            sig += Sigma[i][np.where(S[i][:, t] == 1)[0]]\n",
    "        Y[t] = np.random.normal(loc = mean, scale = sig/n, size = 1)\n",
    "    return(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Composition\n",
    "\n",
    "## HMM_compose\n",
    "\n",
    "This is the main function to take in an original piece, learn the appropriate model parameters, generate a new piece, calculate metrics and output the results.\n",
    "**Inputs:**\n",
    "- input_filename = csv file of original piece (converted from MIDI using http://www.fourmilab.ch/webtools/midicsv/#midicsv.5)\n",
    "- output_filename = filename for csvs of generated pieces and metrics\n",
    "- min_note = length of shortest note occurring in original piece\n",
    "- model = appropriate HMM model to fit, options include 'first_order', 'random', 'first_order-LR', 'second_order', 'second_order-LR', 'third_order', 'third_order-LR', 'TSHMM', 'ARHMM', 'HSMM', 'TVAR', 'factorial' and 'layered'\n",
    "- m = number of hidden states for model \n",
    "- tol = tolerance for convergence of inference algorithms\n",
    "- it = number of generated pieces to produce to calculate metrics\n",
    "- m2 = number of hidden states for the top level of the TSHMM\n",
    "- metrics_calc = True (calculate metrics) or False (generate piece only)\n",
    "- case_study = True (return parameters to explore), False (only save generated piece and metrics to CSV, no other outputs)\n",
    "\n",
    "**Outputs:**\n",
    "- generated piece to 'output_filename', if multiple pieces are generated for metrics, last generated piece is saved by default\n",
    "- metrics for number of generated pieces specified by it are saved to metrics folder\n",
    "- If case_study = True:\n",
    "    - time = time stamp for each note in the original and generated pieces\n",
    "    - notes = original notes\n",
    "    - newNotes = generated note pitches\n",
    "    - z = sequence of generated hidden states\n",
    "    - pi1 = learned initial distribution\n",
    "    - phi1 = learned emission distribution\n",
    "    - Tmat1 = learned transition distribution\n",
    "\n",
    "Note: printed intergers correspond to iteration of inference algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_compose(input_filename, output_filename, min_note, model, m,  tol, it, m2 = None, metrics_calc = False,\n",
    "               case_study = False):\n",
    "    quarter_note, num, denom, key, measures, time, \\\n",
    "            notes, velocity, song, ind = pre_process(input_filename, min_note).read_process()\n",
    "\n",
    "    #Find possible unique notes and velocities\n",
    "    possibleNotes = np.unique(notes)\n",
    "    possibleVelocities =  np.unique(velocity)\n",
    "\n",
    "    k = len(possibleNotes)\n",
    "    xNotes = encode(notes, possibleNotes)\n",
    "    n = len(xNotes)\n",
    "    \n",
    "\n",
    "    if metrics_calc:\n",
    "        orig_metrics = calc_metrics(time, notes, notes, velocity, measures, min_note, num)\n",
    "        metrics = np.zeros(shape = (it+1, len(orig_metrics)))\n",
    "        metrics[0,:] = orig_metrics\n",
    "    \n",
    "\n",
    "    #Run BaumWelch for specified model\n",
    "    if model == 'first_order':\n",
    "        it1, p1, pi1, phi1, Tmat1 = first_order(n, m, k, xNotes, tol)\n",
    "        newNotes, z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "        newVelocities = find_vel(newNotes, velocity)\n",
    "        \n",
    "        if metrics_calc:\n",
    "            for i in range(it):\n",
    "                newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "                newVelocities = find_vel(newNotes, velocity)\n",
    "                metrics[i+1, :] = calc_metrics(time, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "            \n",
    "                \n",
    "                \n",
    "    if model == 'random':\n",
    "        vals = np.random.rand(m)\n",
    "        pi1 = vals/np.sum(vals)\n",
    "        Tmat1 = np.zeros(shape = (m, m))\n",
    "        phi1 = np.zeros(shape = (m, k))\n",
    "        vals1 = np.random.rand(m,m)\n",
    "        vals2 = np.random.rand(m,k)\n",
    "        Tmat1 = vals1/np.sum(vals1, axis=1)[:,None]\n",
    "        phi1 = vals2/np.sum(vals2, axis = 1)[:,None]\n",
    "        newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "        newVelocities = find_vel(newNotes, velocity)\n",
    "        \n",
    "        if metrics_calc:\n",
    "            for i in range(it):\n",
    "                newNotes,z  = hmm(n, pi1, phi1, Tmat1, None, None, possibleNotes,'first_order')\n",
    "                newVelocities = find_vel(newNotes, velocity)\n",
    "                metrics[i+1, :] = calc_metrics(time, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if model == 'TVAR':\n",
    "        # Find parameters that maximize likelihood\n",
    "        x = notes - np.mean(notes)\n",
    "        T = n\n",
    "        pvals=np.array([7, 15]) \n",
    "        p=pvals[1]  \n",
    "        dn=np.arange(0.94, 0.975,.005) \n",
    "        bn=np.arange(0.85, 0.915, 0.005) \n",
    "        m0=np.zeros(shape = (p,1)); n0=1; s0=0.01; C0=np.identity(p); \n",
    "        [popt,delopt,likp] = tvar_lik(x,pvals,dn,bn,m0,C0,s0,n0);\n",
    "        print(popt)\n",
    "\n",
    "        # Fit TVAR\n",
    "        p=popt; m0=np.zeros(shape = (p,1)); n0=1; s0=0.01; C0=np.identity(p);  # initial priors \n",
    "        delta=delopt\n",
    "        [m,C,n,s,e,mf,Cf,sf,nf,ef,qf] = tvar(x,p,delta,m0,C0,s0,n0);\n",
    "\n",
    "        # Simulate from TVAR\n",
    "        N=it; # MC sample size\n",
    "        times=range(T);\n",
    "        phis = tvar_sim(m,C,n,s,times,N)\n",
    "        print(phis.shape)\n",
    "\n",
    "        # Generate new notes\n",
    "\n",
    "        err_term = np.random.normal(0, np.sqrt(s))\n",
    "        z = np.zeros(len(notes))\n",
    "        newNotes = x\n",
    "        for i in range(it):\n",
    "            for t in range(p, T):\n",
    "                if t == p:\n",
    "                    newNotes[t] = np.dot(x[t-1::-1], phis[:,t,0]) + err_term[t]\n",
    "                    z[t] = np.dot(x[t-1::-1], phis[:,t,0])\n",
    "    \n",
    "                else:\n",
    "                    newNotes[t] = np.dot(x[t-1:t-p-1:-1], phis[:,t,0]) + err_term[t]\n",
    "                    z[t] = np.dot(x[t-1:t-p-1:-1], phis[:,t,0])\n",
    "                    \n",
    "            newNotes = np.round(newNotes + np.mean(notes))    \n",
    "            \n",
    "                \n",
    "            for j in range(len(notes)):\n",
    "                if newNotes[j] not in possibleNotes:\n",
    "                    newNotes[j] = find_nearest(possibleNotes, newNotes[j])\n",
    "            newVelocities = find_vel(newNotes, velocity)\n",
    "            if metrics_calc:\n",
    "                metrics[i+1, :] = calc_metrics(time, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "    \n",
    "        phi1 = None\n",
    "        Tmat1 = None\n",
    "        pi1 = None\n",
    "\n",
    "        m = popt\n",
    "\n",
    "    if model == 'factorial':  #originally 15, 10, 5, but 5,5,5 for case_study\n",
    "        xstates = range(0, k)\n",
    "        noteArray = np.zeros(shape = (3, n))\n",
    "        if case_study:\n",
    "            it1, p1, pi1, phi15, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar15 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi15), xNotes)\n",
    "            zStar15 = np.array(zStar15).astype(int)\n",
    "            it1, p1, pi1, phi10, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar10 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi10), xNotes)\n",
    "            zStar10 = np.array(zStar10).astype(int)\n",
    "            it1, p1, pi1, phi5, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar5 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi5), xNotes)\n",
    "            zStar5 = np.array(zStar5).astype(int)\n",
    "            z = [zStar15, zStar10, zStar5]\n",
    "            phi1 = [phi15, phi10, phi5]\n",
    "        \n",
    "        else:\n",
    "            it1, p1, pi1, phi15, Tmat1 = first_order(n, 15, k, xNotes, tol)\n",
    "            zStar15 = Viterbi(n, 15, k, np.log(pi1), np.log(Tmat1), np.log(phi15), xNotes)\n",
    "            zStar15 = np.array(zStar15).astype(int)\n",
    "            it1, p1, pi1, phi10, Tmat1 = first_order(n, 10, k, xNotes, tol)\n",
    "            zStar10 = Viterbi(n, 10, k, np.log(pi1), np.log(Tmat1), np.log(phi10), xNotes)\n",
    "            zStar10 = np.array(zStar10).astype(int)\n",
    "            it1, p1, pi1, phi5, Tmat1 = first_order(n, 5, k, xNotes, tol)\n",
    "            zStar5 = Viterbi(n, 5, k, np.log(pi1), np.log(Tmat1), np.log(phi5), xNotes)\n",
    "            zStar5 = np.array(zStar5).astype(int)\n",
    "            z = [zStar15, zStar10, zStar5]\n",
    "            phi1 = [phi15, phi10, phi5]\n",
    "\n",
    "        for i in range(it):\n",
    "            for j in range(0, n):\n",
    "                noteArray[0,j] = np.random.choice(xstates, size = 1, p = phi15[zStar15[j], :])\n",
    "                noteArray[1,j] = np.random.choice(xstates, size = 1, p = phi10[zStar10[j], :])\n",
    "                noteArray[2,j] = np.random.choice(xstates, size = 1, p = phi5[zStar5[j], :])\n",
    "            temp_notes = np.rint(np.mean(noteArray, axis=0)).astype(int)\n",
    "            temp_notes = decode(temp_notes, possibleNotes)\n",
    "            newNotes = temp_notes\n",
    "            newVelocities = find_vel(newNotes, velocity)\n",
    "            if metrics_calc:\n",
    "                metrics[i+1, :] = calc_metrics(time, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "\n",
    "\n",
    "    if model == 'layered':\n",
    "        it1, p1, pi1, phi1, Tmat1 = first_order(n, m, k, xNotes, tol)\n",
    "        zStar1 = Viterbi(n, m, k, np.log(pi1), np.log(Tmat1), np.log(phi1), xNotes)\n",
    "        zStar1 = np.array(zStar1).astype(int)\n",
    "        it2, p2, pi2, phi2, Tmat2 = first_order(n, m, m, zStar1, tol)\n",
    "        zStar2 = Viterbi(n, m, m, np.log(pi2), np.log(Tmat2), np.log(phi2), zStar1)\n",
    "        zStar2 = np.array(zStar2).astype(int)\n",
    "        it3, p3, pi3, phi3, Tmat3 = first_order(n, m, m, zStar2, tol)\n",
    "        zStar3 = Viterbi(n, m, m, np.log(pi3), np.log(Tmat3), np.log(phi3), zStar2)\n",
    "        zStar3 = np.array(zStar3).astype(int)\n",
    "        output = np.zeros(shape = (3,n), dtype = int)\n",
    "        z = [zStar1, zStar2, zStar3]\n",
    "        \n",
    "        xstates = range(0, k)\n",
    "        zstates = range(0, m)\n",
    "        for i in range(it):\n",
    "            for j in range(0,n):\n",
    "                output[2, j] = np.random.choice(zstates, size = 1, p = phi3[zStar3[j], :])\n",
    "                output[1, j] = np.random.choice(zstates, size = 1, p = phi2[output[2, j], :])\n",
    "                output[0, j] = np.random.choice(xstates, size = 1, p = phi1[output[1, j], :])\n",
    "            temp_notes = decode(output[0,:], possibleNotes).astype(int)\n",
    "            newNotes = temp_notes\n",
    "            newVelocities = find_vel(newNotes, velocity)\n",
    "            if metrics_calc:\n",
    "                metrics[i+1, :] = calc_metrics(time, notes, newNotes, newVelocities, measures, min_note, num)\n",
    "        phi1 = [phi1, phi2, phi3]\n",
    "        \n",
    "\n",
    "    song.iloc[ind, 1] = time\n",
    "    song.iloc[ind, 4] = newNotes\n",
    "    song.iloc[ind, 5] = newVelocities\n",
    "    song.iloc[ind[np.where(newVelocities !=0)], 2] = ' Note_on_c'\n",
    "    song.iloc[ind[np.where(newVelocities ==0)], 2] = ' Note_off_c'\n",
    "    split = output_filename.split('.')\n",
    "    output_filename = split[0] + '__'+ model + '_' + str(m)+  '-tol' +str(tol)+'.' + split[1]\n",
    "    if m2 != None:\n",
    "        output_filename = split[0] + '__'+ model + '_' + str(m)+'-'+str(m2)+ '-tol' +str(tol)+ '.' + split[1]\n",
    "\n",
    "    if metrics_calc:\n",
    "        song_name = split[0].split('/')\n",
    "        metrics_filename = 'metrics/'+song_name[1]+ '__'+ model + '_' + str(m)+  '-tol' +str(tol)+ '.' + split[1] \n",
    "        pd.DataFrame(metrics).to_csv(metrics_filename, header = None, index = False)\n",
    "        print(metrics_filename)\n",
    "    song.to_csv(output_filename, header = None, index = False)\n",
    "    \n",
    "    if case_study:\n",
    "        return(time, notes, newNotes, z, pi1, phi1, Tmat1) #quarter_note, num, denom, key, measures\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
